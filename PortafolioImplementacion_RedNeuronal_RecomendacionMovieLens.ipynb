{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tGLMeZ8GKdx"
      },
      "source": [
        "## Implementación de Red Neuronal con el uso de un framework o librería\n",
        "\n",
        "En este proyecto, se planea construir un sistema de recomendación de películas personalizado utilizando una Red Neuronal (NN) basada en el conjunto de datos MovieLens.\n",
        "\n",
        "El objetivo principal de este proyecto es explorar cómo las técnicas de aprendizaje profundo pueden utilizarse para proporcionar a los usuarios recomendaciones de películas altamente personalizadas.\n",
        "\n",
        "---\n",
        "\n",
        "**¿Qué película deberías ver a continuación?**\n",
        "\n",
        "---\n",
        "\n",
        "El conjunto de datos MovieLens nos proporciona una amplia gama de información sobre las calificaciones de los usuarios para diferentes películas. Esta información nos permitirá entrenar una Red Neuronal que pueda predecir las preferencias de los usuarios y ofrecer recomendaciones de películas que se adapten a sus gustos individuales.\n",
        "\n",
        "*Los datos utilizados en este proyecto provienen de MovieLens: https://grouplens.org/datasets/movielens/100k/, una comunidad en línea que reúne calificaciones y revisiones de películas de usuarios de todo el mundo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n05_ybC_HBwG"
      },
      "source": [
        "### 1. Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "dv5OTsZ9GFXO"
      },
      "outputs": [],
      "source": [
        "# Importamos librerias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Proyecto de Recomendación de Películas\n",
            "    \n",
            "Este proyecto utiliza el conjunto de datos MovieLens para implementar un sistema de recomendación de películas.\n",
            "El objetivo es proporcionar recomendaciones personalizadas a los usuarios ya existentes basadas en sus preferencias, \n",
            "características personales y patrones de calificación. \n",
            "\n",
            "\n",
            "-----------* Librerias importadas con éxito \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Introducción al proyecto\n",
        "resumen = \"\"\"\n",
        "Proyecto de Recomendación de Películas\n",
        "    \n",
        "Este proyecto utiliza el conjunto de datos MovieLens para implementar un sistema de recomendación de películas.\n",
        "El objetivo es proporcionar recomendaciones personalizadas a los usuarios ya existentes basadas en sus preferencias, \n",
        "características personales y patrones de calificación. \\n\n",
        "\"\"\"\n",
        "print(resumen)\n",
        "print(\"-----------* Librerias importadas con éxito \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Definir funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------* Funciones definidas con éxito \n",
            "\n"
          ]
        }
      ],
      "source": [
        "       # Función para obtener el nombre del género para un 'movie_id'\n",
        "def obtener_genre_name(movie_id):\n",
        "              # Buscamos el movie_id en el dataset data_item y seleccionamos las columnas binarias de cada genre_id\n",
        "    genres = data_item[data_item['movie_id'] == movie_id].iloc[:, 5:] \n",
        "              # Buscamos la columna que tiene el valor máximo (1) y accedemos al nombre de la columna (genre_id)\n",
        "    genre_id = genres.idxmax(axis=1).values[0]\n",
        "              # Con el genre_id y el diccionario, obtenemos el genre_name de el movie_id correspondiente\n",
        "    return genre_mapping[int(genre_id.split('_')[1])]\n",
        "\n",
        "        #Función para predecir y evaluar modelos multiclase\n",
        "def evaluar_modelo_multiclase(modelo, X_test, y_test):\n",
        "    # Realizar predicciones en el conjunto de prueba\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Calcular métricas\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    # Matriz de confusión\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"Precisión:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"Exactitud (Accuracy):\", accuracy)\n",
        "    print(\"\\nMatriz de Confusión:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "        #Función para predecir y evaluar red neuronal\n",
        "def evaluar_modelo_nn(modelo, X_test, y_test):\n",
        "    # Realizar predicciones en el conjunto de prueba\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Convierte las predicciones one-hot en clases numéricas\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1) + 1\n",
        "\n",
        "    # Convierte las etiquetas one-hot en clases numéricas\n",
        "    y_test_classes = np.argmax(y_test_one_hot, axis=1) + 1\n",
        "\n",
        "    # Calcular métricas\n",
        "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "    \n",
        "    # Matriz de confusión\n",
        "    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"Precisión:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"Exactitud (Accuracy):\", accuracy)\n",
        "    print(\"\\nMatriz de Confusión:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "        # Función para definir estructura del modelo de red neuronal\n",
        "def set_nn_model_architecture():\n",
        "    # Define Model\n",
        "    model = Sequential(name='my_sequential_model')\n",
        "    \n",
        "    # Hidden Layer 1: Fully-connected layer con 64 unidades y función de activación ReLU\n",
        "    model.add(Dense(units=64, input_shape=X_train_scaled.shape[1:], activation='relu',\n",
        "                    kernel_initializer=tf.keras.initializers.HeUniform(seed=0),\n",
        "                    bias_initializer='ones',\n",
        "                    name='hiddenlayer1'))\n",
        "    \n",
        "    # Configuración de capas ocultas adicionales\n",
        "    model.add(Dense(units=128, activation='relu', name='hiddenlayer2'))\n",
        "    model.add(Dense(units=128, activation='relu', name='hiddenlayer3'))\n",
        "    # Agrega más capas ocultas según sea necesario\n",
        "    \n",
        "    # Capa de salida con activación softmax para clasificación multiclase\n",
        "    num_classes = 5  # Ajusta esto al número de clases en tus datos\n",
        "    model.add(Dense(units=num_classes, activation='softmax', name='outputlayer'))\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "        # Función para trazar las curvas de aprendizaje\n",
        "def plot_acc_loss(training_history):\n",
        "    plt.plot(training_history.history['accuracy'])\n",
        "    plt.plot(training_history.history['val_accuracy'])\n",
        "    plt.title('Accuracy vs. Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(training_history.history['loss'])\n",
        "    plt.plot(training_history.history['val_loss'])\n",
        "    plt.title('Loss vs. Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "print(\"-----------* Funciones definidas con éxito \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYeAJ47EHQWg"
      },
      "source": [
        "### 3. Importar datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------* Datos importados con éxito \n",
            "\n",
            "Para realizar el proyecto, se tienen los siguientes datos.\n",
            "- Cantidad de usuarios: 943\n",
            "- Cantidad de películas: 1682\n",
            "- Cantidad de calificaciones: 100000\n"
          ]
        }
      ],
      "source": [
        "# Cargamos los datasets (la carpeta MovieLens debe estar en la misma carpeta que el programa)\n",
        "    # Leer el archivo u_data en un DataFrame\n",
        "data_general = pd.read_csv('MovieLens/u_data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "\n",
        "    # Leer el archivo u_genre en un DataFrame\n",
        "data_genre = pd.read_csv('MovieLens/u_genre', sep='|', names=['genre_name', 'genre_id'])\n",
        "\n",
        "    # Leer el archivo u_item en un DataFrame\n",
        "        # Lista de nombres de columnas para el DataFrame\n",
        "columns = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL'] + [f'genre_{i}' for i in range(19)]\n",
        "data_item = pd.read_csv('MovieLens/u_item', sep='|', names=columns, encoding='latin-1')   \n",
        "\n",
        "    # Lee el archivo 'u_user' usando '|'\n",
        "data_user = pd.read_csv('MovieLens/u_user', sep='|', names=['user_id', 'age', 'gender', 'occupation', 'zip_code']) \n",
        "\n",
        "    # Lee el archivo u_info y almacena la información en variables individuales\n",
        "with open('MovieLens/u_info', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    users_count = int(lines[0].split()[0])\n",
        "    items_count = int(lines[1].split()[0])\n",
        "    ratings_count = int(lines[2].split()[0])\n",
        "\n",
        "print(\"-----------* Datos importados con éxito \\n\")\n",
        "\n",
        "# Muestra la información de u_info\n",
        "print(\"Para realizar el proyecto, se tienen los siguientes datos.\")\n",
        "print(\"- Cantidad de usuarios:\", users_count)\n",
        "print(\"- Cantidad de películas:\", items_count)\n",
        "print(\"- Cantidad de calificaciones:\", ratings_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Combinar datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------* Combinando datos... \n",
            "\n",
            "-----------* Datos combinados con éxito \n",
            "\n",
            "       user_id  movie_id  age gender occupation genre_name  rating\n",
            "0          196       242   49      M     writer     Comedy       3\n",
            "1          196       393   49      M     writer     Comedy       4\n",
            "2          196       381   49      M     writer     Comedy       4\n",
            "3          196       251   49      M     writer     Comedy       3\n",
            "4          196       655   49      M     writer  Adventure       5\n",
            "...        ...       ...  ...    ...        ...        ...     ...\n",
            "99995      941       919   20      M    student  Adventure       5\n",
            "99996      941       273   20      M    student     Action       3\n",
            "99997      941         1   20      M    student  Animation       5\n",
            "99998      941       294   20      M    student     Comedy       4\n",
            "99999      941      1007   20      M    student     Comedy       4\n",
            "\n",
            "[100000 rows x 7 columns]\n",
            "\n",
            " Estos son los datos que utilizaremos para entrenar nuestros modelos. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------* Combinando datos... \\n\")\n",
        "\n",
        "# Fusionar los DataFrames\n",
        "merged_data = pd.merge(data_general, data_user, on='user_id') # Combinamos las calificaciones con las características del usuario\n",
        "\n",
        "# Añadimos el género de las peliculas segun su id\n",
        "       # Crear un diccionario que mapee 'genre_id' a 'genre_name'\n",
        "genre_mapping = dict(data_genre[['genre_id', 'genre_name']].values)\n",
        "\n",
        "# Aplicar la función obtener_genre_name para crear la columna 'genre_name'\n",
        "merged_data['genre_name'] = merged_data['movie_id'].apply(obtener_genre_name)\n",
        "\n",
        "# Seleccionar las columnas de interés\n",
        "final_data = merged_data[['user_id', 'movie_id', 'age', 'gender',\n",
        "       'occupation', 'genre_name', 'rating']] # Quitamos la columna timestamp, zip_code y genre_id\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "print(\"-----------* Datos combinados con éxito \\n\")\n",
        "\n",
        "print(final_data)\n",
        "print(\"\\n Estos son los datos que utilizaremos para entrenar nuestros modelos. \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKjDq3JaNg7S"
      },
      "source": [
        "### 5. Dividir datos (Entrenamiento y prueba)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QoGfB_ISNkAH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------* Datos divididos para entrenamiento y prueba con éxito \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definir X y y\n",
        "X = final_data[['user_id', 'movie_id', 'age', 'gender',\n",
        "       'occupation', 'genre_name']]\n",
        "y = final_data['rating']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=44)\n",
        "\n",
        "# Ajustar los datos a los modelos que no manejan cualitativas originales\n",
        "X_encoded = pd.get_dummies(X, columns=['gender', 'genre_name', 'occupation'], drop_first=True)\n",
        "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(X_encoded, y, test_size = 0.2, random_state=44)\n",
        "\n",
        "print(\"-----------* Datos divididos para entrenamiento y prueba con éxito \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okwrQGggQefx"
      },
      "source": [
        "### 4. Entrenar modelos\n",
        "\n",
        "#### *Árbol de decisión*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------* Creación del primer modelo con éxito \n",
            "\n",
            "-----------* Primer modelo entrenado con éxito \n",
            "\n",
            "Evaluación del primer modelo: Árbol de decisión \n",
            "\n",
            "F1 Score: 0.2766897294338014\n",
            "Precisión: 0.3779273014087032\n",
            "Recall: 0.3615\n",
            "Exactitud (Accuracy): 0.3615\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[ 112    2  296  784   20]\n",
            " [  13    6  576 1651   24]\n",
            " [  11   12 1074 4299  111]\n",
            " [   3    8  850 5732  231]\n",
            " [   2    4  369 3504  306]]\n",
            " \n",
            "      \n",
            "Continuaremos explorando otros modelos...\n"
          ]
        }
      ],
      "source": [
        "# Crear el modelo de Árbol de Decisión\n",
        "decision_tree_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "    # profundidad máxima de 5 para el árbol de decisión con el propósito de acelerar el tiempo de entrenamiento y prevenir el sobreajuste\n",
        "\n",
        "print(\"-----------* Creación del primer modelo con éxito \\n\")\n",
        "\n",
        "# Entrenar el modelo en los datos de entrenamiento\n",
        "decision_tree_model.fit(X_train_encoded, y_train_encoded)\n",
        "\n",
        "print(\"-----------* Primer modelo entrenado con éxito \\n\")\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba y evaluar el modelo\n",
        "print(\"Evaluación del primer modelo: Árbol de decisión \\n\")\n",
        "evaluar_modelo_multiclase(decision_tree_model, X_test_encoded, y_test_encoded)\n",
        "\n",
        "# Despliegue de conclusión\n",
        "print(\"\"\" \n",
        "      \n",
        "Continuaremos explorando otros modelos...\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Random Forest*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------* Creación del segundo modelo con éxito \n",
            "\n",
            "-----------* Segundo modelo entrenado con éxito \n",
            "\n",
            "Evaluación del segundo modelo: Random Forest \n",
            "\n",
            "F1 Score: 0.34555489427746644\n",
            "Precisión: 0.344092587184264\n",
            "Recall: 0.34765\n",
            "Exactitud (Accuracy): 0.34765\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[ 292  221  303  274  124]\n",
            " [ 194  366  778  655  277]\n",
            " [ 256  660 1902 1939  750]\n",
            " [ 202  547 1793 2887 1395]\n",
            " [ 118  233  776 1552 1506]]\n",
            " \n",
            "      \n",
            "Continuaremos explorando otros modelos...\n"
          ]
        }
      ],
      "source": [
        "# Crear el modelo de Random Forest\n",
        "random_forest_model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
        "print(\"-----------* Creación del segundo modelo con éxito \\n\")\n",
        "\n",
        "# Entrenar el modelo en los datos de entrenamiento\n",
        "random_forest_model.fit(X_train_encoded, y_train_encoded)\n",
        "\n",
        "print(\"-----------* Segundo modelo entrenado con éxito \\n\")\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba y evaluar el modelo\n",
        "print(\"Evaluación del segundo modelo: Random Forest \\n\")\n",
        "evaluar_modelo_multiclase(random_forest_model, X_test_encoded, y_test_encoded)\n",
        "\n",
        "# Despliegue de conclusión\n",
        "print(\"\"\" \n",
        "      \n",
        "Continuaremos explorando otros modelos...\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *K-Nearest Neighbors*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------* Creación del tercer modelo con éxito \n",
            "\n",
            "-----------* Tercer modelo entrenado con éxito \n",
            "\n",
            "Evaluación del tercer modelo: K-Nearest Neighbors \n",
            "\n",
            "F1 Score: 0.34176416534572446\n",
            "Precisión: 0.3437180963357277\n",
            "Recall: 0.3492\n",
            "Exactitud (Accuracy): 0.3492\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[ 272  152  355  333  102]\n",
            " [ 108  320  909  744  189]\n",
            " [ 179  500 2069 2148  611]\n",
            " [ 144  387 2066 3152 1075]\n",
            " [  76  159  934 1845 1171]]\n",
            " \n",
            "      \n",
            "Continuaremos explorando otros modelos...\n"
          ]
        }
      ],
      "source": [
        "# Escalar las características (si aún no se han escalado)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)  # Asumiendo que tienes tus conjuntos de entrenamiento y prueba\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "\n",
        "# Crear el modelo KNN\n",
        "knn_model = KNeighborsClassifier(n_neighbors=10) \n",
        "print(\"-----------* Creación del tercer modelo con éxito \\n\")\n",
        "\n",
        "\n",
        "# Entrenar el modelo en los datos de entrenamiento\n",
        "knn_model.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "print(\"-----------* Tercer modelo entrenado con éxito \\n\")\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba y evaluar el modelo\n",
        "print(\"Evaluación del tercer modelo: K-Nearest Neighbors \\n\")\n",
        "evaluar_modelo_multiclase(knn_model, X_test_scaled, y_test_encoded)\n",
        "\n",
        "# Despliegue de conclusión\n",
        "print(\"\"\" \n",
        "      \n",
        "Continuaremos explorando otros modelos...\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Red Neuronal*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_sequential_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenlayer1 (Dense)        (None, 64)                2752      \n",
            "                                                                 \n",
            " hiddenlayer2 (Dense)        (None, 128)               8320      \n",
            "                                                                 \n",
            " hiddenlayer3 (Dense)        (None, 128)               16512     \n",
            "                                                                 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " outputlayer (Dense)         (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,229\n",
            "Trainable params: 28,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "-----------* Creación del cuarto modelo con éxito \n",
            "\n",
            "Epoch 1/800\n",
            "1700/1700 [==============================] - 1s 612us/step - loss: 1.4570 - accuracy: 0.3429 - val_loss: 1.4381 - val_accuracy: 0.3492\n",
            "Epoch 2/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.4292 - accuracy: 0.3569 - val_loss: 1.4312 - val_accuracy: 0.3532\n",
            "Epoch 3/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.4215 - accuracy: 0.3625 - val_loss: 1.4285 - val_accuracy: 0.3560\n",
            "Epoch 4/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.4158 - accuracy: 0.3630 - val_loss: 1.4247 - val_accuracy: 0.3557\n",
            "Epoch 5/800\n",
            "1700/1700 [==============================] - 1s 532us/step - loss: 1.4119 - accuracy: 0.3650 - val_loss: 1.4234 - val_accuracy: 0.3583\n",
            "Epoch 6/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.4092 - accuracy: 0.3684 - val_loss: 1.4234 - val_accuracy: 0.3550\n",
            "Epoch 7/800\n",
            "1700/1700 [==============================] - 1s 594us/step - loss: 1.4063 - accuracy: 0.3702 - val_loss: 1.4221 - val_accuracy: 0.3575\n",
            "Epoch 8/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.4040 - accuracy: 0.3711 - val_loss: 1.4245 - val_accuracy: 0.3564\n",
            "Epoch 9/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.4023 - accuracy: 0.3716 - val_loss: 1.4215 - val_accuracy: 0.3566\n",
            "Epoch 10/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.4001 - accuracy: 0.3740 - val_loss: 1.4193 - val_accuracy: 0.3584\n",
            "Epoch 11/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3986 - accuracy: 0.3750 - val_loss: 1.4182 - val_accuracy: 0.3602\n",
            "Epoch 12/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3969 - accuracy: 0.3753 - val_loss: 1.4181 - val_accuracy: 0.3588\n",
            "Epoch 13/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.3952 - accuracy: 0.3752 - val_loss: 1.4170 - val_accuracy: 0.3596\n",
            "Epoch 14/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3939 - accuracy: 0.3784 - val_loss: 1.4170 - val_accuracy: 0.3623\n",
            "Epoch 15/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3924 - accuracy: 0.3773 - val_loss: 1.4181 - val_accuracy: 0.3657\n",
            "Epoch 16/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.3912 - accuracy: 0.3790 - val_loss: 1.4159 - val_accuracy: 0.3633\n",
            "Epoch 17/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3896 - accuracy: 0.3794 - val_loss: 1.4175 - val_accuracy: 0.3626\n",
            "Epoch 18/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3886 - accuracy: 0.3798 - val_loss: 1.4173 - val_accuracy: 0.3635\n",
            "Epoch 19/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3875 - accuracy: 0.3811 - val_loss: 1.4155 - val_accuracy: 0.3619\n",
            "Epoch 20/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.3861 - accuracy: 0.3825 - val_loss: 1.4160 - val_accuracy: 0.3645\n",
            "Epoch 21/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3851 - accuracy: 0.3821 - val_loss: 1.4151 - val_accuracy: 0.3613\n",
            "Epoch 22/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3844 - accuracy: 0.3832 - val_loss: 1.4142 - val_accuracy: 0.3638\n",
            "Epoch 23/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3825 - accuracy: 0.3833 - val_loss: 1.4157 - val_accuracy: 0.3602\n",
            "Epoch 24/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3818 - accuracy: 0.3838 - val_loss: 1.4142 - val_accuracy: 0.3632\n",
            "Epoch 25/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3806 - accuracy: 0.3836 - val_loss: 1.4146 - val_accuracy: 0.3623\n",
            "Epoch 26/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3801 - accuracy: 0.3854 - val_loss: 1.4136 - val_accuracy: 0.3653\n",
            "Epoch 27/800\n",
            "1700/1700 [==============================] - 1s 561us/step - loss: 1.3785 - accuracy: 0.3860 - val_loss: 1.4139 - val_accuracy: 0.3630\n",
            "Epoch 28/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3781 - accuracy: 0.3859 - val_loss: 1.4125 - val_accuracy: 0.3640\n",
            "Epoch 29/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3766 - accuracy: 0.3865 - val_loss: 1.4157 - val_accuracy: 0.3632\n",
            "Epoch 30/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3759 - accuracy: 0.3884 - val_loss: 1.4141 - val_accuracy: 0.3620\n",
            "Epoch 31/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.3748 - accuracy: 0.3865 - val_loss: 1.4115 - val_accuracy: 0.3635\n",
            "Epoch 32/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3738 - accuracy: 0.3883 - val_loss: 1.4132 - val_accuracy: 0.3665\n",
            "Epoch 33/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3726 - accuracy: 0.3886 - val_loss: 1.4124 - val_accuracy: 0.3623\n",
            "Epoch 34/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.3719 - accuracy: 0.3882 - val_loss: 1.4113 - val_accuracy: 0.3657\n",
            "Epoch 35/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3712 - accuracy: 0.3895 - val_loss: 1.4135 - val_accuracy: 0.3694\n",
            "Epoch 36/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3700 - accuracy: 0.3912 - val_loss: 1.4134 - val_accuracy: 0.3655\n",
            "Epoch 37/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3689 - accuracy: 0.3905 - val_loss: 1.4134 - val_accuracy: 0.3638\n",
            "Epoch 38/800\n",
            "1700/1700 [==============================] - 1s 577us/step - loss: 1.3682 - accuracy: 0.3908 - val_loss: 1.4137 - val_accuracy: 0.3684\n",
            "Epoch 39/800\n",
            "1700/1700 [==============================] - 1s 561us/step - loss: 1.3672 - accuracy: 0.3916 - val_loss: 1.4121 - val_accuracy: 0.3661\n",
            "Epoch 40/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3665 - accuracy: 0.3917 - val_loss: 1.4122 - val_accuracy: 0.3651\n",
            "Epoch 41/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.3658 - accuracy: 0.3934 - val_loss: 1.4147 - val_accuracy: 0.3667\n",
            "Epoch 42/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.3646 - accuracy: 0.3942 - val_loss: 1.4117 - val_accuracy: 0.3696\n",
            "Epoch 43/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3632 - accuracy: 0.3936 - val_loss: 1.4136 - val_accuracy: 0.3663\n",
            "Epoch 44/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3629 - accuracy: 0.3940 - val_loss: 1.4126 - val_accuracy: 0.3634\n",
            "Epoch 45/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.3623 - accuracy: 0.3941 - val_loss: 1.4131 - val_accuracy: 0.3643\n",
            "Epoch 46/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3614 - accuracy: 0.3947 - val_loss: 1.4138 - val_accuracy: 0.3617\n",
            "Epoch 47/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3602 - accuracy: 0.3960 - val_loss: 1.4110 - val_accuracy: 0.3663\n",
            "Epoch 48/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3594 - accuracy: 0.3957 - val_loss: 1.4118 - val_accuracy: 0.3651\n",
            "Epoch 49/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3585 - accuracy: 0.3975 - val_loss: 1.4131 - val_accuracy: 0.3652\n",
            "Epoch 50/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.3578 - accuracy: 0.3972 - val_loss: 1.4124 - val_accuracy: 0.3662\n",
            "Epoch 51/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3574 - accuracy: 0.3977 - val_loss: 1.4149 - val_accuracy: 0.3638\n",
            "Epoch 52/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3563 - accuracy: 0.3978 - val_loss: 1.4129 - val_accuracy: 0.3686\n",
            "Epoch 53/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.3553 - accuracy: 0.3993 - val_loss: 1.4150 - val_accuracy: 0.3611\n",
            "Epoch 54/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.3545 - accuracy: 0.3996 - val_loss: 1.4118 - val_accuracy: 0.3672\n",
            "Epoch 55/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.3541 - accuracy: 0.3988 - val_loss: 1.4125 - val_accuracy: 0.3666\n",
            "Epoch 56/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3527 - accuracy: 0.3995 - val_loss: 1.4108 - val_accuracy: 0.3669\n",
            "Epoch 57/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.3524 - accuracy: 0.3987 - val_loss: 1.4123 - val_accuracy: 0.3633\n",
            "Epoch 58/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3514 - accuracy: 0.4010 - val_loss: 1.4120 - val_accuracy: 0.3659\n",
            "Epoch 59/800\n",
            "1700/1700 [==============================] - 1s 551us/step - loss: 1.3504 - accuracy: 0.4002 - val_loss: 1.4135 - val_accuracy: 0.3661\n",
            "Epoch 60/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3501 - accuracy: 0.3996 - val_loss: 1.4139 - val_accuracy: 0.3692\n",
            "Epoch 61/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3489 - accuracy: 0.4021 - val_loss: 1.4151 - val_accuracy: 0.3652\n",
            "Epoch 62/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3487 - accuracy: 0.4007 - val_loss: 1.4162 - val_accuracy: 0.3638\n",
            "Epoch 63/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.3476 - accuracy: 0.4014 - val_loss: 1.4154 - val_accuracy: 0.3683\n",
            "Epoch 64/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.3468 - accuracy: 0.4026 - val_loss: 1.4146 - val_accuracy: 0.3616\n",
            "Epoch 65/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3459 - accuracy: 0.4021 - val_loss: 1.4166 - val_accuracy: 0.3663\n",
            "Epoch 66/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3455 - accuracy: 0.4043 - val_loss: 1.4138 - val_accuracy: 0.3647\n",
            "Epoch 67/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3450 - accuracy: 0.4029 - val_loss: 1.4176 - val_accuracy: 0.3632\n",
            "Epoch 68/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.3441 - accuracy: 0.4034 - val_loss: 1.4161 - val_accuracy: 0.3725\n",
            "Epoch 69/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.3436 - accuracy: 0.4055 - val_loss: 1.4164 - val_accuracy: 0.3652\n",
            "Epoch 70/800\n",
            "1700/1700 [==============================] - 1s 564us/step - loss: 1.3427 - accuracy: 0.4071 - val_loss: 1.4163 - val_accuracy: 0.3652\n",
            "Epoch 71/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.3423 - accuracy: 0.4064 - val_loss: 1.4139 - val_accuracy: 0.3652\n",
            "Epoch 72/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.3412 - accuracy: 0.4061 - val_loss: 1.4178 - val_accuracy: 0.3682\n",
            "Epoch 73/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3408 - accuracy: 0.4065 - val_loss: 1.4140 - val_accuracy: 0.3645\n",
            "Epoch 74/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3398 - accuracy: 0.4076 - val_loss: 1.4180 - val_accuracy: 0.3668\n",
            "Epoch 75/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.3396 - accuracy: 0.4076 - val_loss: 1.4168 - val_accuracy: 0.3683\n",
            "Epoch 76/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3390 - accuracy: 0.4083 - val_loss: 1.4165 - val_accuracy: 0.3692\n",
            "Epoch 77/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3380 - accuracy: 0.4077 - val_loss: 1.4177 - val_accuracy: 0.3673\n",
            "Epoch 78/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3373 - accuracy: 0.4091 - val_loss: 1.4174 - val_accuracy: 0.3672\n",
            "Epoch 79/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3368 - accuracy: 0.4090 - val_loss: 1.4163 - val_accuracy: 0.3690\n",
            "Epoch 80/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.3366 - accuracy: 0.4103 - val_loss: 1.4182 - val_accuracy: 0.3692\n",
            "Epoch 81/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.3353 - accuracy: 0.4106 - val_loss: 1.4198 - val_accuracy: 0.3687\n",
            "Epoch 82/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3349 - accuracy: 0.4101 - val_loss: 1.4167 - val_accuracy: 0.3688\n",
            "Epoch 83/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3341 - accuracy: 0.4100 - val_loss: 1.4179 - val_accuracy: 0.3663\n",
            "Epoch 84/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3336 - accuracy: 0.4111 - val_loss: 1.4157 - val_accuracy: 0.3686\n",
            "Epoch 85/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3328 - accuracy: 0.4100 - val_loss: 1.4211 - val_accuracy: 0.3648\n",
            "Epoch 86/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.3324 - accuracy: 0.4098 - val_loss: 1.4184 - val_accuracy: 0.3654\n",
            "Epoch 87/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3317 - accuracy: 0.4116 - val_loss: 1.4171 - val_accuracy: 0.3674\n",
            "Epoch 88/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3309 - accuracy: 0.4124 - val_loss: 1.4182 - val_accuracy: 0.3668\n",
            "Epoch 89/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.3307 - accuracy: 0.4127 - val_loss: 1.4214 - val_accuracy: 0.3663\n",
            "Epoch 90/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3299 - accuracy: 0.4118 - val_loss: 1.4197 - val_accuracy: 0.3658\n",
            "Epoch 91/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.3291 - accuracy: 0.4130 - val_loss: 1.4194 - val_accuracy: 0.3652\n",
            "Epoch 92/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3289 - accuracy: 0.4123 - val_loss: 1.4175 - val_accuracy: 0.3668\n",
            "Epoch 93/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.3285 - accuracy: 0.4145 - val_loss: 1.4191 - val_accuracy: 0.3663\n",
            "Epoch 94/800\n",
            "1700/1700 [==============================] - 1s 564us/step - loss: 1.3278 - accuracy: 0.4143 - val_loss: 1.4208 - val_accuracy: 0.3654\n",
            "Epoch 95/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3266 - accuracy: 0.4136 - val_loss: 1.4228 - val_accuracy: 0.3698\n",
            "Epoch 96/800\n",
            "1700/1700 [==============================] - 1s 586us/step - loss: 1.3263 - accuracy: 0.4145 - val_loss: 1.4231 - val_accuracy: 0.3647\n",
            "Epoch 97/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.3257 - accuracy: 0.4146 - val_loss: 1.4229 - val_accuracy: 0.3604\n",
            "Epoch 98/800\n",
            "1700/1700 [==============================] - 1s 593us/step - loss: 1.3249 - accuracy: 0.4149 - val_loss: 1.4199 - val_accuracy: 0.3691\n",
            "Epoch 99/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.3243 - accuracy: 0.4159 - val_loss: 1.4218 - val_accuracy: 0.3666\n",
            "Epoch 100/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.3238 - accuracy: 0.4177 - val_loss: 1.4257 - val_accuracy: 0.3570\n",
            "Epoch 101/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3235 - accuracy: 0.4153 - val_loss: 1.4206 - val_accuracy: 0.3687\n",
            "Epoch 102/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3228 - accuracy: 0.4165 - val_loss: 1.4240 - val_accuracy: 0.3631\n",
            "Epoch 103/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.3225 - accuracy: 0.4157 - val_loss: 1.4233 - val_accuracy: 0.3652\n",
            "Epoch 104/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.3218 - accuracy: 0.4161 - val_loss: 1.4220 - val_accuracy: 0.3631\n",
            "Epoch 105/800\n",
            "1700/1700 [==============================] - 1s 589us/step - loss: 1.3211 - accuracy: 0.4175 - val_loss: 1.4214 - val_accuracy: 0.3680\n",
            "Epoch 106/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.3208 - accuracy: 0.4174 - val_loss: 1.4232 - val_accuracy: 0.3674\n",
            "Epoch 107/800\n",
            "1700/1700 [==============================] - 1s 590us/step - loss: 1.3203 - accuracy: 0.4190 - val_loss: 1.4223 - val_accuracy: 0.3725\n",
            "Epoch 108/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.3197 - accuracy: 0.4190 - val_loss: 1.4226 - val_accuracy: 0.3663\n",
            "Epoch 109/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.3188 - accuracy: 0.4171 - val_loss: 1.4237 - val_accuracy: 0.3710\n",
            "Epoch 110/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3182 - accuracy: 0.4174 - val_loss: 1.4247 - val_accuracy: 0.3689\n",
            "Epoch 111/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.3182 - accuracy: 0.4196 - val_loss: 1.4233 - val_accuracy: 0.3684\n",
            "Epoch 112/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3177 - accuracy: 0.4200 - val_loss: 1.4271 - val_accuracy: 0.3672\n",
            "Epoch 113/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3168 - accuracy: 0.4205 - val_loss: 1.4241 - val_accuracy: 0.3642\n",
            "Epoch 114/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3160 - accuracy: 0.4204 - val_loss: 1.4261 - val_accuracy: 0.3663\n",
            "Epoch 115/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3159 - accuracy: 0.4207 - val_loss: 1.4282 - val_accuracy: 0.3660\n",
            "Epoch 116/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.3155 - accuracy: 0.4215 - val_loss: 1.4263 - val_accuracy: 0.3658\n",
            "Epoch 117/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3147 - accuracy: 0.4215 - val_loss: 1.4250 - val_accuracy: 0.3655\n",
            "Epoch 118/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.3142 - accuracy: 0.4206 - val_loss: 1.4274 - val_accuracy: 0.3652\n",
            "Epoch 119/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3134 - accuracy: 0.4201 - val_loss: 1.4252 - val_accuracy: 0.3667\n",
            "Epoch 120/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3133 - accuracy: 0.4228 - val_loss: 1.4280 - val_accuracy: 0.3673\n",
            "Epoch 121/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3129 - accuracy: 0.4217 - val_loss: 1.4273 - val_accuracy: 0.3676\n",
            "Epoch 122/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3118 - accuracy: 0.4223 - val_loss: 1.4281 - val_accuracy: 0.3671\n",
            "Epoch 123/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.3116 - accuracy: 0.4217 - val_loss: 1.4258 - val_accuracy: 0.3688\n",
            "Epoch 124/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3114 - accuracy: 0.4216 - val_loss: 1.4278 - val_accuracy: 0.3662\n",
            "Epoch 125/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3103 - accuracy: 0.4236 - val_loss: 1.4286 - val_accuracy: 0.3686\n",
            "Epoch 126/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.3101 - accuracy: 0.4219 - val_loss: 1.4285 - val_accuracy: 0.3649\n",
            "Epoch 127/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3095 - accuracy: 0.4229 - val_loss: 1.4281 - val_accuracy: 0.3677\n",
            "Epoch 128/800\n",
            "1700/1700 [==============================] - 1s 560us/step - loss: 1.3093 - accuracy: 0.4237 - val_loss: 1.4275 - val_accuracy: 0.3672\n",
            "Epoch 129/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.3090 - accuracy: 0.4228 - val_loss: 1.4293 - val_accuracy: 0.3661\n",
            "Epoch 130/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3081 - accuracy: 0.4252 - val_loss: 1.4267 - val_accuracy: 0.3663\n",
            "Epoch 131/800\n",
            "1700/1700 [==============================] - 1s 577us/step - loss: 1.3077 - accuracy: 0.4238 - val_loss: 1.4303 - val_accuracy: 0.3612\n",
            "Epoch 132/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.3078 - accuracy: 0.4242 - val_loss: 1.4288 - val_accuracy: 0.3683\n",
            "Epoch 133/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.3066 - accuracy: 0.4252 - val_loss: 1.4304 - val_accuracy: 0.3658\n",
            "Epoch 134/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.3062 - accuracy: 0.4249 - val_loss: 1.4327 - val_accuracy: 0.3672\n",
            "Epoch 135/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3065 - accuracy: 0.4238 - val_loss: 1.4295 - val_accuracy: 0.3644\n",
            "Epoch 136/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.3053 - accuracy: 0.4262 - val_loss: 1.4294 - val_accuracy: 0.3600\n",
            "Epoch 137/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3045 - accuracy: 0.4262 - val_loss: 1.4332 - val_accuracy: 0.3685\n",
            "Epoch 138/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.3048 - accuracy: 0.4260 - val_loss: 1.4288 - val_accuracy: 0.3705\n",
            "Epoch 139/800\n",
            "1700/1700 [==============================] - 1s 561us/step - loss: 1.3037 - accuracy: 0.4277 - val_loss: 1.4288 - val_accuracy: 0.3659\n",
            "Epoch 140/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3034 - accuracy: 0.4284 - val_loss: 1.4337 - val_accuracy: 0.3605\n",
            "Epoch 141/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3028 - accuracy: 0.4289 - val_loss: 1.4313 - val_accuracy: 0.3665\n",
            "Epoch 142/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.3023 - accuracy: 0.4275 - val_loss: 1.4311 - val_accuracy: 0.3672\n",
            "Epoch 143/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.3019 - accuracy: 0.4280 - val_loss: 1.4326 - val_accuracy: 0.3671\n",
            "Epoch 144/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.3016 - accuracy: 0.4285 - val_loss: 1.4325 - val_accuracy: 0.3639\n",
            "Epoch 145/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.3012 - accuracy: 0.4280 - val_loss: 1.4324 - val_accuracy: 0.3627\n",
            "Epoch 146/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.3004 - accuracy: 0.4300 - val_loss: 1.4388 - val_accuracy: 0.3627\n",
            "Epoch 147/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.3003 - accuracy: 0.4290 - val_loss: 1.4329 - val_accuracy: 0.3648\n",
            "Epoch 148/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2993 - accuracy: 0.4302 - val_loss: 1.4353 - val_accuracy: 0.3653\n",
            "Epoch 149/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2993 - accuracy: 0.4288 - val_loss: 1.4362 - val_accuracy: 0.3632\n",
            "Epoch 150/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2987 - accuracy: 0.4279 - val_loss: 1.4351 - val_accuracy: 0.3656\n",
            "Epoch 151/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2987 - accuracy: 0.4289 - val_loss: 1.4364 - val_accuracy: 0.3692\n",
            "Epoch 152/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.2982 - accuracy: 0.4282 - val_loss: 1.4342 - val_accuracy: 0.3658\n",
            "Epoch 153/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2980 - accuracy: 0.4294 - val_loss: 1.4352 - val_accuracy: 0.3651\n",
            "Epoch 154/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2972 - accuracy: 0.4305 - val_loss: 1.4350 - val_accuracy: 0.3688\n",
            "Epoch 155/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.2968 - accuracy: 0.4301 - val_loss: 1.4337 - val_accuracy: 0.3637\n",
            "Epoch 156/800\n",
            "1700/1700 [==============================] - 1s 564us/step - loss: 1.2959 - accuracy: 0.4301 - val_loss: 1.4359 - val_accuracy: 0.3619\n",
            "Epoch 157/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2957 - accuracy: 0.4312 - val_loss: 1.4384 - val_accuracy: 0.3700\n",
            "Epoch 158/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2951 - accuracy: 0.4311 - val_loss: 1.4398 - val_accuracy: 0.3632\n",
            "Epoch 159/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.2950 - accuracy: 0.4302 - val_loss: 1.4347 - val_accuracy: 0.3681\n",
            "Epoch 160/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2943 - accuracy: 0.4323 - val_loss: 1.4367 - val_accuracy: 0.3642\n",
            "Epoch 161/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2942 - accuracy: 0.4313 - val_loss: 1.4364 - val_accuracy: 0.3659\n",
            "Epoch 162/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2937 - accuracy: 0.4313 - val_loss: 1.4355 - val_accuracy: 0.3708\n",
            "Epoch 163/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2928 - accuracy: 0.4331 - val_loss: 1.4388 - val_accuracy: 0.3636\n",
            "Epoch 164/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2926 - accuracy: 0.4332 - val_loss: 1.4398 - val_accuracy: 0.3629\n",
            "Epoch 165/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2925 - accuracy: 0.4304 - val_loss: 1.4373 - val_accuracy: 0.3636\n",
            "Epoch 166/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2921 - accuracy: 0.4322 - val_loss: 1.4383 - val_accuracy: 0.3613\n",
            "Epoch 167/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.2919 - accuracy: 0.4339 - val_loss: 1.4387 - val_accuracy: 0.3652\n",
            "Epoch 168/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2914 - accuracy: 0.4331 - val_loss: 1.4389 - val_accuracy: 0.3639\n",
            "Epoch 169/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2906 - accuracy: 0.4335 - val_loss: 1.4391 - val_accuracy: 0.3632\n",
            "Epoch 170/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.2906 - accuracy: 0.4333 - val_loss: 1.4385 - val_accuracy: 0.3657\n",
            "Epoch 171/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2899 - accuracy: 0.4336 - val_loss: 1.4375 - val_accuracy: 0.3668\n",
            "Epoch 172/800\n",
            "1700/1700 [==============================] - 1s 560us/step - loss: 1.2898 - accuracy: 0.4330 - val_loss: 1.4396 - val_accuracy: 0.3658\n",
            "Epoch 173/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2890 - accuracy: 0.4345 - val_loss: 1.4398 - val_accuracy: 0.3672\n",
            "Epoch 174/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.2887 - accuracy: 0.4347 - val_loss: 1.4413 - val_accuracy: 0.3649\n",
            "Epoch 175/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2882 - accuracy: 0.4345 - val_loss: 1.4406 - val_accuracy: 0.3668\n",
            "Epoch 176/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2880 - accuracy: 0.4359 - val_loss: 1.4422 - val_accuracy: 0.3627\n",
            "Epoch 177/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2875 - accuracy: 0.4374 - val_loss: 1.4480 - val_accuracy: 0.3641\n",
            "Epoch 178/800\n",
            "1700/1700 [==============================] - 1s 538us/step - loss: 1.2871 - accuracy: 0.4349 - val_loss: 1.4411 - val_accuracy: 0.3663\n",
            "Epoch 179/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2865 - accuracy: 0.4348 - val_loss: 1.4411 - val_accuracy: 0.3641\n",
            "Epoch 180/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2860 - accuracy: 0.4355 - val_loss: 1.4396 - val_accuracy: 0.3713\n",
            "Epoch 181/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.2860 - accuracy: 0.4361 - val_loss: 1.4401 - val_accuracy: 0.3671\n",
            "Epoch 182/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2857 - accuracy: 0.4373 - val_loss: 1.4435 - val_accuracy: 0.3637\n",
            "Epoch 183/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2849 - accuracy: 0.4379 - val_loss: 1.4443 - val_accuracy: 0.3719\n",
            "Epoch 184/800\n",
            "1700/1700 [==============================] - 1s 560us/step - loss: 1.2848 - accuracy: 0.4375 - val_loss: 1.4411 - val_accuracy: 0.3634\n",
            "Epoch 185/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2842 - accuracy: 0.4370 - val_loss: 1.4456 - val_accuracy: 0.3609\n",
            "Epoch 186/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2844 - accuracy: 0.4373 - val_loss: 1.4442 - val_accuracy: 0.3704\n",
            "Epoch 187/800\n",
            "1700/1700 [==============================] - 1s 560us/step - loss: 1.2829 - accuracy: 0.4376 - val_loss: 1.4458 - val_accuracy: 0.3663\n",
            "Epoch 188/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2829 - accuracy: 0.4377 - val_loss: 1.4426 - val_accuracy: 0.3658\n",
            "Epoch 189/800\n",
            "1700/1700 [==============================] - 1s 562us/step - loss: 1.2828 - accuracy: 0.4353 - val_loss: 1.4424 - val_accuracy: 0.3661\n",
            "Epoch 190/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.2823 - accuracy: 0.4366 - val_loss: 1.4449 - val_accuracy: 0.3635\n",
            "Epoch 191/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2816 - accuracy: 0.4379 - val_loss: 1.4500 - val_accuracy: 0.3689\n",
            "Epoch 192/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.2819 - accuracy: 0.4395 - val_loss: 1.4444 - val_accuracy: 0.3632\n",
            "Epoch 193/800\n",
            "1700/1700 [==============================] - 1s 561us/step - loss: 1.2811 - accuracy: 0.4381 - val_loss: 1.4460 - val_accuracy: 0.3600\n",
            "Epoch 194/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2810 - accuracy: 0.4390 - val_loss: 1.4465 - val_accuracy: 0.3683\n",
            "Epoch 195/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2805 - accuracy: 0.4396 - val_loss: 1.4464 - val_accuracy: 0.3669\n",
            "Epoch 196/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2805 - accuracy: 0.4390 - val_loss: 1.4449 - val_accuracy: 0.3660\n",
            "Epoch 197/800\n",
            "1700/1700 [==============================] - 1s 560us/step - loss: 1.2802 - accuracy: 0.4398 - val_loss: 1.4446 - val_accuracy: 0.3671\n",
            "Epoch 198/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2794 - accuracy: 0.4399 - val_loss: 1.4489 - val_accuracy: 0.3659\n",
            "Epoch 199/800\n",
            "1700/1700 [==============================] - 1s 549us/step - loss: 1.2795 - accuracy: 0.4382 - val_loss: 1.4508 - val_accuracy: 0.3605\n",
            "Epoch 200/800\n",
            "1700/1700 [==============================] - 1s 562us/step - loss: 1.2790 - accuracy: 0.4394 - val_loss: 1.4456 - val_accuracy: 0.3618\n",
            "Epoch 201/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2788 - accuracy: 0.4400 - val_loss: 1.4503 - val_accuracy: 0.3674\n",
            "Epoch 202/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2781 - accuracy: 0.4404 - val_loss: 1.4468 - val_accuracy: 0.3666\n",
            "Epoch 203/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.2777 - accuracy: 0.4405 - val_loss: 1.4459 - val_accuracy: 0.3642\n",
            "Epoch 204/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2771 - accuracy: 0.4404 - val_loss: 1.4479 - val_accuracy: 0.3611\n",
            "Epoch 205/800\n",
            "1700/1700 [==============================] - 1s 548us/step - loss: 1.2778 - accuracy: 0.4406 - val_loss: 1.4479 - val_accuracy: 0.3623\n",
            "Epoch 206/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2766 - accuracy: 0.4418 - val_loss: 1.4581 - val_accuracy: 0.3557\n",
            "Epoch 207/800\n",
            "1700/1700 [==============================] - 1s 564us/step - loss: 1.2767 - accuracy: 0.4413 - val_loss: 1.4466 - val_accuracy: 0.3632\n",
            "Epoch 208/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2753 - accuracy: 0.4415 - val_loss: 1.4500 - val_accuracy: 0.3691\n",
            "Epoch 209/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.2757 - accuracy: 0.4411 - val_loss: 1.4486 - val_accuracy: 0.3650\n",
            "Epoch 210/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2751 - accuracy: 0.4415 - val_loss: 1.4501 - val_accuracy: 0.3671\n",
            "Epoch 211/800\n",
            "1700/1700 [==============================] - 1s 551us/step - loss: 1.2749 - accuracy: 0.4416 - val_loss: 1.4523 - val_accuracy: 0.3582\n",
            "Epoch 212/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2743 - accuracy: 0.4413 - val_loss: 1.4519 - val_accuracy: 0.3675\n",
            "Epoch 213/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2742 - accuracy: 0.4421 - val_loss: 1.4520 - val_accuracy: 0.3604\n",
            "Epoch 214/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2742 - accuracy: 0.4412 - val_loss: 1.4503 - val_accuracy: 0.3649\n",
            "Epoch 215/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2734 - accuracy: 0.4421 - val_loss: 1.4493 - val_accuracy: 0.3633\n",
            "Epoch 216/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2740 - accuracy: 0.4409 - val_loss: 1.4500 - val_accuracy: 0.3604\n",
            "Epoch 217/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2725 - accuracy: 0.4437 - val_loss: 1.4499 - val_accuracy: 0.3699\n",
            "Epoch 218/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2728 - accuracy: 0.4439 - val_loss: 1.4499 - val_accuracy: 0.3677\n",
            "Epoch 219/800\n",
            "1700/1700 [==============================] - 1s 549us/step - loss: 1.2719 - accuracy: 0.4447 - val_loss: 1.4537 - val_accuracy: 0.3650\n",
            "Epoch 220/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2722 - accuracy: 0.4433 - val_loss: 1.4513 - val_accuracy: 0.3658\n",
            "Epoch 221/800\n",
            "1700/1700 [==============================] - 1s 536us/step - loss: 1.2714 - accuracy: 0.4436 - val_loss: 1.4521 - val_accuracy: 0.3642\n",
            "Epoch 222/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2712 - accuracy: 0.4440 - val_loss: 1.4544 - val_accuracy: 0.3639\n",
            "Epoch 223/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2702 - accuracy: 0.4444 - val_loss: 1.4511 - val_accuracy: 0.3640\n",
            "Epoch 224/800\n",
            "1700/1700 [==============================] - 1s 562us/step - loss: 1.2702 - accuracy: 0.4447 - val_loss: 1.4543 - val_accuracy: 0.3662\n",
            "Epoch 225/800\n",
            "1700/1700 [==============================] - 1s 547us/step - loss: 1.2703 - accuracy: 0.4435 - val_loss: 1.4543 - val_accuracy: 0.3669\n",
            "Epoch 226/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2695 - accuracy: 0.4430 - val_loss: 1.4527 - val_accuracy: 0.3654\n",
            "Epoch 227/800\n",
            "1700/1700 [==============================] - 1s 548us/step - loss: 1.2695 - accuracy: 0.4460 - val_loss: 1.4542 - val_accuracy: 0.3654\n",
            "Epoch 228/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2691 - accuracy: 0.4458 - val_loss: 1.4545 - val_accuracy: 0.3651\n",
            "Epoch 229/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2684 - accuracy: 0.4449 - val_loss: 1.4531 - val_accuracy: 0.3689\n",
            "Epoch 230/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2681 - accuracy: 0.4451 - val_loss: 1.4551 - val_accuracy: 0.3652\n",
            "Epoch 231/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2689 - accuracy: 0.4450 - val_loss: 1.4559 - val_accuracy: 0.3618\n",
            "Epoch 232/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2682 - accuracy: 0.4454 - val_loss: 1.4546 - val_accuracy: 0.3647\n",
            "Epoch 233/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2679 - accuracy: 0.4444 - val_loss: 1.4573 - val_accuracy: 0.3647\n",
            "Epoch 234/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2677 - accuracy: 0.4445 - val_loss: 1.4569 - val_accuracy: 0.3652\n",
            "Epoch 235/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2671 - accuracy: 0.4462 - val_loss: 1.4536 - val_accuracy: 0.3613\n",
            "Epoch 236/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2668 - accuracy: 0.4459 - val_loss: 1.4561 - val_accuracy: 0.3692\n",
            "Epoch 237/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.2664 - accuracy: 0.4451 - val_loss: 1.4551 - val_accuracy: 0.3626\n",
            "Epoch 238/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2659 - accuracy: 0.4462 - val_loss: 1.4562 - val_accuracy: 0.3681\n",
            "Epoch 239/800\n",
            "1700/1700 [==============================] - 1s 542us/step - loss: 1.2656 - accuracy: 0.4459 - val_loss: 1.4616 - val_accuracy: 0.3688\n",
            "Epoch 240/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2657 - accuracy: 0.4469 - val_loss: 1.4604 - val_accuracy: 0.3627\n",
            "Epoch 241/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2653 - accuracy: 0.4479 - val_loss: 1.4605 - val_accuracy: 0.3634\n",
            "Epoch 242/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2646 - accuracy: 0.4469 - val_loss: 1.4588 - val_accuracy: 0.3613\n",
            "Epoch 243/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2654 - accuracy: 0.4468 - val_loss: 1.4583 - val_accuracy: 0.3669\n",
            "Epoch 244/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2647 - accuracy: 0.4469 - val_loss: 1.4583 - val_accuracy: 0.3671\n",
            "Epoch 245/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2642 - accuracy: 0.4476 - val_loss: 1.4567 - val_accuracy: 0.3644\n",
            "Epoch 246/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2637 - accuracy: 0.4479 - val_loss: 1.4616 - val_accuracy: 0.3613\n",
            "Epoch 247/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.2633 - accuracy: 0.4473 - val_loss: 1.4606 - val_accuracy: 0.3696\n",
            "Epoch 248/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2630 - accuracy: 0.4482 - val_loss: 1.4586 - val_accuracy: 0.3661\n",
            "Epoch 249/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2632 - accuracy: 0.4479 - val_loss: 1.4626 - val_accuracy: 0.3618\n",
            "Epoch 250/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2628 - accuracy: 0.4477 - val_loss: 1.4607 - val_accuracy: 0.3605\n",
            "Epoch 251/800\n",
            "1700/1700 [==============================] - 1s 561us/step - loss: 1.2627 - accuracy: 0.4483 - val_loss: 1.4635 - val_accuracy: 0.3596\n",
            "Epoch 252/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2616 - accuracy: 0.4496 - val_loss: 1.4614 - val_accuracy: 0.3658\n",
            "Epoch 253/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2617 - accuracy: 0.4478 - val_loss: 1.4655 - val_accuracy: 0.3700\n",
            "Epoch 254/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2618 - accuracy: 0.4475 - val_loss: 1.4602 - val_accuracy: 0.3580\n",
            "Epoch 255/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2605 - accuracy: 0.4479 - val_loss: 1.4640 - val_accuracy: 0.3623\n",
            "Epoch 256/800\n",
            "1700/1700 [==============================] - 1s 542us/step - loss: 1.2612 - accuracy: 0.4488 - val_loss: 1.4630 - val_accuracy: 0.3645\n",
            "Epoch 257/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2603 - accuracy: 0.4491 - val_loss: 1.4626 - val_accuracy: 0.3663\n",
            "Epoch 258/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2608 - accuracy: 0.4486 - val_loss: 1.4595 - val_accuracy: 0.3679\n",
            "Epoch 259/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2603 - accuracy: 0.4501 - val_loss: 1.4644 - val_accuracy: 0.3668\n",
            "Epoch 260/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2594 - accuracy: 0.4495 - val_loss: 1.4666 - val_accuracy: 0.3648\n",
            "Epoch 261/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2600 - accuracy: 0.4498 - val_loss: 1.4658 - val_accuracy: 0.3627\n",
            "Epoch 262/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2590 - accuracy: 0.4513 - val_loss: 1.4647 - val_accuracy: 0.3668\n",
            "Epoch 263/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2590 - accuracy: 0.4493 - val_loss: 1.4634 - val_accuracy: 0.3658\n",
            "Epoch 264/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2587 - accuracy: 0.4505 - val_loss: 1.4692 - val_accuracy: 0.3585\n",
            "Epoch 265/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2587 - accuracy: 0.4492 - val_loss: 1.4663 - val_accuracy: 0.3658\n",
            "Epoch 266/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2579 - accuracy: 0.4503 - val_loss: 1.4694 - val_accuracy: 0.3699\n",
            "Epoch 267/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2582 - accuracy: 0.4522 - val_loss: 1.4704 - val_accuracy: 0.3670\n",
            "Epoch 268/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2576 - accuracy: 0.4499 - val_loss: 1.4681 - val_accuracy: 0.3646\n",
            "Epoch 269/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2574 - accuracy: 0.4501 - val_loss: 1.4682 - val_accuracy: 0.3588\n",
            "Epoch 270/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2570 - accuracy: 0.4503 - val_loss: 1.4628 - val_accuracy: 0.3632\n",
            "Epoch 271/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2566 - accuracy: 0.4498 - val_loss: 1.4715 - val_accuracy: 0.3637\n",
            "Epoch 272/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2562 - accuracy: 0.4509 - val_loss: 1.4671 - val_accuracy: 0.3613\n",
            "Epoch 273/800\n",
            "1700/1700 [==============================] - 1s 563us/step - loss: 1.2561 - accuracy: 0.4514 - val_loss: 1.4682 - val_accuracy: 0.3652\n",
            "Epoch 274/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2559 - accuracy: 0.4518 - val_loss: 1.4679 - val_accuracy: 0.3650\n",
            "Epoch 275/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2548 - accuracy: 0.4520 - val_loss: 1.4664 - val_accuracy: 0.3663\n",
            "Epoch 276/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2555 - accuracy: 0.4509 - val_loss: 1.4682 - val_accuracy: 0.3659\n",
            "Epoch 277/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2552 - accuracy: 0.4512 - val_loss: 1.4739 - val_accuracy: 0.3554\n",
            "Epoch 278/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2545 - accuracy: 0.4519 - val_loss: 1.4695 - val_accuracy: 0.3656\n",
            "Epoch 279/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2545 - accuracy: 0.4497 - val_loss: 1.4676 - val_accuracy: 0.3663\n",
            "Epoch 280/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2540 - accuracy: 0.4519 - val_loss: 1.4768 - val_accuracy: 0.3621\n",
            "Epoch 281/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2544 - accuracy: 0.4516 - val_loss: 1.4685 - val_accuracy: 0.3608\n",
            "Epoch 282/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2538 - accuracy: 0.4521 - val_loss: 1.4711 - val_accuracy: 0.3623\n",
            "Epoch 283/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2532 - accuracy: 0.4529 - val_loss: 1.4767 - val_accuracy: 0.3548\n",
            "Epoch 284/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2534 - accuracy: 0.4519 - val_loss: 1.4702 - val_accuracy: 0.3639\n",
            "Epoch 285/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2524 - accuracy: 0.4517 - val_loss: 1.4759 - val_accuracy: 0.3659\n",
            "Epoch 286/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.2523 - accuracy: 0.4535 - val_loss: 1.4697 - val_accuracy: 0.3675\n",
            "Epoch 287/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2531 - accuracy: 0.4519 - val_loss: 1.4705 - val_accuracy: 0.3634\n",
            "Epoch 288/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2526 - accuracy: 0.4515 - val_loss: 1.4714 - val_accuracy: 0.3627\n",
            "Epoch 289/800\n",
            "1700/1700 [==============================] - 1s 560us/step - loss: 1.2520 - accuracy: 0.4513 - val_loss: 1.4720 - val_accuracy: 0.3603\n",
            "Epoch 290/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2515 - accuracy: 0.4526 - val_loss: 1.4707 - val_accuracy: 0.3652\n",
            "Epoch 291/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2514 - accuracy: 0.4528 - val_loss: 1.4795 - val_accuracy: 0.3623\n",
            "Epoch 292/800\n",
            "1700/1700 [==============================] - 1s 551us/step - loss: 1.2514 - accuracy: 0.4530 - val_loss: 1.4727 - val_accuracy: 0.3672\n",
            "Epoch 293/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.2507 - accuracy: 0.4530 - val_loss: 1.4731 - val_accuracy: 0.3625\n",
            "Epoch 294/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2511 - accuracy: 0.4538 - val_loss: 1.4725 - val_accuracy: 0.3642\n",
            "Epoch 295/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2505 - accuracy: 0.4517 - val_loss: 1.4786 - val_accuracy: 0.3661\n",
            "Epoch 296/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2507 - accuracy: 0.4533 - val_loss: 1.4775 - val_accuracy: 0.3650\n",
            "Epoch 297/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2495 - accuracy: 0.4547 - val_loss: 1.4762 - val_accuracy: 0.3630\n",
            "Epoch 298/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2503 - accuracy: 0.4543 - val_loss: 1.4762 - val_accuracy: 0.3609\n",
            "Epoch 299/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2497 - accuracy: 0.4537 - val_loss: 1.4759 - val_accuracy: 0.3652\n",
            "Epoch 300/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2495 - accuracy: 0.4543 - val_loss: 1.4759 - val_accuracy: 0.3612\n",
            "Epoch 301/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2488 - accuracy: 0.4550 - val_loss: 1.4737 - val_accuracy: 0.3680\n",
            "Epoch 302/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2491 - accuracy: 0.4552 - val_loss: 1.4781 - val_accuracy: 0.3681\n",
            "Epoch 303/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2482 - accuracy: 0.4543 - val_loss: 1.4801 - val_accuracy: 0.3662\n",
            "Epoch 304/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2486 - accuracy: 0.4541 - val_loss: 1.4777 - val_accuracy: 0.3697\n",
            "Epoch 305/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2478 - accuracy: 0.4528 - val_loss: 1.4750 - val_accuracy: 0.3615\n",
            "Epoch 306/800\n",
            "1700/1700 [==============================] - 1s 560us/step - loss: 1.2479 - accuracy: 0.4557 - val_loss: 1.4778 - val_accuracy: 0.3632\n",
            "Epoch 307/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.2479 - accuracy: 0.4545 - val_loss: 1.4773 - val_accuracy: 0.3620\n",
            "Epoch 308/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2475 - accuracy: 0.4546 - val_loss: 1.4796 - val_accuracy: 0.3605\n",
            "Epoch 309/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2475 - accuracy: 0.4548 - val_loss: 1.4778 - val_accuracy: 0.3618\n",
            "Epoch 310/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2468 - accuracy: 0.4565 - val_loss: 1.4799 - val_accuracy: 0.3657\n",
            "Epoch 311/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2465 - accuracy: 0.4554 - val_loss: 1.4787 - val_accuracy: 0.3632\n",
            "Epoch 312/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2463 - accuracy: 0.4559 - val_loss: 1.4742 - val_accuracy: 0.3664\n",
            "Epoch 313/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2466 - accuracy: 0.4559 - val_loss: 1.4784 - val_accuracy: 0.3641\n",
            "Epoch 314/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.2462 - accuracy: 0.4545 - val_loss: 1.4772 - val_accuracy: 0.3728\n",
            "Epoch 315/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2457 - accuracy: 0.4571 - val_loss: 1.4824 - val_accuracy: 0.3621\n",
            "Epoch 316/800\n",
            "1700/1700 [==============================] - 1s 561us/step - loss: 1.2456 - accuracy: 0.4563 - val_loss: 1.4751 - val_accuracy: 0.3750\n",
            "Epoch 317/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2457 - accuracy: 0.4552 - val_loss: 1.4812 - val_accuracy: 0.3618\n",
            "Epoch 318/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2450 - accuracy: 0.4564 - val_loss: 1.4851 - val_accuracy: 0.3639\n",
            "Epoch 319/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2449 - accuracy: 0.4556 - val_loss: 1.4795 - val_accuracy: 0.3631\n",
            "Epoch 320/800\n",
            "1700/1700 [==============================] - 1s 549us/step - loss: 1.2444 - accuracy: 0.4568 - val_loss: 1.4889 - val_accuracy: 0.3581\n",
            "Epoch 321/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2440 - accuracy: 0.4563 - val_loss: 1.4810 - val_accuracy: 0.3638\n",
            "Epoch 322/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2437 - accuracy: 0.4577 - val_loss: 1.4798 - val_accuracy: 0.3618\n",
            "Epoch 323/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2434 - accuracy: 0.4583 - val_loss: 1.4778 - val_accuracy: 0.3628\n",
            "Epoch 324/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.2444 - accuracy: 0.4559 - val_loss: 1.4770 - val_accuracy: 0.3677\n",
            "Epoch 325/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2433 - accuracy: 0.4572 - val_loss: 1.4827 - val_accuracy: 0.3636\n",
            "Epoch 326/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2429 - accuracy: 0.4570 - val_loss: 1.4870 - val_accuracy: 0.3652\n",
            "Epoch 327/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2433 - accuracy: 0.4560 - val_loss: 1.4814 - val_accuracy: 0.3631\n",
            "Epoch 328/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2427 - accuracy: 0.4580 - val_loss: 1.4840 - val_accuracy: 0.3668\n",
            "Epoch 329/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2425 - accuracy: 0.4585 - val_loss: 1.4832 - val_accuracy: 0.3602\n",
            "Epoch 330/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2427 - accuracy: 0.4568 - val_loss: 1.4874 - val_accuracy: 0.3622\n",
            "Epoch 331/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2423 - accuracy: 0.4583 - val_loss: 1.4819 - val_accuracy: 0.3660\n",
            "Epoch 332/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2420 - accuracy: 0.4582 - val_loss: 1.4851 - val_accuracy: 0.3689\n",
            "Epoch 333/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2418 - accuracy: 0.4573 - val_loss: 1.4816 - val_accuracy: 0.3669\n",
            "Epoch 334/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2417 - accuracy: 0.4585 - val_loss: 1.4817 - val_accuracy: 0.3668\n",
            "Epoch 335/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2415 - accuracy: 0.4581 - val_loss: 1.4927 - val_accuracy: 0.3631\n",
            "Epoch 336/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2410 - accuracy: 0.4577 - val_loss: 1.4834 - val_accuracy: 0.3677\n",
            "Epoch 337/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2404 - accuracy: 0.4585 - val_loss: 1.4849 - val_accuracy: 0.3591\n",
            "Epoch 338/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2409 - accuracy: 0.4569 - val_loss: 1.4883 - val_accuracy: 0.3654\n",
            "Epoch 339/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2397 - accuracy: 0.4575 - val_loss: 1.4928 - val_accuracy: 0.3658\n",
            "Epoch 340/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2405 - accuracy: 0.4579 - val_loss: 1.4855 - val_accuracy: 0.3607\n",
            "Epoch 341/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2400 - accuracy: 0.4586 - val_loss: 1.4886 - val_accuracy: 0.3622\n",
            "Epoch 342/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2396 - accuracy: 0.4581 - val_loss: 1.4838 - val_accuracy: 0.3652\n",
            "Epoch 343/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.2391 - accuracy: 0.4595 - val_loss: 1.4860 - val_accuracy: 0.3677\n",
            "Epoch 344/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2395 - accuracy: 0.4574 - val_loss: 1.4935 - val_accuracy: 0.3627\n",
            "Epoch 345/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2384 - accuracy: 0.4582 - val_loss: 1.4879 - val_accuracy: 0.3638\n",
            "Epoch 346/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2389 - accuracy: 0.4586 - val_loss: 1.4872 - val_accuracy: 0.3647\n",
            "Epoch 347/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2384 - accuracy: 0.4575 - val_loss: 1.4871 - val_accuracy: 0.3596\n",
            "Epoch 348/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2383 - accuracy: 0.4577 - val_loss: 1.4837 - val_accuracy: 0.3669\n",
            "Epoch 349/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2382 - accuracy: 0.4593 - val_loss: 1.4861 - val_accuracy: 0.3658\n",
            "Epoch 350/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2383 - accuracy: 0.4602 - val_loss: 1.4902 - val_accuracy: 0.3562\n",
            "Epoch 351/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2379 - accuracy: 0.4585 - val_loss: 1.4816 - val_accuracy: 0.3706\n",
            "Epoch 352/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.2369 - accuracy: 0.4609 - val_loss: 1.4908 - val_accuracy: 0.3652\n",
            "Epoch 353/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2376 - accuracy: 0.4592 - val_loss: 1.4873 - val_accuracy: 0.3680\n",
            "Epoch 354/800\n",
            "1700/1700 [==============================] - 1s 549us/step - loss: 1.2369 - accuracy: 0.4606 - val_loss: 1.4852 - val_accuracy: 0.3647\n",
            "Epoch 355/800\n",
            "1700/1700 [==============================] - 1s 547us/step - loss: 1.2377 - accuracy: 0.4585 - val_loss: 1.4877 - val_accuracy: 0.3632\n",
            "Epoch 356/800\n",
            "1700/1700 [==============================] - 1s 542us/step - loss: 1.2367 - accuracy: 0.4598 - val_loss: 1.4844 - val_accuracy: 0.3662\n",
            "Epoch 357/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2362 - accuracy: 0.4611 - val_loss: 1.4875 - val_accuracy: 0.3666\n",
            "Epoch 358/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2359 - accuracy: 0.4610 - val_loss: 1.4941 - val_accuracy: 0.3659\n",
            "Epoch 359/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2363 - accuracy: 0.4600 - val_loss: 1.4894 - val_accuracy: 0.3618\n",
            "Epoch 360/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.2357 - accuracy: 0.4597 - val_loss: 1.4915 - val_accuracy: 0.3657\n",
            "Epoch 361/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2355 - accuracy: 0.4614 - val_loss: 1.4916 - val_accuracy: 0.3653\n",
            "Epoch 362/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2357 - accuracy: 0.4606 - val_loss: 1.4958 - val_accuracy: 0.3594\n",
            "Epoch 363/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2351 - accuracy: 0.4609 - val_loss: 1.4879 - val_accuracy: 0.3698\n",
            "Epoch 364/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2351 - accuracy: 0.4585 - val_loss: 1.4893 - val_accuracy: 0.3668\n",
            "Epoch 365/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2348 - accuracy: 0.4621 - val_loss: 1.4899 - val_accuracy: 0.3612\n",
            "Epoch 366/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2346 - accuracy: 0.4606 - val_loss: 1.4908 - val_accuracy: 0.3646\n",
            "Epoch 367/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2345 - accuracy: 0.4617 - val_loss: 1.4895 - val_accuracy: 0.3651\n",
            "Epoch 368/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2340 - accuracy: 0.4608 - val_loss: 1.4876 - val_accuracy: 0.3660\n",
            "Epoch 369/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2341 - accuracy: 0.4611 - val_loss: 1.4903 - val_accuracy: 0.3669\n",
            "Epoch 370/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2338 - accuracy: 0.4607 - val_loss: 1.4955 - val_accuracy: 0.3638\n",
            "Epoch 371/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2336 - accuracy: 0.4628 - val_loss: 1.4910 - val_accuracy: 0.3623\n",
            "Epoch 372/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2335 - accuracy: 0.4613 - val_loss: 1.4961 - val_accuracy: 0.3547\n",
            "Epoch 373/800\n",
            "1700/1700 [==============================] - 1s 545us/step - loss: 1.2330 - accuracy: 0.4608 - val_loss: 1.4932 - val_accuracy: 0.3619\n",
            "Epoch 374/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2332 - accuracy: 0.4625 - val_loss: 1.4938 - val_accuracy: 0.3627\n",
            "Epoch 375/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2324 - accuracy: 0.4613 - val_loss: 1.4935 - val_accuracy: 0.3693\n",
            "Epoch 376/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.2324 - accuracy: 0.4621 - val_loss: 1.4954 - val_accuracy: 0.3616\n",
            "Epoch 377/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2326 - accuracy: 0.4621 - val_loss: 1.4939 - val_accuracy: 0.3634\n",
            "Epoch 378/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2323 - accuracy: 0.4608 - val_loss: 1.4974 - val_accuracy: 0.3557\n",
            "Epoch 379/800\n",
            "1700/1700 [==============================] - 1s 579us/step - loss: 1.2319 - accuracy: 0.4621 - val_loss: 1.4908 - val_accuracy: 0.3658\n",
            "Epoch 380/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2314 - accuracy: 0.4610 - val_loss: 1.4968 - val_accuracy: 0.3657\n",
            "Epoch 381/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2315 - accuracy: 0.4614 - val_loss: 1.4940 - val_accuracy: 0.3683\n",
            "Epoch 382/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2317 - accuracy: 0.4622 - val_loss: 1.4950 - val_accuracy: 0.3623\n",
            "Epoch 383/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2312 - accuracy: 0.4637 - val_loss: 1.4940 - val_accuracy: 0.3634\n",
            "Epoch 384/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2312 - accuracy: 0.4616 - val_loss: 1.4954 - val_accuracy: 0.3652\n",
            "Epoch 385/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2313 - accuracy: 0.4633 - val_loss: 1.4960 - val_accuracy: 0.3613\n",
            "Epoch 386/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2308 - accuracy: 0.4620 - val_loss: 1.4969 - val_accuracy: 0.3660\n",
            "Epoch 387/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2309 - accuracy: 0.4628 - val_loss: 1.4964 - val_accuracy: 0.3628\n",
            "Epoch 388/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2303 - accuracy: 0.4641 - val_loss: 1.4972 - val_accuracy: 0.3616\n",
            "Epoch 389/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2304 - accuracy: 0.4618 - val_loss: 1.5025 - val_accuracy: 0.3582\n",
            "Epoch 390/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.2300 - accuracy: 0.4618 - val_loss: 1.4977 - val_accuracy: 0.3676\n",
            "Epoch 391/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2306 - accuracy: 0.4612 - val_loss: 1.4974 - val_accuracy: 0.3698\n",
            "Epoch 392/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2294 - accuracy: 0.4636 - val_loss: 1.4991 - val_accuracy: 0.3647\n",
            "Epoch 393/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2291 - accuracy: 0.4635 - val_loss: 1.4970 - val_accuracy: 0.3641\n",
            "Epoch 394/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2291 - accuracy: 0.4649 - val_loss: 1.4991 - val_accuracy: 0.3670\n",
            "Epoch 395/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2290 - accuracy: 0.4641 - val_loss: 1.4960 - val_accuracy: 0.3677\n",
            "Epoch 396/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2289 - accuracy: 0.4634 - val_loss: 1.4958 - val_accuracy: 0.3658\n",
            "Epoch 397/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2286 - accuracy: 0.4654 - val_loss: 1.5034 - val_accuracy: 0.3621\n",
            "Epoch 398/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2285 - accuracy: 0.4641 - val_loss: 1.4960 - val_accuracy: 0.3640\n",
            "Epoch 399/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2285 - accuracy: 0.4617 - val_loss: 1.5012 - val_accuracy: 0.3619\n",
            "Epoch 400/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2282 - accuracy: 0.4640 - val_loss: 1.5026 - val_accuracy: 0.3680\n",
            "Epoch 401/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2279 - accuracy: 0.4639 - val_loss: 1.5001 - val_accuracy: 0.3664\n",
            "Epoch 402/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2278 - accuracy: 0.4644 - val_loss: 1.5000 - val_accuracy: 0.3653\n",
            "Epoch 403/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2273 - accuracy: 0.4654 - val_loss: 1.5036 - val_accuracy: 0.3679\n",
            "Epoch 404/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2270 - accuracy: 0.4656 - val_loss: 1.5001 - val_accuracy: 0.3678\n",
            "Epoch 405/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2273 - accuracy: 0.4644 - val_loss: 1.5036 - val_accuracy: 0.3668\n",
            "Epoch 406/800\n",
            "1700/1700 [==============================] - 1s 564us/step - loss: 1.2271 - accuracy: 0.4647 - val_loss: 1.5005 - val_accuracy: 0.3658\n",
            "Epoch 407/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2274 - accuracy: 0.4626 - val_loss: 1.5041 - val_accuracy: 0.3620\n",
            "Epoch 408/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.2272 - accuracy: 0.4657 - val_loss: 1.5033 - val_accuracy: 0.3650\n",
            "Epoch 409/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2268 - accuracy: 0.4666 - val_loss: 1.5003 - val_accuracy: 0.3612\n",
            "Epoch 410/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2261 - accuracy: 0.4663 - val_loss: 1.4997 - val_accuracy: 0.3629\n",
            "Epoch 411/800\n",
            "1700/1700 [==============================] - 1s 561us/step - loss: 1.2268 - accuracy: 0.4662 - val_loss: 1.4995 - val_accuracy: 0.3691\n",
            "Epoch 412/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2258 - accuracy: 0.4645 - val_loss: 1.5046 - val_accuracy: 0.3638\n",
            "Epoch 413/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2261 - accuracy: 0.4654 - val_loss: 1.4985 - val_accuracy: 0.3683\n",
            "Epoch 414/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2258 - accuracy: 0.4644 - val_loss: 1.5050 - val_accuracy: 0.3630\n",
            "Epoch 415/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2255 - accuracy: 0.4645 - val_loss: 1.5101 - val_accuracy: 0.3602\n",
            "Epoch 416/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2255 - accuracy: 0.4651 - val_loss: 1.5022 - val_accuracy: 0.3707\n",
            "Epoch 417/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2249 - accuracy: 0.4675 - val_loss: 1.5086 - val_accuracy: 0.3639\n",
            "Epoch 418/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2252 - accuracy: 0.4645 - val_loss: 1.5019 - val_accuracy: 0.3690\n",
            "Epoch 419/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2242 - accuracy: 0.4662 - val_loss: 1.5112 - val_accuracy: 0.3669\n",
            "Epoch 420/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2247 - accuracy: 0.4657 - val_loss: 1.5043 - val_accuracy: 0.3644\n",
            "Epoch 421/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2245 - accuracy: 0.4655 - val_loss: 1.5062 - val_accuracy: 0.3607\n",
            "Epoch 422/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2241 - accuracy: 0.4667 - val_loss: 1.5111 - val_accuracy: 0.3643\n",
            "Epoch 423/800\n",
            "1700/1700 [==============================] - 1s 563us/step - loss: 1.2237 - accuracy: 0.4668 - val_loss: 1.5076 - val_accuracy: 0.3661\n",
            "Epoch 424/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2238 - accuracy: 0.4680 - val_loss: 1.5094 - val_accuracy: 0.3626\n",
            "Epoch 425/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2245 - accuracy: 0.4668 - val_loss: 1.5047 - val_accuracy: 0.3605\n",
            "Epoch 426/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2236 - accuracy: 0.4675 - val_loss: 1.5102 - val_accuracy: 0.3628\n",
            "Epoch 427/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2233 - accuracy: 0.4672 - val_loss: 1.5007 - val_accuracy: 0.3638\n",
            "Epoch 428/800\n",
            "1700/1700 [==============================] - 1s 564us/step - loss: 1.2229 - accuracy: 0.4667 - val_loss: 1.5056 - val_accuracy: 0.3679\n",
            "Epoch 429/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2228 - accuracy: 0.4673 - val_loss: 1.5060 - val_accuracy: 0.3641\n",
            "Epoch 430/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2231 - accuracy: 0.4650 - val_loss: 1.5034 - val_accuracy: 0.3655\n",
            "Epoch 431/800\n",
            "1700/1700 [==============================] - 1s 550us/step - loss: 1.2227 - accuracy: 0.4669 - val_loss: 1.5055 - val_accuracy: 0.3722\n",
            "Epoch 432/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2222 - accuracy: 0.4679 - val_loss: 1.5133 - val_accuracy: 0.3588\n",
            "Epoch 433/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2222 - accuracy: 0.4670 - val_loss: 1.5082 - val_accuracy: 0.3678\n",
            "Epoch 434/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2216 - accuracy: 0.4670 - val_loss: 1.5095 - val_accuracy: 0.3656\n",
            "Epoch 435/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2221 - accuracy: 0.4687 - val_loss: 1.5084 - val_accuracy: 0.3659\n",
            "Epoch 436/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2224 - accuracy: 0.4656 - val_loss: 1.5160 - val_accuracy: 0.3593\n",
            "Epoch 437/800\n",
            "1700/1700 [==============================] - 1s 549us/step - loss: 1.2216 - accuracy: 0.4675 - val_loss: 1.5127 - val_accuracy: 0.3646\n",
            "Epoch 438/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2211 - accuracy: 0.4670 - val_loss: 1.5159 - val_accuracy: 0.3623\n",
            "Epoch 439/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2214 - accuracy: 0.4688 - val_loss: 1.5098 - val_accuracy: 0.3649\n",
            "Epoch 440/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2208 - accuracy: 0.4677 - val_loss: 1.5101 - val_accuracy: 0.3643\n",
            "Epoch 441/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2208 - accuracy: 0.4688 - val_loss: 1.5059 - val_accuracy: 0.3693\n",
            "Epoch 442/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2202 - accuracy: 0.4670 - val_loss: 1.5088 - val_accuracy: 0.3697\n",
            "Epoch 443/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.2205 - accuracy: 0.4690 - val_loss: 1.5102 - val_accuracy: 0.3613\n",
            "Epoch 444/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2202 - accuracy: 0.4690 - val_loss: 1.5101 - val_accuracy: 0.3614\n",
            "Epoch 445/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2202 - accuracy: 0.4685 - val_loss: 1.5159 - val_accuracy: 0.3562\n",
            "Epoch 446/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2200 - accuracy: 0.4673 - val_loss: 1.5105 - val_accuracy: 0.3662\n",
            "Epoch 447/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2203 - accuracy: 0.4674 - val_loss: 1.5225 - val_accuracy: 0.3549\n",
            "Epoch 448/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2199 - accuracy: 0.4687 - val_loss: 1.5177 - val_accuracy: 0.3613\n",
            "Epoch 449/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2191 - accuracy: 0.4681 - val_loss: 1.5122 - val_accuracy: 0.3691\n",
            "Epoch 450/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2189 - accuracy: 0.4684 - val_loss: 1.5137 - val_accuracy: 0.3647\n",
            "Epoch 451/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2188 - accuracy: 0.4675 - val_loss: 1.5210 - val_accuracy: 0.3557\n",
            "Epoch 452/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2192 - accuracy: 0.4674 - val_loss: 1.5100 - val_accuracy: 0.3641\n",
            "Epoch 453/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2184 - accuracy: 0.4699 - val_loss: 1.5132 - val_accuracy: 0.3698\n",
            "Epoch 454/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2183 - accuracy: 0.4690 - val_loss: 1.5182 - val_accuracy: 0.3618\n",
            "Epoch 455/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2186 - accuracy: 0.4683 - val_loss: 1.5114 - val_accuracy: 0.3651\n",
            "Epoch 456/800\n",
            "1700/1700 [==============================] - 1s 584us/step - loss: 1.2184 - accuracy: 0.4685 - val_loss: 1.5164 - val_accuracy: 0.3585\n",
            "Epoch 457/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2180 - accuracy: 0.4665 - val_loss: 1.5102 - val_accuracy: 0.3657\n",
            "Epoch 458/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2185 - accuracy: 0.4688 - val_loss: 1.5132 - val_accuracy: 0.3598\n",
            "Epoch 459/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2180 - accuracy: 0.4705 - val_loss: 1.5167 - val_accuracy: 0.3599\n",
            "Epoch 460/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2180 - accuracy: 0.4693 - val_loss: 1.5161 - val_accuracy: 0.3653\n",
            "Epoch 461/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2175 - accuracy: 0.4710 - val_loss: 1.5124 - val_accuracy: 0.3644\n",
            "Epoch 462/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2170 - accuracy: 0.4678 - val_loss: 1.5170 - val_accuracy: 0.3649\n",
            "Epoch 463/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2175 - accuracy: 0.4694 - val_loss: 1.5157 - val_accuracy: 0.3574\n",
            "Epoch 464/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2176 - accuracy: 0.4679 - val_loss: 1.5187 - val_accuracy: 0.3587\n",
            "Epoch 465/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.2168 - accuracy: 0.4699 - val_loss: 1.5144 - val_accuracy: 0.3672\n",
            "Epoch 466/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2168 - accuracy: 0.4681 - val_loss: 1.5181 - val_accuracy: 0.3679\n",
            "Epoch 467/800\n",
            "1700/1700 [==============================] - 1s 579us/step - loss: 1.2165 - accuracy: 0.4684 - val_loss: 1.5243 - val_accuracy: 0.3606\n",
            "Epoch 468/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2165 - accuracy: 0.4701 - val_loss: 1.5287 - val_accuracy: 0.3503\n",
            "Epoch 469/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2165 - accuracy: 0.4704 - val_loss: 1.5201 - val_accuracy: 0.3619\n",
            "Epoch 470/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2156 - accuracy: 0.4690 - val_loss: 1.5179 - val_accuracy: 0.3692\n",
            "Epoch 471/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2160 - accuracy: 0.4688 - val_loss: 1.5173 - val_accuracy: 0.3609\n",
            "Epoch 472/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2154 - accuracy: 0.4703 - val_loss: 1.5188 - val_accuracy: 0.3668\n",
            "Epoch 473/800\n",
            "1700/1700 [==============================] - 1s 588us/step - loss: 1.2145 - accuracy: 0.4704 - val_loss: 1.5153 - val_accuracy: 0.3679\n",
            "Epoch 474/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2147 - accuracy: 0.4711 - val_loss: 1.5185 - val_accuracy: 0.3660\n",
            "Epoch 475/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2151 - accuracy: 0.4704 - val_loss: 1.5188 - val_accuracy: 0.3638\n",
            "Epoch 476/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2155 - accuracy: 0.4687 - val_loss: 1.5194 - val_accuracy: 0.3681\n",
            "Epoch 477/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2151 - accuracy: 0.4691 - val_loss: 1.5215 - val_accuracy: 0.3624\n",
            "Epoch 478/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2149 - accuracy: 0.4700 - val_loss: 1.5233 - val_accuracy: 0.3689\n",
            "Epoch 479/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2146 - accuracy: 0.4698 - val_loss: 1.5186 - val_accuracy: 0.3673\n",
            "Epoch 480/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2143 - accuracy: 0.4717 - val_loss: 1.5189 - val_accuracy: 0.3680\n",
            "Epoch 481/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2139 - accuracy: 0.4706 - val_loss: 1.5184 - val_accuracy: 0.3577\n",
            "Epoch 482/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2142 - accuracy: 0.4697 - val_loss: 1.5222 - val_accuracy: 0.3600\n",
            "Epoch 483/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2141 - accuracy: 0.4704 - val_loss: 1.5186 - val_accuracy: 0.3688\n",
            "Epoch 484/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2135 - accuracy: 0.4715 - val_loss: 1.5200 - val_accuracy: 0.3629\n",
            "Epoch 485/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2132 - accuracy: 0.4706 - val_loss: 1.5205 - val_accuracy: 0.3596\n",
            "Epoch 486/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2133 - accuracy: 0.4704 - val_loss: 1.5231 - val_accuracy: 0.3592\n",
            "Epoch 487/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.2135 - accuracy: 0.4732 - val_loss: 1.5191 - val_accuracy: 0.3663\n",
            "Epoch 488/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2127 - accuracy: 0.4705 - val_loss: 1.5190 - val_accuracy: 0.3573\n",
            "Epoch 489/800\n",
            "1700/1700 [==============================] - 1s 583us/step - loss: 1.2132 - accuracy: 0.4698 - val_loss: 1.5260 - val_accuracy: 0.3615\n",
            "Epoch 490/800\n",
            "1700/1700 [==============================] - 1s 562us/step - loss: 1.2132 - accuracy: 0.4708 - val_loss: 1.5210 - val_accuracy: 0.3692\n",
            "Epoch 491/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2136 - accuracy: 0.4695 - val_loss: 1.5219 - val_accuracy: 0.3641\n",
            "Epoch 492/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2122 - accuracy: 0.4709 - val_loss: 1.5242 - val_accuracy: 0.3659\n",
            "Epoch 493/800\n",
            "1700/1700 [==============================] - 1s 563us/step - loss: 1.2125 - accuracy: 0.4724 - val_loss: 1.5240 - val_accuracy: 0.3643\n",
            "Epoch 494/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2125 - accuracy: 0.4719 - val_loss: 1.5248 - val_accuracy: 0.3667\n",
            "Epoch 495/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2125 - accuracy: 0.4707 - val_loss: 1.5201 - val_accuracy: 0.3677\n",
            "Epoch 496/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2120 - accuracy: 0.4727 - val_loss: 1.5209 - val_accuracy: 0.3668\n",
            "Epoch 497/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2118 - accuracy: 0.4708 - val_loss: 1.5189 - val_accuracy: 0.3723\n",
            "Epoch 498/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2120 - accuracy: 0.4719 - val_loss: 1.5252 - val_accuracy: 0.3607\n",
            "Epoch 499/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2114 - accuracy: 0.4730 - val_loss: 1.5229 - val_accuracy: 0.3662\n",
            "Epoch 500/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2115 - accuracy: 0.4717 - val_loss: 1.5234 - val_accuracy: 0.3649\n",
            "Epoch 501/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2108 - accuracy: 0.4722 - val_loss: 1.5246 - val_accuracy: 0.3618\n",
            "Epoch 502/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2110 - accuracy: 0.4717 - val_loss: 1.5271 - val_accuracy: 0.3629\n",
            "Epoch 503/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2107 - accuracy: 0.4734 - val_loss: 1.5251 - val_accuracy: 0.3587\n",
            "Epoch 504/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.2105 - accuracy: 0.4731 - val_loss: 1.5247 - val_accuracy: 0.3607\n",
            "Epoch 505/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2100 - accuracy: 0.4722 - val_loss: 1.5239 - val_accuracy: 0.3722\n",
            "Epoch 506/800\n",
            "1700/1700 [==============================] - 1s 586us/step - loss: 1.2100 - accuracy: 0.4733 - val_loss: 1.5246 - val_accuracy: 0.3659\n",
            "Epoch 507/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2095 - accuracy: 0.4743 - val_loss: 1.5261 - val_accuracy: 0.3621\n",
            "Epoch 508/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2102 - accuracy: 0.4736 - val_loss: 1.5231 - val_accuracy: 0.3671\n",
            "Epoch 509/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2097 - accuracy: 0.4718 - val_loss: 1.5261 - val_accuracy: 0.3603\n",
            "Epoch 510/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2103 - accuracy: 0.4732 - val_loss: 1.5254 - val_accuracy: 0.3610\n",
            "Epoch 511/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2099 - accuracy: 0.4720 - val_loss: 1.5287 - val_accuracy: 0.3625\n",
            "Epoch 512/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2099 - accuracy: 0.4718 - val_loss: 1.5263 - val_accuracy: 0.3596\n",
            "Epoch 513/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2096 - accuracy: 0.4733 - val_loss: 1.5281 - val_accuracy: 0.3628\n",
            "Epoch 514/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2088 - accuracy: 0.4750 - val_loss: 1.5293 - val_accuracy: 0.3640\n",
            "Epoch 515/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2101 - accuracy: 0.4717 - val_loss: 1.5275 - val_accuracy: 0.3670\n",
            "Epoch 516/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2092 - accuracy: 0.4733 - val_loss: 1.5284 - val_accuracy: 0.3638\n",
            "Epoch 517/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2092 - accuracy: 0.4735 - val_loss: 1.5257 - val_accuracy: 0.3598\n",
            "Epoch 518/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2090 - accuracy: 0.4732 - val_loss: 1.5254 - val_accuracy: 0.3653\n",
            "Epoch 519/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2089 - accuracy: 0.4712 - val_loss: 1.5317 - val_accuracy: 0.3666\n",
            "Epoch 520/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2086 - accuracy: 0.4743 - val_loss: 1.5255 - val_accuracy: 0.3668\n",
            "Epoch 521/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2086 - accuracy: 0.4725 - val_loss: 1.5304 - val_accuracy: 0.3593\n",
            "Epoch 522/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2087 - accuracy: 0.4724 - val_loss: 1.5263 - val_accuracy: 0.3683\n",
            "Epoch 523/800\n",
            "1700/1700 [==============================] - 1s 581us/step - loss: 1.2082 - accuracy: 0.4738 - val_loss: 1.5358 - val_accuracy: 0.3675\n",
            "Epoch 524/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.2081 - accuracy: 0.4743 - val_loss: 1.5267 - val_accuracy: 0.3688\n",
            "Epoch 525/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2081 - accuracy: 0.4728 - val_loss: 1.5288 - val_accuracy: 0.3632\n",
            "Epoch 526/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.2080 - accuracy: 0.4738 - val_loss: 1.5271 - val_accuracy: 0.3643\n",
            "Epoch 527/800\n",
            "1700/1700 [==============================] - 1s 577us/step - loss: 1.2078 - accuracy: 0.4741 - val_loss: 1.5232 - val_accuracy: 0.3681\n",
            "Epoch 528/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2071 - accuracy: 0.4740 - val_loss: 1.5305 - val_accuracy: 0.3657\n",
            "Epoch 529/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2073 - accuracy: 0.4740 - val_loss: 1.5303 - val_accuracy: 0.3626\n",
            "Epoch 530/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2073 - accuracy: 0.4753 - val_loss: 1.5303 - val_accuracy: 0.3626\n",
            "Epoch 531/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2075 - accuracy: 0.4721 - val_loss: 1.5334 - val_accuracy: 0.3577\n",
            "Epoch 532/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2065 - accuracy: 0.4739 - val_loss: 1.5322 - val_accuracy: 0.3663\n",
            "Epoch 533/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2070 - accuracy: 0.4739 - val_loss: 1.5296 - val_accuracy: 0.3611\n",
            "Epoch 534/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2075 - accuracy: 0.4738 - val_loss: 1.5363 - val_accuracy: 0.3658\n",
            "Epoch 535/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2060 - accuracy: 0.4735 - val_loss: 1.5320 - val_accuracy: 0.3629\n",
            "Epoch 536/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2064 - accuracy: 0.4744 - val_loss: 1.5308 - val_accuracy: 0.3627\n",
            "Epoch 537/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2063 - accuracy: 0.4733 - val_loss: 1.5305 - val_accuracy: 0.3591\n",
            "Epoch 538/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2061 - accuracy: 0.4746 - val_loss: 1.5320 - val_accuracy: 0.3613\n",
            "Epoch 539/800\n",
            "1700/1700 [==============================] - 1s 583us/step - loss: 1.2061 - accuracy: 0.4723 - val_loss: 1.5373 - val_accuracy: 0.3737\n",
            "Epoch 540/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2054 - accuracy: 0.4748 - val_loss: 1.5376 - val_accuracy: 0.3559\n",
            "Epoch 541/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.2055 - accuracy: 0.4735 - val_loss: 1.5331 - val_accuracy: 0.3661\n",
            "Epoch 542/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2055 - accuracy: 0.4731 - val_loss: 1.5333 - val_accuracy: 0.3623\n",
            "Epoch 543/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2050 - accuracy: 0.4750 - val_loss: 1.5346 - val_accuracy: 0.3642\n",
            "Epoch 544/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2052 - accuracy: 0.4750 - val_loss: 1.5372 - val_accuracy: 0.3631\n",
            "Epoch 545/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2053 - accuracy: 0.4741 - val_loss: 1.5360 - val_accuracy: 0.3693\n",
            "Epoch 546/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2046 - accuracy: 0.4752 - val_loss: 1.5355 - val_accuracy: 0.3704\n",
            "Epoch 547/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2050 - accuracy: 0.4744 - val_loss: 1.5342 - val_accuracy: 0.3631\n",
            "Epoch 548/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2050 - accuracy: 0.4757 - val_loss: 1.5381 - val_accuracy: 0.3613\n",
            "Epoch 549/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2051 - accuracy: 0.4738 - val_loss: 1.5308 - val_accuracy: 0.3622\n",
            "Epoch 550/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2040 - accuracy: 0.4753 - val_loss: 1.5353 - val_accuracy: 0.3534\n",
            "Epoch 551/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2047 - accuracy: 0.4763 - val_loss: 1.5390 - val_accuracy: 0.3648\n",
            "Epoch 552/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2042 - accuracy: 0.4757 - val_loss: 1.5382 - val_accuracy: 0.3613\n",
            "Epoch 553/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2045 - accuracy: 0.4758 - val_loss: 1.5417 - val_accuracy: 0.3555\n",
            "Epoch 554/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2041 - accuracy: 0.4743 - val_loss: 1.5338 - val_accuracy: 0.3660\n",
            "Epoch 555/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.2043 - accuracy: 0.4751 - val_loss: 1.5330 - val_accuracy: 0.3683\n",
            "Epoch 556/800\n",
            "1700/1700 [==============================] - 1s 562us/step - loss: 1.2037 - accuracy: 0.4757 - val_loss: 1.5410 - val_accuracy: 0.3661\n",
            "Epoch 557/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2035 - accuracy: 0.4768 - val_loss: 1.5360 - val_accuracy: 0.3673\n",
            "Epoch 558/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2039 - accuracy: 0.4738 - val_loss: 1.5415 - val_accuracy: 0.3643\n",
            "Epoch 559/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2033 - accuracy: 0.4757 - val_loss: 1.5454 - val_accuracy: 0.3692\n",
            "Epoch 560/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2034 - accuracy: 0.4748 - val_loss: 1.5365 - val_accuracy: 0.3618\n",
            "Epoch 561/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2031 - accuracy: 0.4766 - val_loss: 1.5433 - val_accuracy: 0.3714\n",
            "Epoch 562/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.2029 - accuracy: 0.4759 - val_loss: 1.5391 - val_accuracy: 0.3654\n",
            "Epoch 563/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2037 - accuracy: 0.4742 - val_loss: 1.5436 - val_accuracy: 0.3582\n",
            "Epoch 564/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.2027 - accuracy: 0.4762 - val_loss: 1.5466 - val_accuracy: 0.3657\n",
            "Epoch 565/800\n",
            "1700/1700 [==============================] - 1s 563us/step - loss: 1.2031 - accuracy: 0.4748 - val_loss: 1.5399 - val_accuracy: 0.3664\n",
            "Epoch 566/800\n",
            "1700/1700 [==============================] - 1s 561us/step - loss: 1.2024 - accuracy: 0.4770 - val_loss: 1.5446 - val_accuracy: 0.3704\n",
            "Epoch 567/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2023 - accuracy: 0.4749 - val_loss: 1.5410 - val_accuracy: 0.3613\n",
            "Epoch 568/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.2026 - accuracy: 0.4761 - val_loss: 1.5354 - val_accuracy: 0.3717\n",
            "Epoch 569/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2020 - accuracy: 0.4778 - val_loss: 1.5424 - val_accuracy: 0.3579\n",
            "Epoch 570/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2023 - accuracy: 0.4774 - val_loss: 1.5374 - val_accuracy: 0.3655\n",
            "Epoch 571/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2020 - accuracy: 0.4756 - val_loss: 1.5374 - val_accuracy: 0.3685\n",
            "Epoch 572/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2015 - accuracy: 0.4759 - val_loss: 1.5390 - val_accuracy: 0.3611\n",
            "Epoch 573/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.2016 - accuracy: 0.4773 - val_loss: 1.5406 - val_accuracy: 0.3668\n",
            "Epoch 574/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.2019 - accuracy: 0.4757 - val_loss: 1.5425 - val_accuracy: 0.3677\n",
            "Epoch 575/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.2018 - accuracy: 0.4781 - val_loss: 1.5398 - val_accuracy: 0.3654\n",
            "Epoch 576/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.2011 - accuracy: 0.4766 - val_loss: 1.5409 - val_accuracy: 0.3671\n",
            "Epoch 577/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2016 - accuracy: 0.4777 - val_loss: 1.5384 - val_accuracy: 0.3666\n",
            "Epoch 578/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2012 - accuracy: 0.4759 - val_loss: 1.5409 - val_accuracy: 0.3595\n",
            "Epoch 579/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.2014 - accuracy: 0.4760 - val_loss: 1.5454 - val_accuracy: 0.3671\n",
            "Epoch 580/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2011 - accuracy: 0.4770 - val_loss: 1.5425 - val_accuracy: 0.3665\n",
            "Epoch 581/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.2012 - accuracy: 0.4769 - val_loss: 1.5481 - val_accuracy: 0.3683\n",
            "Epoch 582/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.2012 - accuracy: 0.4757 - val_loss: 1.5472 - val_accuracy: 0.3676\n",
            "Epoch 583/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2006 - accuracy: 0.4763 - val_loss: 1.5409 - val_accuracy: 0.3659\n",
            "Epoch 584/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.2010 - accuracy: 0.4749 - val_loss: 1.5402 - val_accuracy: 0.3642\n",
            "Epoch 585/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2000 - accuracy: 0.4770 - val_loss: 1.5407 - val_accuracy: 0.3658\n",
            "Epoch 586/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.2002 - accuracy: 0.4774 - val_loss: 1.5449 - val_accuracy: 0.3673\n",
            "Epoch 587/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1999 - accuracy: 0.4750 - val_loss: 1.5426 - val_accuracy: 0.3688\n",
            "Epoch 588/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1999 - accuracy: 0.4770 - val_loss: 1.5444 - val_accuracy: 0.3662\n",
            "Epoch 589/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.2001 - accuracy: 0.4763 - val_loss: 1.5485 - val_accuracy: 0.3614\n",
            "Epoch 590/800\n",
            "1700/1700 [==============================] - 1s 559us/step - loss: 1.1997 - accuracy: 0.4775 - val_loss: 1.5437 - val_accuracy: 0.3671\n",
            "Epoch 591/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.2001 - accuracy: 0.4772 - val_loss: 1.5434 - val_accuracy: 0.3546\n",
            "Epoch 592/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1993 - accuracy: 0.4756 - val_loss: 1.5519 - val_accuracy: 0.3556\n",
            "Epoch 593/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1994 - accuracy: 0.4784 - val_loss: 1.5466 - val_accuracy: 0.3587\n",
            "Epoch 594/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1991 - accuracy: 0.4765 - val_loss: 1.5440 - val_accuracy: 0.3683\n",
            "Epoch 595/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1997 - accuracy: 0.4770 - val_loss: 1.5458 - val_accuracy: 0.3670\n",
            "Epoch 596/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.1985 - accuracy: 0.4774 - val_loss: 1.5430 - val_accuracy: 0.3621\n",
            "Epoch 597/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1992 - accuracy: 0.4771 - val_loss: 1.5393 - val_accuracy: 0.3682\n",
            "Epoch 598/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1990 - accuracy: 0.4756 - val_loss: 1.5468 - val_accuracy: 0.3582\n",
            "Epoch 599/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1986 - accuracy: 0.4778 - val_loss: 1.5481 - val_accuracy: 0.3627\n",
            "Epoch 600/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.1988 - accuracy: 0.4777 - val_loss: 1.5461 - val_accuracy: 0.3659\n",
            "Epoch 601/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1984 - accuracy: 0.4786 - val_loss: 1.5462 - val_accuracy: 0.3648\n",
            "Epoch 602/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1979 - accuracy: 0.4772 - val_loss: 1.5479 - val_accuracy: 0.3705\n",
            "Epoch 603/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1984 - accuracy: 0.4783 - val_loss: 1.5449 - val_accuracy: 0.3673\n",
            "Epoch 604/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.1975 - accuracy: 0.4777 - val_loss: 1.5467 - val_accuracy: 0.3597\n",
            "Epoch 605/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1987 - accuracy: 0.4764 - val_loss: 1.5469 - val_accuracy: 0.3652\n",
            "Epoch 606/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.1978 - accuracy: 0.4796 - val_loss: 1.5423 - val_accuracy: 0.3594\n",
            "Epoch 607/800\n",
            "1700/1700 [==============================] - 1s 581us/step - loss: 1.1980 - accuracy: 0.4777 - val_loss: 1.5452 - val_accuracy: 0.3639\n",
            "Epoch 608/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1979 - accuracy: 0.4772 - val_loss: 1.5523 - val_accuracy: 0.3637\n",
            "Epoch 609/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1976 - accuracy: 0.4786 - val_loss: 1.5464 - val_accuracy: 0.3680\n",
            "Epoch 610/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.1976 - accuracy: 0.4780 - val_loss: 1.5478 - val_accuracy: 0.3702\n",
            "Epoch 611/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1974 - accuracy: 0.4791 - val_loss: 1.5455 - val_accuracy: 0.3644\n",
            "Epoch 612/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1968 - accuracy: 0.4779 - val_loss: 1.5631 - val_accuracy: 0.3579\n",
            "Epoch 613/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.1968 - accuracy: 0.4790 - val_loss: 1.5519 - val_accuracy: 0.3663\n",
            "Epoch 614/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1968 - accuracy: 0.4783 - val_loss: 1.5469 - val_accuracy: 0.3576\n",
            "Epoch 615/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1966 - accuracy: 0.4785 - val_loss: 1.5513 - val_accuracy: 0.3643\n",
            "Epoch 616/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1970 - accuracy: 0.4783 - val_loss: 1.5494 - val_accuracy: 0.3642\n",
            "Epoch 617/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1979 - accuracy: 0.4777 - val_loss: 1.5497 - val_accuracy: 0.3595\n",
            "Epoch 618/800\n",
            "1700/1700 [==============================] - 1s 549us/step - loss: 1.1962 - accuracy: 0.4778 - val_loss: 1.5485 - val_accuracy: 0.3599\n",
            "Epoch 619/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1956 - accuracy: 0.4784 - val_loss: 1.5503 - val_accuracy: 0.3609\n",
            "Epoch 620/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.1967 - accuracy: 0.4781 - val_loss: 1.5523 - val_accuracy: 0.3698\n",
            "Epoch 621/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1959 - accuracy: 0.4804 - val_loss: 1.5534 - val_accuracy: 0.3696\n",
            "Epoch 622/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1958 - accuracy: 0.4796 - val_loss: 1.5471 - val_accuracy: 0.3652\n",
            "Epoch 623/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.1964 - accuracy: 0.4793 - val_loss: 1.5516 - val_accuracy: 0.3672\n",
            "Epoch 624/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1956 - accuracy: 0.4802 - val_loss: 1.5521 - val_accuracy: 0.3624\n",
            "Epoch 625/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.1962 - accuracy: 0.4786 - val_loss: 1.5528 - val_accuracy: 0.3557\n",
            "Epoch 626/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1965 - accuracy: 0.4778 - val_loss: 1.5541 - val_accuracy: 0.3609\n",
            "Epoch 627/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.1960 - accuracy: 0.4798 - val_loss: 1.5532 - val_accuracy: 0.3654\n",
            "Epoch 628/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.1955 - accuracy: 0.4796 - val_loss: 1.5537 - val_accuracy: 0.3623\n",
            "Epoch 629/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1951 - accuracy: 0.4783 - val_loss: 1.5597 - val_accuracy: 0.3637\n",
            "Epoch 630/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1956 - accuracy: 0.4787 - val_loss: 1.5517 - val_accuracy: 0.3646\n",
            "Epoch 631/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1953 - accuracy: 0.4782 - val_loss: 1.5534 - val_accuracy: 0.3600\n",
            "Epoch 632/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.1951 - accuracy: 0.4776 - val_loss: 1.5459 - val_accuracy: 0.3654\n",
            "Epoch 633/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1952 - accuracy: 0.4796 - val_loss: 1.5520 - val_accuracy: 0.3578\n",
            "Epoch 634/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1950 - accuracy: 0.4801 - val_loss: 1.5576 - val_accuracy: 0.3679\n",
            "Epoch 635/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1947 - accuracy: 0.4785 - val_loss: 1.5537 - val_accuracy: 0.3627\n",
            "Epoch 636/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.1951 - accuracy: 0.4799 - val_loss: 1.5501 - val_accuracy: 0.3672\n",
            "Epoch 637/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.1947 - accuracy: 0.4781 - val_loss: 1.5554 - val_accuracy: 0.3644\n",
            "Epoch 638/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1949 - accuracy: 0.4778 - val_loss: 1.5601 - val_accuracy: 0.3554\n",
            "Epoch 639/800\n",
            "1700/1700 [==============================] - 1s 577us/step - loss: 1.1939 - accuracy: 0.4807 - val_loss: 1.5554 - val_accuracy: 0.3609\n",
            "Epoch 640/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1938 - accuracy: 0.4813 - val_loss: 1.5582 - val_accuracy: 0.3722\n",
            "Epoch 641/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1944 - accuracy: 0.4783 - val_loss: 1.5571 - val_accuracy: 0.3641\n",
            "Epoch 642/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1947 - accuracy: 0.4793 - val_loss: 1.5512 - val_accuracy: 0.3637\n",
            "Epoch 643/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.1945 - accuracy: 0.4778 - val_loss: 1.5527 - val_accuracy: 0.3603\n",
            "Epoch 644/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1941 - accuracy: 0.4807 - val_loss: 1.5557 - val_accuracy: 0.3647\n",
            "Epoch 645/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1940 - accuracy: 0.4798 - val_loss: 1.5560 - val_accuracy: 0.3688\n",
            "Epoch 646/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1937 - accuracy: 0.4803 - val_loss: 1.5544 - val_accuracy: 0.3621\n",
            "Epoch 647/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1938 - accuracy: 0.4772 - val_loss: 1.5585 - val_accuracy: 0.3609\n",
            "Epoch 648/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1939 - accuracy: 0.4793 - val_loss: 1.5623 - val_accuracy: 0.3666\n",
            "Epoch 649/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1934 - accuracy: 0.4805 - val_loss: 1.5537 - val_accuracy: 0.3645\n",
            "Epoch 650/800\n",
            "1700/1700 [==============================] - 1s 560us/step - loss: 1.1936 - accuracy: 0.4787 - val_loss: 1.5540 - val_accuracy: 0.3677\n",
            "Epoch 651/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.1939 - accuracy: 0.4807 - val_loss: 1.5607 - val_accuracy: 0.3595\n",
            "Epoch 652/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1934 - accuracy: 0.4804 - val_loss: 1.5549 - val_accuracy: 0.3697\n",
            "Epoch 653/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.1931 - accuracy: 0.4802 - val_loss: 1.5568 - val_accuracy: 0.3618\n",
            "Epoch 654/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1927 - accuracy: 0.4784 - val_loss: 1.5538 - val_accuracy: 0.3610\n",
            "Epoch 655/800\n",
            "1700/1700 [==============================] - 1s 564us/step - loss: 1.1930 - accuracy: 0.4814 - val_loss: 1.5537 - val_accuracy: 0.3638\n",
            "Epoch 656/800\n",
            "1700/1700 [==============================] - 1s 565us/step - loss: 1.1918 - accuracy: 0.4802 - val_loss: 1.5594 - val_accuracy: 0.3639\n",
            "Epoch 657/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1921 - accuracy: 0.4809 - val_loss: 1.5697 - val_accuracy: 0.3632\n",
            "Epoch 658/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1927 - accuracy: 0.4806 - val_loss: 1.5612 - val_accuracy: 0.3605\n",
            "Epoch 659/800\n",
            "1700/1700 [==============================] - 1s 582us/step - loss: 1.1925 - accuracy: 0.4805 - val_loss: 1.5534 - val_accuracy: 0.3697\n",
            "Epoch 660/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.1925 - accuracy: 0.4815 - val_loss: 1.5572 - val_accuracy: 0.3611\n",
            "Epoch 661/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1930 - accuracy: 0.4807 - val_loss: 1.5596 - val_accuracy: 0.3608\n",
            "Epoch 662/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1918 - accuracy: 0.4783 - val_loss: 1.5625 - val_accuracy: 0.3636\n",
            "Epoch 663/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1924 - accuracy: 0.4807 - val_loss: 1.5570 - val_accuracy: 0.3647\n",
            "Epoch 664/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1908 - accuracy: 0.4815 - val_loss: 1.5570 - val_accuracy: 0.3658\n",
            "Epoch 665/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1917 - accuracy: 0.4807 - val_loss: 1.5617 - val_accuracy: 0.3665\n",
            "Epoch 666/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1922 - accuracy: 0.4795 - val_loss: 1.5639 - val_accuracy: 0.3635\n",
            "Epoch 667/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.1923 - accuracy: 0.4801 - val_loss: 1.5613 - val_accuracy: 0.3639\n",
            "Epoch 668/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1912 - accuracy: 0.4810 - val_loss: 1.5564 - val_accuracy: 0.3583\n",
            "Epoch 669/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1916 - accuracy: 0.4796 - val_loss: 1.5626 - val_accuracy: 0.3603\n",
            "Epoch 670/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1911 - accuracy: 0.4811 - val_loss: 1.5600 - val_accuracy: 0.3551\n",
            "Epoch 671/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.1912 - accuracy: 0.4805 - val_loss: 1.5642 - val_accuracy: 0.3647\n",
            "Epoch 672/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1911 - accuracy: 0.4814 - val_loss: 1.5586 - val_accuracy: 0.3650\n",
            "Epoch 673/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.1907 - accuracy: 0.4800 - val_loss: 1.5624 - val_accuracy: 0.3602\n",
            "Epoch 674/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1916 - accuracy: 0.4808 - val_loss: 1.5586 - val_accuracy: 0.3669\n",
            "Epoch 675/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1906 - accuracy: 0.4816 - val_loss: 1.5644 - val_accuracy: 0.3660\n",
            "Epoch 676/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1909 - accuracy: 0.4809 - val_loss: 1.5618 - val_accuracy: 0.3652\n",
            "Epoch 677/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1909 - accuracy: 0.4800 - val_loss: 1.5587 - val_accuracy: 0.3643\n",
            "Epoch 678/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1905 - accuracy: 0.4813 - val_loss: 1.5692 - val_accuracy: 0.3636\n",
            "Epoch 679/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1902 - accuracy: 0.4815 - val_loss: 1.5619 - val_accuracy: 0.3588\n",
            "Epoch 680/800\n",
            "1700/1700 [==============================] - 1s 556us/step - loss: 1.1912 - accuracy: 0.4789 - val_loss: 1.5660 - val_accuracy: 0.3659\n",
            "Epoch 681/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1903 - accuracy: 0.4807 - val_loss: 1.5637 - val_accuracy: 0.3616\n",
            "Epoch 682/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1895 - accuracy: 0.4817 - val_loss: 1.5630 - val_accuracy: 0.3565\n",
            "Epoch 683/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1895 - accuracy: 0.4824 - val_loss: 1.5649 - val_accuracy: 0.3672\n",
            "Epoch 684/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1900 - accuracy: 0.4801 - val_loss: 1.5655 - val_accuracy: 0.3721\n",
            "Epoch 685/800\n",
            "1700/1700 [==============================] - 1s 548us/step - loss: 1.1905 - accuracy: 0.4815 - val_loss: 1.5611 - val_accuracy: 0.3601\n",
            "Epoch 686/800\n",
            "1700/1700 [==============================] - 1s 575us/step - loss: 1.1897 - accuracy: 0.4827 - val_loss: 1.5644 - val_accuracy: 0.3566\n",
            "Epoch 687/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1898 - accuracy: 0.4821 - val_loss: 1.5608 - val_accuracy: 0.3701\n",
            "Epoch 688/800\n",
            "1700/1700 [==============================] - 1s 599us/step - loss: 1.1894 - accuracy: 0.4828 - val_loss: 1.5668 - val_accuracy: 0.3647\n",
            "Epoch 689/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.1888 - accuracy: 0.4812 - val_loss: 1.5623 - val_accuracy: 0.3668\n",
            "Epoch 690/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1898 - accuracy: 0.4795 - val_loss: 1.5631 - val_accuracy: 0.3705\n",
            "Epoch 691/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1894 - accuracy: 0.4820 - val_loss: 1.5662 - val_accuracy: 0.3616\n",
            "Epoch 692/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1888 - accuracy: 0.4815 - val_loss: 1.5685 - val_accuracy: 0.3629\n",
            "Epoch 693/800\n",
            "1700/1700 [==============================] - 1s 562us/step - loss: 1.1891 - accuracy: 0.4818 - val_loss: 1.5637 - val_accuracy: 0.3653\n",
            "Epoch 694/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.1887 - accuracy: 0.4811 - val_loss: 1.5598 - val_accuracy: 0.3660\n",
            "Epoch 695/800\n",
            "1700/1700 [==============================] - 1s 616us/step - loss: 1.1886 - accuracy: 0.4825 - val_loss: 1.5646 - val_accuracy: 0.3599\n",
            "Epoch 696/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.1891 - accuracy: 0.4807 - val_loss: 1.5661 - val_accuracy: 0.3653\n",
            "Epoch 697/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.1892 - accuracy: 0.4816 - val_loss: 1.5664 - val_accuracy: 0.3640\n",
            "Epoch 698/800\n",
            "1700/1700 [==============================] - 1s 555us/step - loss: 1.1883 - accuracy: 0.4813 - val_loss: 1.5647 - val_accuracy: 0.3613\n",
            "Epoch 699/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1892 - accuracy: 0.4807 - val_loss: 1.5622 - val_accuracy: 0.3657\n",
            "Epoch 700/800\n",
            "1700/1700 [==============================] - 1s 566us/step - loss: 1.1884 - accuracy: 0.4821 - val_loss: 1.5670 - val_accuracy: 0.3619\n",
            "Epoch 701/800\n",
            "1700/1700 [==============================] - 1s 553us/step - loss: 1.1880 - accuracy: 0.4816 - val_loss: 1.5688 - val_accuracy: 0.3640\n",
            "Epoch 702/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.1886 - accuracy: 0.4830 - val_loss: 1.5672 - val_accuracy: 0.3671\n",
            "Epoch 703/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1884 - accuracy: 0.4835 - val_loss: 1.5717 - val_accuracy: 0.3521\n",
            "Epoch 704/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1888 - accuracy: 0.4810 - val_loss: 1.5675 - val_accuracy: 0.3591\n",
            "Epoch 705/800\n",
            "1700/1700 [==============================] - 1s 563us/step - loss: 1.1881 - accuracy: 0.4809 - val_loss: 1.5659 - val_accuracy: 0.3609\n",
            "Epoch 706/800\n",
            "1700/1700 [==============================] - 1s 573us/step - loss: 1.1876 - accuracy: 0.4820 - val_loss: 1.5666 - val_accuracy: 0.3679\n",
            "Epoch 707/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1880 - accuracy: 0.4816 - val_loss: 1.5714 - val_accuracy: 0.3614\n",
            "Epoch 708/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.1872 - accuracy: 0.4831 - val_loss: 1.5660 - val_accuracy: 0.3573\n",
            "Epoch 709/800\n",
            "1700/1700 [==============================] - 1s 567us/step - loss: 1.1881 - accuracy: 0.4818 - val_loss: 1.5678 - val_accuracy: 0.3618\n",
            "Epoch 710/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1880 - accuracy: 0.4808 - val_loss: 1.5691 - val_accuracy: 0.3598\n",
            "Epoch 711/800\n",
            "1700/1700 [==============================] - 1s 569us/step - loss: 1.1880 - accuracy: 0.4807 - val_loss: 1.5692 - val_accuracy: 0.3664\n",
            "Epoch 712/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1873 - accuracy: 0.4815 - val_loss: 1.5720 - val_accuracy: 0.3568\n",
            "Epoch 713/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.1870 - accuracy: 0.4818 - val_loss: 1.5675 - val_accuracy: 0.3615\n",
            "Epoch 714/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.1869 - accuracy: 0.4819 - val_loss: 1.5675 - val_accuracy: 0.3646\n",
            "Epoch 715/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1870 - accuracy: 0.4804 - val_loss: 1.5659 - val_accuracy: 0.3562\n",
            "Epoch 716/800\n",
            "1700/1700 [==============================] - 1s 570us/step - loss: 1.1868 - accuracy: 0.4834 - val_loss: 1.5678 - val_accuracy: 0.3631\n",
            "Epoch 717/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1872 - accuracy: 0.4834 - val_loss: 1.5674 - val_accuracy: 0.3657\n",
            "Epoch 718/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1862 - accuracy: 0.4850 - val_loss: 1.5695 - val_accuracy: 0.3582\n",
            "Epoch 719/800\n",
            "1700/1700 [==============================] - 1s 574us/step - loss: 1.1866 - accuracy: 0.4832 - val_loss: 1.5704 - val_accuracy: 0.3660\n",
            "Epoch 720/800\n",
            "1700/1700 [==============================] - 1s 557us/step - loss: 1.1863 - accuracy: 0.4836 - val_loss: 1.5743 - val_accuracy: 0.3632\n",
            "Epoch 721/800\n",
            "1700/1700 [==============================] - 1s 605us/step - loss: 1.1859 - accuracy: 0.4831 - val_loss: 1.5741 - val_accuracy: 0.3608\n",
            "Epoch 722/800\n",
            "1700/1700 [==============================] - 1s 591us/step - loss: 1.1865 - accuracy: 0.4835 - val_loss: 1.5702 - val_accuracy: 0.3606\n",
            "Epoch 723/800\n",
            "1700/1700 [==============================] - 1s 572us/step - loss: 1.1862 - accuracy: 0.4818 - val_loss: 1.5731 - val_accuracy: 0.3618\n",
            "Epoch 724/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1860 - accuracy: 0.4828 - val_loss: 1.5745 - val_accuracy: 0.3632\n",
            "Epoch 725/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.1869 - accuracy: 0.4833 - val_loss: 1.5734 - val_accuracy: 0.3592\n",
            "Epoch 726/800\n",
            "1700/1700 [==============================] - 1s 571us/step - loss: 1.1866 - accuracy: 0.4834 - val_loss: 1.5780 - val_accuracy: 0.3542\n",
            "Epoch 727/800\n",
            "1700/1700 [==============================] - 1s 552us/step - loss: 1.1857 - accuracy: 0.4841 - val_loss: 1.5674 - val_accuracy: 0.3637\n",
            "Epoch 728/800\n",
            "1700/1700 [==============================] - 1s 568us/step - loss: 1.1851 - accuracy: 0.4817 - val_loss: 1.5716 - val_accuracy: 0.3612\n",
            "Epoch 729/800\n",
            "1700/1700 [==============================] - 1s 554us/step - loss: 1.1857 - accuracy: 0.4839 - val_loss: 1.5744 - val_accuracy: 0.3557\n",
            "Epoch 730/800\n",
            "1700/1700 [==============================] - 1s 558us/step - loss: 1.1858 - accuracy: 0.4840 - val_loss: 1.5747 - val_accuracy: 0.3554\n",
            "Epoch 731/800\n",
            "1700/1700 [==============================] - 1s 576us/step - loss: 1.1855 - accuracy: 0.4836 - val_loss: 1.5708 - val_accuracy: 0.3621\n",
            "Epoch 732/800\n",
            "1700/1700 [==============================] - 1s 593us/step - loss: 1.1865 - accuracy: 0.4833 - val_loss: 1.5720 - val_accuracy: 0.3633\n",
            "Epoch 733/800\n",
            "1700/1700 [==============================] - 1s 613us/step - loss: 1.1856 - accuracy: 0.4827 - val_loss: 1.5757 - val_accuracy: 0.3672\n",
            "Epoch 734/800\n",
            "1700/1700 [==============================] - 1s 635us/step - loss: 1.1853 - accuracy: 0.4837 - val_loss: 1.5762 - val_accuracy: 0.3618\n",
            "Epoch 735/800\n",
            "1700/1700 [==============================] - 1s 656us/step - loss: 1.1857 - accuracy: 0.4848 - val_loss: 1.5720 - val_accuracy: 0.3660\n",
            "Epoch 736/800\n",
            "1700/1700 [==============================] - 1s 694us/step - loss: 1.1853 - accuracy: 0.4823 - val_loss: 1.5716 - val_accuracy: 0.3627\n",
            "Epoch 737/800\n",
            "1700/1700 [==============================] - 1s 850us/step - loss: 1.1855 - accuracy: 0.4828 - val_loss: 1.5773 - val_accuracy: 0.3657\n",
            "Epoch 738/800\n",
            "1700/1700 [==============================] - 1s 859us/step - loss: 1.1851 - accuracy: 0.4816 - val_loss: 1.5712 - val_accuracy: 0.3590\n",
            "Epoch 739/800\n",
            "1700/1700 [==============================] - 1s 861us/step - loss: 1.1853 - accuracy: 0.4822 - val_loss: 1.5704 - val_accuracy: 0.3613\n",
            "Epoch 740/800\n",
            "1700/1700 [==============================] - 2s 966us/step - loss: 1.1851 - accuracy: 0.4839 - val_loss: 1.5738 - val_accuracy: 0.3638\n",
            "Epoch 741/800\n",
            "1700/1700 [==============================] - 2s 1ms/step - loss: 1.1855 - accuracy: 0.4829 - val_loss: 1.5740 - val_accuracy: 0.3631\n",
            "Epoch 742/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1848 - accuracy: 0.4839 - val_loss: 1.5785 - val_accuracy: 0.3672\n",
            "Epoch 743/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1845 - accuracy: 0.4832 - val_loss: 1.5723 - val_accuracy: 0.3632\n",
            "Epoch 744/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1843 - accuracy: 0.4856 - val_loss: 1.5743 - val_accuracy: 0.3697\n",
            "Epoch 745/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1843 - accuracy: 0.4826 - val_loss: 1.5745 - val_accuracy: 0.3674\n",
            "Epoch 746/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1841 - accuracy: 0.4826 - val_loss: 1.5675 - val_accuracy: 0.3674\n",
            "Epoch 747/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1843 - accuracy: 0.4830 - val_loss: 1.5779 - val_accuracy: 0.3610\n",
            "Epoch 748/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1847 - accuracy: 0.4825 - val_loss: 1.5710 - val_accuracy: 0.3627\n",
            "Epoch 749/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1844 - accuracy: 0.4840 - val_loss: 1.5724 - val_accuracy: 0.3620\n",
            "Epoch 750/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1838 - accuracy: 0.4821 - val_loss: 1.5715 - val_accuracy: 0.3691\n",
            "Epoch 751/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1835 - accuracy: 0.4848 - val_loss: 1.5764 - val_accuracy: 0.3639\n",
            "Epoch 752/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1841 - accuracy: 0.4829 - val_loss: 1.5755 - val_accuracy: 0.3623\n",
            "Epoch 753/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1840 - accuracy: 0.4842 - val_loss: 1.5764 - val_accuracy: 0.3627\n",
            "Epoch 754/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1841 - accuracy: 0.4844 - val_loss: 1.5797 - val_accuracy: 0.3692\n",
            "Epoch 755/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1837 - accuracy: 0.4848 - val_loss: 1.5832 - val_accuracy: 0.3623\n",
            "Epoch 756/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1833 - accuracy: 0.4848 - val_loss: 1.5730 - val_accuracy: 0.3604\n",
            "Epoch 757/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1828 - accuracy: 0.4842 - val_loss: 1.5878 - val_accuracy: 0.3492\n",
            "Epoch 758/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1829 - accuracy: 0.4831 - val_loss: 1.5840 - val_accuracy: 0.3573\n",
            "Epoch 759/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1838 - accuracy: 0.4846 - val_loss: 1.5768 - val_accuracy: 0.3605\n",
            "Epoch 760/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1830 - accuracy: 0.4834 - val_loss: 1.5827 - val_accuracy: 0.3585\n",
            "Epoch 761/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1839 - accuracy: 0.4851 - val_loss: 1.5787 - val_accuracy: 0.3616\n",
            "Epoch 762/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1828 - accuracy: 0.4856 - val_loss: 1.5749 - val_accuracy: 0.3621\n",
            "Epoch 763/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1826 - accuracy: 0.4836 - val_loss: 1.5740 - val_accuracy: 0.3665\n",
            "Epoch 764/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1833 - accuracy: 0.4832 - val_loss: 1.5789 - val_accuracy: 0.3592\n",
            "Epoch 765/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1826 - accuracy: 0.4853 - val_loss: 1.5803 - val_accuracy: 0.3590\n",
            "Epoch 766/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1823 - accuracy: 0.4842 - val_loss: 1.5814 - val_accuracy: 0.3691\n",
            "Epoch 767/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1828 - accuracy: 0.4849 - val_loss: 1.5902 - val_accuracy: 0.3600\n",
            "Epoch 768/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1821 - accuracy: 0.4844 - val_loss: 1.5821 - val_accuracy: 0.3562\n",
            "Epoch 769/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1821 - accuracy: 0.4838 - val_loss: 1.5809 - val_accuracy: 0.3643\n",
            "Epoch 770/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1824 - accuracy: 0.4858 - val_loss: 1.5822 - val_accuracy: 0.3663\n",
            "Epoch 771/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1823 - accuracy: 0.4838 - val_loss: 1.5789 - val_accuracy: 0.3560\n",
            "Epoch 772/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1816 - accuracy: 0.4849 - val_loss: 1.5775 - val_accuracy: 0.3639\n",
            "Epoch 773/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1815 - accuracy: 0.4842 - val_loss: 1.5770 - val_accuracy: 0.3597\n",
            "Epoch 774/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1823 - accuracy: 0.4828 - val_loss: 1.5784 - val_accuracy: 0.3663\n",
            "Epoch 775/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1819 - accuracy: 0.4834 - val_loss: 1.5800 - val_accuracy: 0.3684\n",
            "Epoch 776/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1816 - accuracy: 0.4849 - val_loss: 1.5800 - val_accuracy: 0.3662\n",
            "Epoch 777/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1827 - accuracy: 0.4851 - val_loss: 1.5915 - val_accuracy: 0.3532\n",
            "Epoch 778/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1812 - accuracy: 0.4850 - val_loss: 1.5739 - val_accuracy: 0.3652\n",
            "Epoch 779/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1813 - accuracy: 0.4840 - val_loss: 1.5967 - val_accuracy: 0.3653\n",
            "Epoch 780/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1812 - accuracy: 0.4855 - val_loss: 1.5881 - val_accuracy: 0.3557\n",
            "Epoch 781/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1822 - accuracy: 0.4836 - val_loss: 1.5870 - val_accuracy: 0.3574\n",
            "Epoch 782/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1811 - accuracy: 0.4850 - val_loss: 1.5838 - val_accuracy: 0.3689\n",
            "Epoch 783/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1816 - accuracy: 0.4853 - val_loss: 1.5792 - val_accuracy: 0.3613\n",
            "Epoch 784/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1806 - accuracy: 0.4857 - val_loss: 1.5783 - val_accuracy: 0.3668\n",
            "Epoch 785/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1819 - accuracy: 0.4840 - val_loss: 1.5736 - val_accuracy: 0.3688\n",
            "Epoch 786/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1807 - accuracy: 0.4847 - val_loss: 1.5902 - val_accuracy: 0.3552\n",
            "Epoch 787/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1809 - accuracy: 0.4836 - val_loss: 1.5787 - val_accuracy: 0.3624\n",
            "Epoch 788/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1807 - accuracy: 0.4842 - val_loss: 1.5851 - val_accuracy: 0.3526\n",
            "Epoch 789/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1810 - accuracy: 0.4839 - val_loss: 1.5819 - val_accuracy: 0.3672\n",
            "Epoch 790/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1805 - accuracy: 0.4839 - val_loss: 1.5802 - val_accuracy: 0.3603\n",
            "Epoch 791/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1810 - accuracy: 0.4841 - val_loss: 1.5868 - val_accuracy: 0.3565\n",
            "Epoch 792/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1807 - accuracy: 0.4857 - val_loss: 1.5912 - val_accuracy: 0.3568\n",
            "Epoch 793/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1812 - accuracy: 0.4835 - val_loss: 1.5862 - val_accuracy: 0.3511\n",
            "Epoch 794/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1804 - accuracy: 0.4846 - val_loss: 1.5850 - val_accuracy: 0.3629\n",
            "Epoch 795/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1812 - accuracy: 0.4843 - val_loss: 1.5802 - val_accuracy: 0.3640\n",
            "Epoch 796/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1803 - accuracy: 0.4844 - val_loss: 1.5856 - val_accuracy: 0.3620\n",
            "Epoch 797/800\n",
            "1700/1700 [==============================] - 4s 2ms/step - loss: 1.1804 - accuracy: 0.4849 - val_loss: 1.5837 - val_accuracy: 0.3630\n",
            "Epoch 798/800\n",
            "1700/1700 [==============================] - 2s 1ms/step - loss: 1.1798 - accuracy: 0.4855 - val_loss: 1.5860 - val_accuracy: 0.3578\n",
            "Epoch 799/800\n",
            "1700/1700 [==============================] - 2s 1ms/step - loss: 1.1800 - accuracy: 0.4846 - val_loss: 1.5796 - val_accuracy: 0.3604\n",
            "Epoch 800/800\n",
            "1700/1700 [==============================] - 3s 2ms/step - loss: 1.1799 - accuracy: 0.4851 - val_loss: 1.5892 - val_accuracy: 0.3702\n",
            "-----------* Cuarto modelo entrenado con éxito \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hacemos uso de los datos escalados\n",
        "\n",
        "# Convierte las etiquetas a formato one-hot\n",
        "y_train_encoded_adjusted = y_train_encoded - 1 # Resta 1 a tus etiquetas para que estén en el rango de 0 a 4\n",
        "y_test_encoded_adjusted = y_test_encoded - 1 # Resta 1 a tus etiquetas para que estén en el rango de 0 a 4\n",
        "\n",
        "y_train_one_hot = to_categorical(y_train_encoded_adjusted, num_classes=5)\n",
        "y_test_one_hot = to_categorical(y_test_encoded_adjusted, num_classes=5)\n",
        "\n",
        "\n",
        "# Crea tu modelo\n",
        "model_nn = set_nn_model_architecture()\n",
        "\n",
        "print(\"-----------* Creación del cuarto modelo con éxito \\n\")\n",
        "\n",
        "# Define el optimizador (puedes cambiarlo según tus necesidades)\n",
        "adam = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compila el modelo\n",
        "model_nn.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrena el modelo\n",
        "training_history = model_nn.fit(X_train_scaled, y_train_one_hot, epochs=800, validation_split=0.15, batch_size=40)\n",
        "\n",
        "print(\"-----------* Cuarto modelo entrenado con éxito \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluación del cuarto modelo: Red Neuronal \n",
            "\n",
            "625/625 [==============================] - 0s 238us/step\n",
            "F1 Score: 0.33679279386935584\n",
            "Precisión: 0.3498331558337859\n",
            "Recall: 0.363\n",
            "Exactitud (Accuracy): 0.363\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[ 265  112  239  496  102]\n",
            " [ 124  211  633 1114  188]\n",
            " [ 190  279 1421 3038  579]\n",
            " [ 127  207 1255 4318  917]\n",
            " [  48   90  541 2461 1045]]\n"
          ]
        }
      ],
      "source": [
        "# Realizar predicciones en el conjunto de prueba y evaluar el modelo\n",
        "print(\"Evaluación del cuarto modelo: Red Neuronal \\n\")\n",
        "evaluar_modelo_nn(model_nn, X_test_scaled, y_test_one_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Seleccionar modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observando las evaluaciones de cada modelo, se selecciona el modelo de...\n",
            "\n",
            "RED NEURONAL\n",
            "      \n",
            "La decisión fue tomado por su capacidad de abordar la complejidad de los datos y el potencial que se le \n",
            "ve al modelo para mejorar mediante validación cruzada. Además se toma en cuenta que con 100,000 registros es suficiente\n",
            "para entrenar una Red Neuronal.\n",
            "\n",
            "-----------* Modelo seleccionado con éxito \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\"\"\n",
        "Observando las evaluaciones de cada modelo, se selecciona el modelo de...\n",
        "\n",
        "RED NEURONAL\n",
        "      \n",
        "La decisión fue tomado por su capacidad de abordar la complejidad de los datos y el potencial que se le \n",
        "ve al modelo para mejorar mediante validación cruzada. Además se toma en cuenta que con 100,000 registros es suficiente\n",
        "para entrenar una Red Neuronal.\n",
        "\"\"\")\n",
        "      \n",
        "print(\"-----------* Modelo seleccionado con éxito \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Análisis del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Realizaremos un análisis profundo de nuestro modelo de Red Neuronal original. \n",
            "Posterior a esto, se mejorará el modelo y se volverá a analizar.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\"\"\n",
        "Realizaremos un análisis profundo de nuestro modelo de Red Neuronal original. \n",
        "Posterior a esto, se mejorará el modelo y se volverá a analizar.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqeklEQVR4nO3dd3gU1eLG8e9ueichhCSE0CF0EKSqCIgIyBWxokj72UVBxd69tqtXRa+9gQiCooLY6UWRTijSIfSEECC9Z+f3x0CSJYUEkmyyeT/Ps09mz5yZPbMoeZk5xWIYhoGIiIiIk7A6ugEiIiIiFUnhRkRERJyKwo2IiIg4FYUbERERcSoKNyIiIuJUFG5ERETEqSjciIiIiFNRuBERERGnonAjIiIiTkXhRsTJTJ06FYvFwrp16xzdlGrnzHdT0mvp0qUObd/+/fuxWCz897//dWg7RGo6V0c3QESkqk2ZMoWoqKgi5W3atHFAa0SkoinciEit065dO7p27eroZohIJdFjKZFa6s8//6R///74+fnh7e1Nr169+OWXX+zqpKenM2nSJJo0aYKnpydBQUF07dqVmTNn5tfZt28fN998M+Hh4Xh4eFC/fn369+9PdHR0iZ89efJkLBYLe/bsKbLvsccew93dnYSEBAA2btzI1VdfTUhICB4eHoSHhzNkyBAOHz5cMV9ECSwWC+PHj+fjjz+mZcuWeHh40KZNG2bNmlWk7tatW7nmmmsIDAzE09OTTp068eWXXxapl5iYyMMPP0zTpk3x8PAgJCSEwYMHs2PHjiJ133rrLZo0aYKvry89e/Zk1apVdvvP53sXqS1050akFlq2bBkDBgygQ4cOfP7553h4ePDBBx8wdOhQZs6cyU033QTAQw89xFdffcVLL71E586dSUtLY+vWrZw4cSL/XIMHDyYvL4/XX3+dyMhIEhISWLlyJYmJiSV+/siRI3nssceYOnUqL730Un55Xl4e06dPZ+jQoQQHB5OWlsaAAQNo0qQJ77//PvXr1ycuLo4lS5aQkpJy3tefl5dHbm6uXZnFYsHFxcWubN68eSxZsoQXX3wRHx8fPvjgA0aMGIGrqyvXX389ADt37qRXr16EhITw7rvvUrduXaZPn86YMWM4duwYjz76KAApKSlccskl7N+/n8cee4zu3buTmprK8uXLiY2NtXtM9v777xMVFcXkyZMBeOaZZxg8eDAxMTEEBASc9/cuUmsYIuJUpkyZYgDG2rVrS6zTo0cPIyQkxEhJSckvy83NNdq1a2dEREQYNpvNMAzDaNeunTFs2LASz5OQkGAAxuTJk8vdzuHDhxsRERFGXl5eftmvv/5qAMZPP/1kGIZhrFu3zgCMuXPnlvv8xTnz3RT3cnFxsasLGF5eXkZcXFx+WW5urhEVFWU0b948v+zmm282PDw8jIMHD9odP2jQIMPb29tITEw0DMMwXnzxRQMwFixYUGL7YmJiDMBo3769kZubm1++Zs0aAzBmzpxpGMaFfe8itYEeS4nUMmlpaaxevZrrr78eX1/f/HIXFxduu+02Dh8+zM6dOwHo1q0bv/32G48//jhLly4lIyPD7lxBQUE0a9aMN954g7feeouNGzdis9nK1I6xY8dy+PBhFi5cmF82ZcoUQkNDGTRoEADNmzcnMDCQxx57jI8++oht27Zd6OUDMG3aNNauXWv3Wr16dZF6/fv3p379+vnvXVxcuOmmm9izZ0/+Y7HFixfTv39/GjZsaHfsmDFjSE9P5++//wbgt99+o2XLllxxxRXnbN+QIUPs7iJ16NABgAMHDgAX9r2L1AYKNyK1zKlTpzAMg7CwsCL7wsPDAfIfO7377rs89thjzJ07l759+xIUFMSwYcPYvXs3YD7KWbRoEQMHDuT111/noosuol69ejzwwAPnfGw0aNAgwsLCmDJlSn675s2bx6hRo/J/sQcEBLBs2TI6derEk08+Sdu2bQkPD+e5554jJyfnvL+D1q1b07VrV7tXly5ditQLDQ0tsezMd3TixIkyfZfHjx8nIiKiTO2rW7eu3XsPDw+A/HB5Id+7SG2gcCNSywQGBmK1WomNjS2y7+jRowAEBwcD4OPjwwsvvMCOHTuIi4vjww8/ZNWqVQwdOjT/mEaNGvH5558TFxfHzp07efDBB/nggw945JFHSm3HmTtFc+fOJTExka+//pqsrCzGjh1rV699+/bMmjWLEydOEB0dzU033cSLL77Im2++eaFfxTnFxcWVWHYmgNStW7dM32W9evUqtBP0+X7vIrWBwo1ILePj40P37t354Ycf7B4z2Ww2pk+fTkREBC1btixyXP369RkzZgwjRoxg586dpKenF6nTsmVLnn76adq3b8+GDRvO2ZaxY8eSmZnJzJkzmTp1Kj179ix2/hkw71Z07NiRt99+mzp16pTp/Bdq0aJFHDt2LP99Xl4e33zzDc2aNcu/C9O/f38WL16cH2bOmDZtGt7e3vTo0QMw71Tt2rWLxYsXV3g7y/u9izg7jZYScVKLFy9m//79RcoHDx7Mq6++yoABA+jbty+TJk3C3d2dDz74gK1btzJz5kwsFgsA3bt35+qrr6ZDhw4EBgayfft2vvrqK3r27Im3tzebN29m/Pjx3HDDDbRo0QJ3d3cWL17M5s2befzxx8/ZxqioKHr27Mmrr77KoUOH+OSTT+z2//zzz3zwwQcMGzaMpk2bYhgGP/zwA4mJiQwYMCC/Xv/+/Vm2bFmREVAl2bp1a7F1mzVrRr169fLfBwcH069fP5555pn80VI7duywGw7+3HPP8fPPP9O3b1+effZZgoKCmDFjBr/88guvv/56/uimiRMn8s0333DNNdfw+OOP061bNzIyMli2bBlXX301ffv2LVPbgQv+3kWcnqN7NItIxSptRBBgxMTEGIZhGCtWrDD69etn+Pj4GF5eXkaPHj3yRymd8fjjjxtdu3Y1AgMDDQ8PD6Np06bGgw8+aCQkJBiGYRjHjh0zxowZY0RFRRk+Pj6Gr6+v0aFDB+Ptt9+2G+1Tmk8++SR/ZFJSUpLdvh07dhgjRowwmjVrZnh5eRkBAQFGt27djKlTp9rV69Onj1GWv87O9d18+umn+XUB47777jM++OADo1mzZoabm5sRFRVlzJgxo8h5t2zZYgwdOtQICAgw3N3djY4dOxpTpkwpUu/UqVPGhAkTjMjISMPNzc0ICQkxhgwZYuzYscMwjILRUm+88UaRYwHjueeeMwyjYr53EWdmMQzDqOI8JSJS7VksFu677z7ee+89RzdFRMpJfW5ERETEqSjciIiIiFNRh2IRkWLoib1IzaU7NyIiIuJUFG5ERETEqSjciIiIiFOpdX1ubDYbR48exc/PL3+iMhEREaneDMMgJSWF8PBwrNbS783UunBz9OjRIqv3ioiISM1w6NChcy5CW+vCjZ+fH2B+Of7+/g5ujYiIiJRFcnIyDRs2zP89XppaF27OPIry9/dXuBEREalhytKlRB2KRURExKko3IiIiIhTUbgRERERp1Lr+tyIiIjzsNlsZGdnO7oZUkHc3d3POcy7LBRuRESkRsrOziYmJgabzebopkgFsVqtNGnSBHd39ws6j8KNiIjUOIZhEBsbi4uLCw0bNqyQf+2LY52ZZDc2NpbIyMgLmmhX4UZERGqc3Nxc0tPTCQ8Px9vb29HNkQpSr149jh49Sm5uLm5ubud9HodG3eXLlzN06FDCw8OxWCzMnTv3nMdkZWXx1FNP0ahRIzw8PGjWrBlffPFF5TdWRESqjby8PIALfnwh1cuZP88zf77ny6F3btLS0ujYsSNjx47luuuuK9MxN954I8eOHePzzz+nefPmxMfHk5ubW8ktFRGR6khrBDqXivrzdGi4GTRoEIMGDSpz/d9//51ly5axb98+goKCAGjcuHEltU5ERERqohrVA2vevHl07dqV119/nQYNGtCyZUsmTZpERkZGicdkZWWRnJxs9xIREXEWl19+ORMnTixz/f3792OxWIiOjq60NjlajepQvG/fPv788088PT2ZM2cOCQkJ3HvvvZw8ebLEfjevvvoqL7zwQhW3VERExN65HrmMHj2aqVOnlvu8P/zwQ7k63zZs2JDY2FiCg4PL/Vk1RY0KNzabDYvFwowZMwgICADgrbfe4vrrr+f999/Hy8uryDFPPPEEDz30UP77M6uKioiIVKXY2Nj87W+++YZnn32WnTt35ped/TssJyenTKHlTDeNsnJxcSE0NLTsBxin5xGy1JyHPTWnpUBYWBgNGjTIDzYArVu3xjAMDh8+XOwxHh4e+SuAayVwERFxlNDQ0PxXQEAAFosl/31mZiZ16tTh22+/5fLLL8fT05Pp06dz4sQJRowYQUREBN7e3rRv356ZM2fanffsx1KNGzfmlVdeYdy4cfj5+REZGcknn3ySv//sx1JLly7FYrGwaNEiunbtire3N7169TKDl2HA8Z0Qv52X/v1vQkJC8PPz4/bbb+fxxx+nU6dOVfDNlV+NCje9e/fm6NGjpKam5pft2rULq9VKRESEA1smIiKOZBgG6dm5DnkZhlFh1/HYY4/xwAMPsH37dgYOHEhmZiZdunTh559/ZuvWrdx5553cdtttrF69utTzvPnmm3Tt2pWNGzdy7733cs8997Bjx45Sj3nqqad48803WbduHa6urowbNw6MPMjNZMbsubz8yiv85z//Yf369URGRvLhhx9W2HVXNIc+lkpNTWXPnj3572NiYoiOjiYoKIjIyEieeOIJjhw5wrRp0wC45ZZb+Pe//83YsWN54YUXSEhI4JFHHmHcuHHFPpISEZHaISMnjzbP/uGQz9724kC83Svm1+nEiRMZPny4XdmkSZPyt++//35+//13Zs+eTffu3Us8z+DBg7n33nsBMzC9/fbbLF26lKioqBKPefnll+nTpw8Ajz/+OEOGDCEzIwNP4H9fzOL/xo5m7NixADz77LPMnz/f7mZDdeLQOzfr1q2jc+fOdO7cGYCHHnqIzp078+yzzwLm88mDBw/m1/f19WXBggUkJibStWtXbr31VoYOHcq7777rkPaLiIhUpK5du9q9z8vL4+WXX6ZDhw7UrVsXX19f5s+fb/e7sTgdOnTI3z7z+Cs+Pr7Mx4SFhQEQf+wYADv3HaBbl8529bt163buC3IQh965ufzyy0u9nVdcr/GoqCgWLFhQia0SEZGaxsvNhW0vDnTYZ1cUHx8fu/dvvvkmb7/9NpMnT6Z9+/b4+PgwceLEc66EfnZHZIvFcs4FRgsfc2Zkl+3EPmhQzyzD/ve1YRhmZ+OkI+AXCtaK+x4uVI0aLSUiIlIci8VSYY+GqpMVK1ZwzTXXMHLkSMAcNbx7925at25d8R92Mgb8O9iHFFsOAK2aNmLN2nXcNs6ApENgdWXdunWQmwVpp+8IBTQwOyDb8sxzOHD26BrVoVhERKQ2ad68OQsWLGDlypVs376du+66i7i4uMr5sKwUSDte7K77x93M59Nm8OWUz9m9dSMvvfQymzdvLpi7JzvN/JmbBce2QNyWymljGTlfzBUREXESzzzzDDExMQwcOBBvb2/uvPNOhg0bRlJS0vmdMCcDTuwteb+t+LUabx0+mH1HTzDpsSfIzEjnxqEDGDPqNtasXG5WOBNyzhzv4EdUFqMix7DVAMnJyQQEBJCUlKQ5b0REaqjMzExiYmJo0qQJnp6ejm5OzXFij3mHBiD8dAdhw4DYaHPbpx4EnJ5aJe04JJ01h1xgUzi1D4ABIx8kNNCHr/73Erh6QnArSD4C6Qng5g31WpW7eaX9uZbn97fu3IiIiNQWxd3PsOUVv7/QdnpGBh9N+56BVw3CJSeZmXN/Z+GSZSyYeXqum9xMiNtUcKyD79wo3IiIiNQGhmHfyTcvB1zc7B9F2QWdgm0LFn5d/CcvvfsZWVnZtGrWmO8/fYMrLithrh2rY+OFwo2IiEhtkHqs4JEUQPx2CGljH24yk8x+OW5edkHHy8uThd98VMKJLXDWMHEsjr1zo9FSIiIitUFKrP17Iw9S487qRGyDhN0FQ7rLwsO3mELHdudVuBEREXF2JY0dysmAjMSz6uZBTjpknCwoK21FcDfvsn9eFVG4ERERcRY5mfaPns7IzSq+fnYqZJ4yt/0bFJSfOnBWRQu4uBd/Dq/AomUubkXLqpD63IiIiNQEpw6Yo5KCW9jfScnNMifR8wqE49vNsnqtIfkouLhCnUjzTkxpvALBN8R8FJUaB3nFhCEPX0gvdDfH1RMCm4CbJ4S0BWyQmw0Zp8C3/gVf7oVQuBEREanubLaCx0Q5GeDuY452Sj9R0JcmL6egfmYiZJ2e6M/dFxLPvhNzFvfTa1r51DXDDYDVLX/5BXNffftwU7d5wR0a19N3dVw9wdPxc8gp3IiIiFR3he+85GaZd1hO7bcbrp2/xtPZ9c8VbABcPE7/dIegpubIKt/6cHLf6QoGuHoU1Pes4/BHT6VRnxsREZHqKDfLXKMpbguc2A3A5dffwcQHxsPJvWDk0bj7ECZ/OsOsf/aQ7tMsDS5i7u9L7PvM1GsNnoX6ytgFlwAIbmn+LMRitZrnAfu7RNWQwo2IiEgVGDp0KFdccUWx+/7++28sFgsb1q0pKMxMMgNLCes9Aaz9dTp3jhxehk+32C+HYLGYfWywmI+fCgWf559/nk6dOplvPE4/YvIOJjY2lkH9LjXfuxczQqoa0WMpERGRKvB///d/DB8+nAMHDtAowGr2nfEPg/STfPH5Z3Rq35qLGniYnXJd3c3951CvbjEjlUpicTH7xBg2M8y4WsxJ/CwW+5mLCwtsbHZW9vAlNMAKuYFmh2Gf4LJ/rgPozo2IiMgZebllChXn4+qrryYkJISpU6aYi0vmpMGJPaSfPMI333zLsCsvY8Q9jxHRqDHe3t607zWAmXN/LziBR9GOuo17XF3wWArYfeQkl91wD55Ne9Dm8utYsHzV6WP9zABTL4rH3vySlq1a4e3tTdOWUTzz/Ivk5JiPmaZOncoLL7zApk2bsFgsWFxcmTrrB7BYsVgszP35N/ALBasrW7ZsoV+/fnh5eVG3bl3uvPNOUlNT89syZswYhg0bxn//+1/CwsKoW7cu9913X/5nVSbduRERkZrPMM493Lks4raYdzaCW5lDnM/1mYkHzf4qQU2Lv/uRnQ5WK7h64urqyqhRo5g69QueveNfWE7Xn/3TQrJzsrl9xLXM/PF3Hpv0MP6Bdfllzjfc9sAzNI1sQPeune37zHjWMT/X6ga+oeAVhC0tgeFj7ye4Xn1WzfuS5NRUJj73plnfK8j8abHg5+/P1KlTCQ8PZ8uWLdxxxx34+fnx6KOPctNNN7F161Z+//13Fi5cCEBAgH3fG4D09HSuuuoqevTowdq1a4mPj+f2229n/PjxTJ06Nb/ekiVLCAsLY8mSJezZs4ebbrqJTp06cccdd5T1T+S8KNyIiEjNl5MOr4Q75rPH/gYBDQuGQ+e3KRMSdppz0oR2AIuFcbfdyhtvvMHSlevo2/tiAL745keGD+pHg7AQJt09Kv/w+8fdzO8r1jN78Qa6DxoBSYcKzh3UpGDbxRUCG7Fw1Ta279jF/t/nE2E9DsArTz3IoBF3mQHrtKeffjp/u3Hjxjz88MN88803PProo3h5eeHr64urqyuhoaElXvKMGTPIyMhg2rRp+PiYw8jfe+89hg4dyn/+8x/q1zfnuQkMDOS9997DxcWFqKgohgwZwqJFixRuREREqr3sVHA9fXckJwNO7C24k2PYzFmDs5KJCvWkV9eOfDHrR/r2vpi9+w+xYvVG5n/9AXl5Nl577wu++Wk+R2KPk5WdTVZ2Dj4BQeawa9fS7yRt37WLyMhIIiIiIO4U2HLp2evSIvW+++47Jk+ezJ49e0hNTSU3Nxd///LNTbN9+3Y6duyYH2wAevfujc1mY+fOnfnhpm3btri4FCyiGRYWxpYtW8r1WedD4UZERGo+N2948uiFnSMvF+L/Mbf9wk6PJipFdgac2GWGjsQDkJ1iPoYybPaT34E5dPu0/xtxDeOfep33X0llyjfzaBQRRv9Lu/HGtN94+7Ovmfz8w7SPaoFPSCMmPvUS2dnZ5oG+9c1HU8UtdwAYhddzCm4JmUlYcu3nolm1ahU333wzL7zwAgMHDiQgIIBZs2bx5ptvlukrKvxZlhI6IRcud3NzK7LPZrOV67POh8KNiIjUfBZLwSy75ysnE9y8zG1Xj4LzZaVAVqrZkTbpkDnHi7uPOTPwmfpgP3tvKW4ceiUTnnuLr39fxZff/cIdo2/BUieSFStXcc011zJy5Ehw9cTmE8Lu3btp3bq1eaDVxQw3JUye16ZNGw4ePMjRo0cJDw8H3xD+/uMPuzp//fUXjRo14qmnnsovO3DAfpI/d3d38vJKXxG8TZs2fPnll6SlpeXfvfnrr7+wWq20bNmyTN9DZdJoKRERqf5Sj8O7F8Gy1yvunDmZ5jDnMwrP9mvLgcxkM9ic2GMuSXB8h7ncQVZywZIH58HXx5ubbryBJ194laNx8Yy5ewL4BNO8eXMWLFzIyu1H2X74FHfddRdxcXFlPu8VV1xBq1atGDVqFJs2bWLFihV2IQagefPmHDx4kFmzZrF3717effdd5syZY1encePGxMTEEB0dTUJCAllZRdeZuvXWW/H09GT06NFs3bqVJUuWcP/993PbbbflP5JyJIUbERGp/lZ9YD7aWfJyxZzPMMxFJhN2Fcy2aysUbnIyzM87saegLDfzwj7TrWDiu//7v9s5deoUV1xxBZGRkQA888wzXHTRRQwcOJDLL7+c0NBQhg0bVubTW61W5syZQ1ZWFt26deP222/n5Zftv69rrrmGBx98kPHjx9OpUydWrlzJM888Y1fnuuuu46qrrqJv377Uq1ePmTNnFvksb29v/vjjD06ePMnFF1/M9ddfT//+/XnvvffK8YVUHoth95DO+SUnJxMQEEBSUlK5O1CJiIiDLHgW/nrH3H4+iczMTGJiYmjSpAmenoU62hqnV6YuPIw7N8u84+JTr+CRTm4WxG8rqONTzwwfZVmHqTh1Is2+Nwm7CsrcvM2+O2f62wQ1MyfAc/MG33rn9zlOrsQ/V8r3+1t3bkREpPpzcT93HYBTB807MhmJBWUn9poLQRYeSn32RH1px+0fS5WHqxd41zX74fhHmGXuPhDcwr4fkKsHBDZSsKkC6lAsIiLVX+Fwk5tdcr3MU+bP1GNmB9zsdMg73WckM8kMMT71in/ElFfKeUtT+C6Rbz378GIB/BuYd5QKL04plUrhRkREqj9rwVwpZCWDi2/p9S1W+/4yZyQdNpcxKG5kU2p8GdrhZt6Nyc0E7yCzv865hoyfa79UOIUbERGp/grfrclMAp9iwo1RxvlTCve1ORerq9lPx5Zn3tnxqQd+jh8NJKVTuBERkeovp9CQ7cxE8GkAgJGXa458suXaTZRXIYtfunpBSJS5nZdjDgv3qnPh55USVdQYJ4UbERGpvnKz4dBq+w7CmUnmlP552WTH78HL//SK14UDzdmdg108zL4xmUll/+zCE/S5uJmPoaRSnZmNufCSDedD4UZERBxj9wL45WG45n1oUnQNJAAWvQB/nzV3yt8f4BrZC++DSzge3g03qw1r8SsBFLC6g80Vck/fGfCPMIdkp8WbIcbNxxwu7uoBWMy7Q+5BkHmBc9tImdlsNo4fP463tzeurhcWTzTPjYiIOMbzAeZPF3d45njpdc7m34Ds7Cxiuv0bm1cQYDGHY7t5mZ2Gz+bmbd65OdOROKBhwcKWUm1YrVaaNGmCu3vRof/l+f2tOzciIlL1ThWaLO98hmAnH8EdaLHifrK9QszRVOPXmfs2r4flZy3T0HsiRN0Iqz+G5v2gftPzbblUInd3d6zWC5+CT+FGREQq19/vQ/RMuP5zqNcKjm2DD3sWrbfjV1j2HwhpY95lGfzfc57aauTimX7UvPtzZkbbsChIPT1hX497zTs6F99mPnLq/0gFXphUVwo3IiJyfjJOwe9PQKdboMllJdf740nz52cD4ImDsH5q0TpZKTBrhLkdG23+XPdFyefsPRGSj8CW2eb7gIYF+wrPK9NyIDS9vPTrEKejcCMiImVny4PfHoWwTnDgL9g003w9X8IopC3fFWxnJUFybPHzzLwaUfY2RPaCAS+Y280HwMLnYfinBft9C81D4x1c9vOK01C4ERGRsvtnDqz9zNz2LNTZd+59MOx9+7qGAd//n33Zhz3NOz7n656/zUdbZ3S8yXwV5uYFnUZCeoL5iEtqHS2cKSIiZRe3pWC78Jwx0dPh0FrIyzVHJO1bCslHix5/rmATdTU8cRguGlVQZnU1yyZsgvpt7JdiKMmw9+GWb6ACOqdKzaM7NyIiUrq4rfDXZLjsUTi+s+R6n18Blz4MB1eZj6y6jC39vPWioH47M6xs/sYs86kHHn7wr//BhmlmWcPuZpmHX4Vcjjg/hRsRESndZ1dAbkZB593SrHizYHv9lIJt72DzMdEZ49dBcAtzOzW+INx4FFoz6tbvYOX/zEn+RMpB4UZEREoWv90MNhei79MQ0ADm3mO+v/bjgmAD9qOb0k4UbLcYYL5EyknhRkSktjMM8zESQKPe5rDsrGT48T6z78yFatYXIrqCZx1zPpoWVxRTpz/sXWTf10bkPCnciIg4O8MoutSAYZhrO4W2g5gVMOdOsFih4wjYNKvowpMleWw/7F4IP9xeUBbQEB6Ihpk3m+cJ72yWRw0u+Tw3z4CkIxDcvDxXJlIshRsREWe2dzF8Nw6ungxthxWU754PX99ozt7bdrhZZtggekbZz935NvAKBN96BWWh7WHAi+DiCiO/K/nYs7l5KdhIhVG4ERFxZl/fZK7dNHs0tD09dNswYNcf5nb6CTi1v/RzWKxm8Dnj0ofNUHTmEVLhuWTuWqEFKcXhFG5ERJzZ2YtSGoY5+unIuoKyQ6vt64R1hNhNBe8b9Yb9K8ztelHQ/1n7+r4hcPef4O6jYCPVgmY3EhFxRnsWwrwHipaf2GsfbMDsPHyGZx0Y9iHcv6GgLCACOtxsbre4svjPC20PQVppW6oH3bkREXFG068rWhazAr68uvj6XkFw51KzD42nv/0+3xDo/zxc/H9miBGp5nTnRkSksuXlwpEN5s/KcuoA7FkEXw2HY8UsTAmw5JWSj+9+NwQ2sg82XcaafWt63GsuY9Cwm9nxV6SasxiGYTi6EVUpOTmZgIAAkpKS8Pf3P/cBIiIXasGz8Nc70Pcp6PNoxZ8/bit81Lvs9ZteDi4eEBsNY36BxAPQtF/x6zDZ8sq2lpNIJSvP7289lhIRqWx/vWP+XPJy2cNNXq45nPps8Ttg6hDocTdc9ggkHir9jkxxBvzbfLx0pvNv4dmCz6ZgIzWQwo2ISFVx8ylbvRVvwbLXYeyvENbJHPGUk27OWbNtrrlG0+KXzCHai14sfzt862tUkzg1hRsRkcqUl1Ow7V23bMcsesH8+Wlf86dnAIRfBPuWnFXvrGBTrzWM+w2mXWM/lLvzSNi3HJIOmu99gsvefpEaSOFGRKS8DAOOrIeQ1ubcLqVJPFiw7eJmv2/+03DsH7h5Jrh5Qupx+OXBoufITCoabM7W9lq4Yaq5PeYX2P6T2c5GvSCoCfzyMKz9zNyvR03i5BRuRETKa8ts+OEOaNIHbptrPuIp6TFP0uGC7fRCK14nHoSV/zO359xpjnRy94XUuHN//sBXIbI7bP0B/n4PrG4w+L8F+z38oNMt9sdcfIcZbpoXs2iliJNRuBERKa/1X5o/Y5bBe13NOzg3l7AmU/KRgu3MRPMxlYsbbP62oHzbj+bP7NSix7t6QW5GwfvB/4Vud5jbDbpAz/GQl3XuR00hUfDgtrI/GhOpwTTPjYhIeXkHFWyf3As7fjYfAZ0tNwvittiX7Vlozkmz8atzf06rwXD1W/ZlnW61f+8fBoGNy9RsAhqYj79EnJzCjYhIeXkFFi37rL85mqmwuffAqg/sy2beDO90OPdilUHNYMRMaHONfbm7d7mbK1Lb6LGUiEhpDKNofxpbMTMNH1kPX10L4/4wV9xOiYWt3xfsD2kD8WfNHHztJ+bIqDOPrjrcZM4GvGU2RA0xy9x94NlT8Nfb5qKVInJOmqFYRKQk0TNh7t3m9k3TofVQs+Pv9OHlP9e4P8y7OGf61zToCncsMrfzcsDqqrlnREpRnt/feiwlIlKSM8EG4JuR5s+ZN5/fucI7w43TCibya3VVwT4XNwUbkQqkx1IiImdb/l/Yt7T4fXnZ5T9fWEdw9TC371wCu+dD93vOu3kiUjqFGxGpnTKTzf4sxU1ot/jfxRxwnndW7t9gP7qqXivzJSKVRuFGRGoPm81cCdsvFN7pZM4P4+YN17xvBpC6zcEvvISDDUg6UsK+YtRvBwNfgbrNKqDhIlIeCjciUnus+QR+f8y+LCcdvhtrbrv5wMTNJR//dhv79xM2wSeXQ8Yp+/LeE2DAeSxoKSIVQh2KRaT2WPhc6ftz0iA1vmh53Rb27yMuhlu/NyfPu3GauXL37Ytg9E9w8e3Q5/GKarGInAfduRGR2iM389x10s4KN00ugxu+hNebmO8bdIXbF9rvv2uZ/XsRcSiFGxGRwqadnhHYOxjuWWmu2VS407F/SX1yRKS60GMpEXFeB/6GHb+ALQ9mjy3fsc36gV/9gmDTZazZ+bjfMxXfThGpUA4NN8uXL2fo0KGEh4djsViYO3duqfWXLl2KxWIp8tqxY0fVNFhEqof0k5CdXvB+9wL4uA8cXAXxO+D1ZvB8AEy5CmbdAnPvhX9+KP5cPcdDu+uKljfvb/9+yFvw6D6o17LirkNEKoVDH0ulpaXRsWNHxo4dy3XXFfOXSwl27txpN/VyvXr1KqN5IlIdZSbB5A7m46Hxa8yyGdebP78YWPwxm2cVX+4VBANOz2lTeB2ogIbmityFWa1g9Tr/dotIlXFouBk0aBCDBg0q93EhISHUqVOn4hskItXf4bWQnQIJOyEjEbzqnP+5rnnfDC2F+YXD+LXgpiAjUlPVyD43nTt3JiwsjP79+7NkyZJS62ZlZZGcnGz3EpEaLO1EwfZf79jfcSmriVtg9M/QqtA/rlqe3u7zqIKNSA1Xo0ZLhYWF8cknn9ClSxeysrL46quv6N+/P0uXLuWyy4offvnqq6/ywgsvVHFLRaRC5GSCm6d9WeKBgu0/3yr52ND20Ppf4BUIv04qtMMCdSLNV2HXfQZxW6Bh9wtutog4lsUwDMPRjQCwWCzMmTOHYcOGleu4oUOHYrFYmDdvXrH7s7KyyMrKyn+fnJxMw4YNy7Rkuog40LF/4JO+4OoJt34LkT1g+8/wza2lHzf6p6JzzSQegqWvQvQMc86atsMqrdkiUjmSk5MJCAgo0+/vGvlYqrAePXqwe/fuEvd7eHjg7+9v9xIRB0s7Ad+Ogt2FJsOL3QwfXgL/bQnx2+HDXubaT1lJZkfhHb/A7DHnPnedRsWUNYRhH8DjhxRsRGqBGvVYqjgbN24kLCzM0c0QkbLIOAX7lsK2ebDtR/P1fJK57+NLC+p90KPosbNuKdi+8iXodb+5kOXMmyHu9HpQAQ0hIKLkz/fUP25EagOHhpvU1FT27NmT/z4mJobo6GiCgoKIjIzkiSee4MiRI0ybNg2AyZMn07hxY9q2bUt2djbTp0/n+++/5/vvz6NDoYhcmLwciN8G9dvD/uUQ2sF8lPTTAzD4DWh+RdFjvr8D9iwo5ly5ZfvM4FZw95/g6m6+D2gAdy6DY1vMGYW9g+xnExaRWsmh4WbdunX07ds3//1DDz0EwOjRo5k6dSqxsbEcPHgwf392djaTJk3iyJEjeHl50bZtW3755RcGDx5c5NwiUsl+nQTrp5qhJm4zhF8EJ/aaj5GmX1dwR6aw4oINQNKhc39e+EVwzXsFweYMqxXCOpa7+SLivKpNh+KqUp4OSSJSiucDzrE/yezIu34quHqYQ6yLO6b7PZCwC/YuKigbNx9CWsNrDc337W+E6z6tsKaLSM1Tnt/fNb7PjYhUkswksFjBw68cB1mA0/9eSjkGk9sV7GpzTfGHrP7Q/n3HERB5ejh2aHtzeHbHm8vRBhGp7RRuRKSo3Cx4vSm4esHjB+1n8TUMsFhKOLDQjeDCd2IANs089+f2HF+wHAKYE+2d2AsRXcrcdBGRGj8UXEQqQdJhsOWayxxknIKj0fDHU7BnEfynMaz9/NznmHuP/fs/3y7Yvn2ROX8NmH12zogaYh+kvOoo2IhIuenOjYgUlVjQkZ+0ePikj7n993vmz18eOv9zh7aHiK5wy7cQswwuexR+fhDST0DExed/XhGR0xRuRMReShx8NazgfWp8+c/R+FLYv6L4fd7B5s+mfcwXwLUfFl9XROQ86LGUiNjb/K39+1Mx5z6m1ZCCbf8GRZc/KKz9DefXLhGRMtKdGxEp8MskWHvWkOsDK8993NDJ0P56WPY6XP85eAXBuimQcrSgzsQtcGQ9tBlWkS0WESlC4UaktrHZIDu16FIEhlE02AAc/Lv0803cCr4h0G64+Trj4e3wWiPITISQtsWvxC0iUgn0WErEGaUlwG+PQdzWovuW/Qdei4R9y2Dr9+bEem9GwZ6FReuCfefibneZyx20uw5aDoLrvzAXpSzJmF+g3fVw01cXdj0iIuWgGYpFnNH3d8CW031nWgyEei3N+WNsefDvuma5Zx3zrkpZXfYI9Hu6olsqIlImmqFYpLZIPW6u1xTWEXIyC+aEObKuoM7uP8xXeGfwL7Ri9rmCzb/+B8e2FcwgHFDKHRoRkWpE4UakJps+3Fy08oxWQ+CGqeDiXrTud+PKd+6LRpmPpM6Em/ptz7uZIiJVSX1uRGqq9JP2wQZg5y8QPQNc3Mp+nmcSSt5XJ9Ic5XTLt+bEeyIiNYDCjUhNFLsJ3mhW/L7EA2A9K9z0HA+3fl/wPvwi8PCHm782g5BPPbPcJwTqNIIBLxbUrRMJLQdWbPtFRCqRHkuJ1BSGYa7z5B0EK94Cw1Z8vRN74egG+7LAxtDiCug0ErZ+B9d9BnULhaORP5hrP/V72r5cRKQGUrgRqe5OHYDcTFg/FVZ9AOPmF9+n5ozt8+zfW1ygUW9ze+g7MORNcPO0rxPWAW6YUqHNFhFxFIUbkeoqOx1ilsMPd0JeNuRmmOW/P1763DKFPbYfXL0KwoyLq/kSEXFi+ltOpLqa/xSs+6Jo+dENcHxHycd5B5t9ZryDwCuw8tonIlJNKdyIVDdpJ8zlEYoLNmfkpBctezoeEnaZ89F41am05omIVHcKNyKOdmo/JB2GxpeY6z59MdAsK4t6rc0OwIPfAFcPCG1fmS0VEakRFG5EHO2djubP2xebI6BO7LbfX7cFBDU1ZxkG+Nd75urbVzxnrsQtIiJ2FG5EHGnpfwq2P+sHERcXrTN+LXz/fwXvL7rNfImISLEUbkQqW04GpMZDYCPzfW4WpB6DL4cWffx0eK35M7wzHN0IEd3AYtG6TiIi5aBwI1LZfhxvTpx36cPQ7xmYPQZ2/lr6MZc8BL71IaDB6fcT4dBqaHddZbdWRKTGU7gRqWxbvzN/rnjTXNrgXMEGzD42oe0K3nsFwrjfK6d9IiJORmtLiRTHlgf7lkJm8oWdJzfb/v1PDxStc+8qCGoG3e8pKAtsfGGfKyJSi+nOTQVJzszh8xUx2AyDh69s5ejmyIVa+zn89ghE9iz/HZO8XPh5InjXhY4jCsp9QyE1zr7uyB8gpDU8cHotqEa9wOoKHr4X1HwRkdpM4aaCZGbn8c6i3VgtKNw4g/Wn11k6+Hf5jstOhxnXw4G/zPd/TTZ/1ouC2+bCW1EFde/+y/7RE0Cbf51Pa0VEpBCFmwri5mI+4bMZkJtnw9VFT/xqtJJW3LarY8D+FeZoKFdPyDgJPz9ortx9trBO4B8GEzbDTxOg+91Fg42IiFQIhZsK4u5aEGZy8gxcXRzYGLlwpYUbwzAfO235zlwmoSwuf8z8GdgIRs290NaJiEgpdHuhgrgVulOTnVuGf/VL9VY43JzYC/MegBVvQVqC+X791NKDzcBXwLOO2X/m4V3m6CcREakSunNTQdxcLPnb2XkKNzWOzQZbvjU7ENeJtA83858uGL59dCO0G178OYJbmTMMdx0LEV2h9b8AA/zqV3rzRUSkgMJNBbFYLLi7WMnOsync1ATL/wsxy+GWb8DNC5a/AUtfMfe1v9F89HRG4Xlpts8zX2cbNx8iu9uX1dGswiIijqBwU4HcXc1wk6PHUo6XmwUpcQVLHpxt8b/Nn1u/h84jC4INmHdwzuYbCmEdYPf8grIrXzKHeicdhvBOFdZ0ERG5MAo3FejMoynduakGZt0CexbC7YvMR0SFFR7NlJkEOZnnPt+AF6BZf1j8otl/pvFl5vpPViv4BFds20VE5IIo3FSgM52K1aG4Gtiz0Py57ouCcHN4PZzcB9kpBfX+eNJ8labRJdDxZnP7X/+r+LaKiEiFUripQGeGg+fozo1j2Qp9/9bTY/K3fAff/1/Zz+HqCV3Hwf4/4ebpFds+ERGpVAo3Fchdd26qh8JLHBgG/Pk2LHz+3Md5B0PTPtBykDnhXuNLKq2JIiJSeRRuKlDBnRvjHDWlUiUeKthOiYWNXxVfzy8Mrv0YfOrB3kXmKCkN2xYRqfEUbipQfp+bvDwHt6QWO7YNvriy4P2ZvjdneAWaHYrdfMy1nXzqmuX121RdG0VEpFIp3FSgM3dusnN156ZSpJ+Elf8zJ8nzj4C/3jaHaHe+1exnk34Cvr6p9HPcNMOc18bdtyDYiIiIU1G4qSg5GbTL/YcAaxzZeZ0d3ZqaKysFZt0KUVdD9zvt9319ExxeA0fWQ5trYNGLZvmqDyBhN+RlFdSN7AWtry4YCdV7AjS/Ahr3rprrEBERh1G4qSipx3jhxCQy3dz4JWeMo1tTc637AmKWma/C4SYv1ww2YO7LLTQ3zbGt9ue46j/Q425z2y/MXEqh3XVgsSAiIs5P4aai+IYC4GnJgcxEQFPvn5f0kwXb73Qy3w//GFzc7OsdWl2wHd4Zut8Nc+81lzzoVigUlbQOlIiIOC2Fm4ri5kmq1R9fWzJu6XFAe0e3qGYqvGDlqRjz58ybS64/7ENoPRQ8/KBBF/OnVYvdi4jUZvotUIGS3cwOqm7p8Q5uSQ2SsBtiVsCcuyH1OKSW47vr+zR0usUMNADBLcAvtHLaKSIiNYbu3FSgFLd6kBWDe8YxRzelejMM8xFSzHJIPlxQvmmmfb06keZ6TuunmO+DmsLQd80FMTvcUHXtFRGRGkXhpgKluJkLKHpl6s5NqY5uhE1fn7verd9DvZYwdDLEbgbvuhDQoNKbJyIiNZvCTQVK8QwHoE7aPge3pJrKToM/J8Py10uu4x0M134ELQbYl4d1qNSmiYiI81C4qUBHAzpBLEQkbTAfvdS2oceZyZB4AELbgy0PMhLN2YD/mQPpCbBtHqQcLfn4oe+YQ7bP9KERERE5Dwo3FSgpqBPZhgv+Occh8SAENnJ0k6qGLQ92/garPoQDf0KrIbDzl3Mf16wf7F1sbkdcDF3GVGozRUSkdlC4qUCBdQLYZTSknWU/xG1xvnBzYq+5yKSnv335ynftV90uS7B5eKc5sinjFBxeDw0vrtCmiohI7aWh4BWonq8H22ynA03cFjgZU76hzdXZ8V3wv4vgy6H25Wkn7INNSZ6MhZu/Nkc89Xu6YMi2VyC0uAI8Ayq8ySIiUjvpzk0FCvbzYIXRGFgGy14zX3VbwPi1Nbf/jWHAyX2wcZr5PjYavr4ZBr8BOenw04SSjx3wojlsu2F3cPeGqCHmS0REpBIp3FSgYF93fs7rwSOu3+JryTALT+w2w0HdZo5t3Pmw2eDrG2HPAvvyXb+Zr+I8EG1OzBfSGvwbaLZgERGpcvrNU4GCfT04QQDjc+6333FgpWMaVB6nDsCaT82O0F/fZE6wd+DPosGmOIGNoe9T8OxJCGoCLa8013hSsBEREQfQnZsK5OnmQoCXG0szOnHwmu+J/PE6c8fu+XDRbY5tXEkOr4eMkzD/GTi+HX6dZJbv+h3aDDv38bfNhWZ9K7OFIiIi5aJwU8Ea1PEiKSOHPV7tibxzKXxyuTlM+uQ+c6SRqxe4OPhrt+WB1QUyk+CzfiXX2zbX/Hnx7bD2M3O7Xmu4/gtzO6gpuHlWalNFRETKS+GmgkUEerEtNpnDpzKgVSdzQru4LfBu54JKvSfCZZOqZrK6rd/Dgb/hyn/DH0/Cui/A3dd8lHRs67mP928Ag96ABl2h8SXm4yYREZFqTOGmgjUI9ALgyKkMc4TUsA9h6hDzLskZf002XxM2gcWlIDCcjAHfEHD3ubBGHI2Gzd+aI5sO/GWWrf20YH92aunBpk4kBDaBmGXmiCerFTqNuLA2iYiIVBGFmwoWEegNwMGT6WZBaHsYvw5+mlh0crt3Opo/e9wL7W+Az/pD075w2w/29fJyYPcCc0bfwo+B9i4x78QERED/58x9ORnw7W1mx+Dz0f4GuOxRc5HKY1uhaZ/zO4+IiIiDKNxUsOYhvgDsOpZSUOgbAiO+NlfDXv0xHN8JRzcU7F/1gfkC2LsIdv0BAQ1h/5+QfBh2/g4JO839g16HE3vMAPLVsIJz+NQzH3f9+kjZgs2EzZCXDVZX8AmGH++D5lfARaMK6ijYiIhIDWQxDMNwdCOqUnJyMgEBASQlJeHv73/uA8opPjmTbq8swmqBbS9ehaebS/EVj0abnY2pwK/fP8IMQwA9x8Pf75nbHUdAnUbmpIJgBqN+T1Xc54qIiFSy8vz+1p2bClbPz4MgH3dOpmWzIy6FTg3rFF8xvBM8k2D2y9k2F74bd+EffibYXPaIucTBlS/B4bUQ0gbcvKHtteadGmdb80pERKQQzbJWwSwWC51PB5rV+06UXtnF1RyS3e46uH8DXPOB/RpLF42CcfOh9en1nPwjzMdSZzTpA3cttz9nUDO4dNKZxkDDbuDha3YKDomC4Obg4nZhFykiIlKN6c5NJejVPJhFO+L5a+8J7upTxmUX6jYzX60GgcUK+5aak+N5BkBkd/u6Fit4B5mhCOC5RPj9CTMoXflSzV3HSkREpAIo3FSC3s3rArAm5gRZuXl4uJbQ76Y43kHmz7bDSq7T7Q779xYLDHqtfI0UERFxUnosVQla1fcj2NedzBwbGw8mOro5IiIitYrCTSWwWCz0ahYMwMo9CQ5ujYiISO3i0HCzfPlyhg4dSnh4OBaLhblz55b52L/++gtXV1c6depUae27EGceTf2pcCMiIlKlHBpu0tLS6NixI++99165jktKSmLUqFH079+/klp24S5pUQ+AjYcSOXgi3cGtERERqT3OK9wcOnSIw4cP579fs2YNEydO5JNPPinXeQYNGsRLL73E8OHDy3XcXXfdxS233ELPnj3LdVxValDHi8ta1sMw4Jt157kUgoiIiJTbeYWbW265hSVLlgAQFxfHgAEDWLNmDU8++SQvvvhihTbwbFOmTGHv3r0899xzZaqflZVFcnKy3auqXHdRAwB+3xpXZZ8pIiJS251XuNm6dSvdunUD4Ntvv6Vdu3asXLmSr7/+mqlTp1Zk++zs3r2bxx9/nBkzZuDqWrZR7K+++ioBAQH5r4YNG1Za+87WNyoEdxcre4+nsf7AySr7XBERkdrsvMJNTk4OHh4eACxcuJB//etfAERFRREbG1txrSskLy+PW265hRdeeIGWLVuW+bgnnniCpKSk/NehQ4cqpX3F8fd0Y1jncAA+XR5TZZ8rIiJSm51XuGnbti0fffQRK1asYMGCBVx11VUAHD16lLp161ZoA89ISUlh3bp1jB8/HldXV1xdXXnxxRfZtGkTrq6uLF68uNjjPDw88Pf3t3tVpTsubQrAH9viiElIq9LPFhERqY3OK9z85z//4eOPP+byyy9nxIgRdOzYEYB58+blP66qaP7+/mzZsoXo6Oj81913302rVq2Ijo6me/fu5z6JA7So70e/qBAMAz7/c5+jmyMiIuL0zmv5hcsvv5yEhASSk5MJDAzML7/zzjvx9vYu83lSU1PZs2dP/vuYmBiio6MJCgoiMjKSJ554giNHjjBt2jSsVivt2rWzOz4kJARPT88i5dXNnZc1ZfGOeGavO8yDV7Skrq+Ho5skIiLitM7rzk1GRgZZWVn5webAgQNMnjyZnTt3EhISUubzrFu3js6dO9O5c2cAHnroITp37syzzz4LQGxsLAcP1vxh1N2bBNEhIoCsXBtfrTrg6OaIiIg4NYthGEZ5D7ryyisZPnw4d999N4mJiURFReHm5kZCQgJvvfUW99xzT2W0tUIkJycTEBBAUlJSlfa/+XnzUcZ/vZEALzeWPXI5dbzdq+yzRUREarry/P4+rzs3GzZs4NJLLwXgu+++o379+hw4cIBp06bx7rvvns8pnd6gdmFEhfqRlJHDpyvU90ZERKSynFe4SU9Px8/PD4D58+czfPhwrFYrPXr04MABPXYpjovVwsQrzCHsX/19gBOpWQ5ukYiIiHM6r3DTvHlz5s6dy6FDh/jjjz+48sorAYiPj6/yodY1yYA29YkK9SM5M5fn5v3j6OaIiIg4pfMKN88++yyTJk2icePGdOvWLX+Np/nz5+d3DpaiXKwW3ri+Iy5WCz9vjmX1vhOObpKIiIjTOa8OxWCuKRUbG0vHjh2xWs2MtGbNGvz9/YmKiqrQRlYkR3UoLuypOVuYsfogUaF+fH9PL3w8zmtEvoiISK1R6R2KAUJDQ+ncuTNHjx7lyJEjAHTr1q1aB5vqYkL/FgT7erAjLoWn5251dHNEREScynmFG5vNxosvvkhAQACNGjUiMjKSOnXq8O9//xubzVbRbXQ6If6efDTyIgB+jD5CXFKmg1skIiLiPM4r3Dz11FO89957vPbaa2zcuJENGzbwyiuv8L///Y9nnnmmotvolLo2DqJLo0BsBkyavQmb7byeDoqIiMhZzqvPTXh4OB999FH+auBn/Pjjj9x77735j6mqo+rQ5+aMLYeTuPHjv8nIyWNC/xY8OKDsq52LiIjUJpXe5+bkyZPF9q2Jiori5MmT53PKWql9RAAPX2kGmncW7Wbz4UTHNkhERMQJnFe46dixI++9916R8vfee48OHTpccKNqk/+7pAmD2oUCcO+MDSSmZzu4RSIiIjXbeY1Bfv311xkyZAgLFy6kZ8+eWCwWVq5cyaFDh/j1118ruo1OzWKx8OhVUfy97wSHT2Xw4dK9PDG4taObJSIiUmOd152bPn36sGvXLq699loSExM5efIkw4cP559//mHKlCkV3Uan1yTYh/9cZ97x+nj5PpbujHdwi0RERGqu857ErzibNm3ioosuIi8vr6JOWeGqU4fiwgzD4Km5W/l69UEa1PFi/oOXaXI/ERGR06pkEj+pWBaLhaeHtCYi0IsjiRn8d/5ORzdJRESkRlK4qUa83V15aVg7AKb8tZ9pf+93bINERERqIIWbaubyViHc3acZAM/++A+rtLimiIhIuZSrU8fw4cNL3Z+YmHghbZHTHruqFSfTsvh23WGemrOFXx64FE83F0c3S0REpEYoV7gJCAg45/5Ro0ZdUIPE7H/z1JA2LN4Rz97jaTwwcyMf39YFi8Xi6KaJiIhUexU6WqomqK6jpYrz994TjJ6yhuxcGw9e0ZIJV7RwdJNEREQcQqOlnETPZnV5eog5od/bC3cxa81BB7dIRESk+lO4qeZG9WzMhP7mHZs3/thJalaug1skIiJSvSnc1ADj+zWnSbAPJ9KyuW/GBpIzcxzdJBERkWpL4aYGcHOx8uTg1lgssGzXcW77bDWZOdV3FmgRERFHUripIQa0qc/su3oS6O3GpsNJvLNot6ObJCIiUi0p3NQgXRsHFSywuWwvS7TApoiISBEKNzXMgDb1ubFrBDYD7v96I+sPnHR0k0RERKoVhZsaxmKx8NKw9vRoGkRqVi43fbyKDQdPObpZIiIi1YbCTQ3k7mrl45Fd6dWsLrk2g0dmb1IHYxERkdMUbmqoAG83Prj1Iur5ebD3eBqjPl/DidQsRzdLRETE4RRuarA63u78b0RnPN2srNl/kkmzN5Fnq1WraYiIiBShcFPD9Whal89HXwzAkp3HeXruFge3SERExLEUbpxA7+bB+WtQzVxziKl/xTi4RSIiIo6jcOMkbr+0KXdc2gSA53/axifL9zq4RSIiIo6hcONEHhkYxdUdwgB45dcdzNQq4iIiUgsp3DgRd1cr/72hI1e2qQ/Aiz9tY3tssoNbJSIiUrUUbpyMp5sLH43swiXNg8nIyWPc1LWs3Jvg6GaJiIhUGYUbJ2S1Wnjvls40DfYhNimTWz9bzfx/4hzdLBERkSqhcOOk6ni7M3d8b67uEIZhwD0zNvDrllhHN0tERKTSKdw4MX9PN966sRNXdwgjz2Zw74wNfLf+sKObJSIiUqkUbpycu6uVt2/qxLBO4QA88cNmftMdHBERcWIKN7WAm4uVN2/sRN9W9cjJM7hnxgZe+20HNi3VICIiTkjhppZwsVr4bPTFXNHaHCb+0bK9vL1wl4NbJSIiUvEUbmoRF6uFT0d14eVr2wHwv8V7eHruFpIychzcMhERkYqjcFPLWCwWbu3eiPv6NgNg+qqD3Ddjg1YTFxERp6FwU0s9MjCK16/vAMCfexIY//UGsnNtDm6ViIjIhVO4qcVu7NqQ/97QEXcXK79tjWPMlDWkZ+c6ulkiIiIXROGmlru+SwQfjrwIH3cXVu49wTXv/cXJtGxHN0tEROS8KdwI/VvX57PRFxPs68Hu+FT+9d6frIk56ehmiYiInBeFGwGgZ7O6zLqzO0E+7hw+lcHYKWuYt+mo5sIREZEaR+FG8jUP8eOPiZfRrUkQadl5PDBzI2OnriUrN8/RTRMRESkzhRuxU8/Pg89Gd2Vkj0g8XK0s23Wcp+ds1VBxERGpMRRupAh/TzdeGtae92+5CIDZ6w9z11frdQdHRERqBIUbKdEVberzzNVtcHe1snD7Me6ZvoG0LA0VFxGR6k3hRkr1f5c04YvRF+PhamXxjnj6vLGEZbuOO7pZIiIiJVK4kXO6pEUw02/vTkSgFwmp2Yz+Yg2v/74Dw1A/HBERqX4UbqRMLm4cxMKH+nB9lwgAPli6l9u/XEd8cqaDWyYiImJP4UbKzNPNhf/e0JF/X9MWiwUW7Yhn8Lt/sjMuxdFNExERyadwI+V2W8/G/D7hMqJC/UhIzeKGj1by/pI9Gk0lIiLVgsKNnJdWoX7MvKMHTev5kJyZyxt/7GT81xs1o7GIiDicwo2ct0Afd+bc05vHB0Xh7mplwbZjXP2/P1m974SjmyYiIrWYwo1ckABvN+7u04w3ru+A1QLbYpMZ9cUa/vgnztFNExGRWkrhRirENZ0asHRSXy5rWY+sXBt3fbWeR2ZvIj5Fo6lERKRqKdxIhYms682no7pwTadwwFy24eZPVrHveKqDWyYiIrWJwo1UKA9XF96+sRMfjeyCn4cr+46nMeDt5Xy79pCjmyYiIrWEwo1UOKvVwlXtQpk67mLaNfAnz2bw6PebmTBrI7uOaU4cERGpXAo3Umm6NArih3t6c23nBgD8GH2Uwe+sYPqqA5xKy3Zw60RExFlZjFq2QFBycjIBAQEkJSXh7+/v6ObUGusPnOQ/v+9kTcxJABoGefH56ItpEeKLxWJxcOtERKS6K8/vb925kSrRpVEQ08Z1Y2zvxgAcOpnBlW8v56Vftju2YSIi4nQUbqTKeLq58NzQtsy8owfW0zdrPv8zhv5vLuWYFuAUEZEK4tBws3z5coYOHUp4eDgWi4W5c+eWWv/PP/+kd+/e1K1bFy8vL6Kionj77berprFSYXo2q8u2F6/KX2F87/E0bvt8NduOJju4ZSIi4gwcGm7S0tLo2LEj7733Xpnq+/j4MH78eJYvX8727dt5+umnefrpp/nkk08quaVS0TzdXHhteHvu69sMgF3HUrnm/T95Z+Fu0rJyHdw6ERGpyapNh2KLxcKcOXMYNmxYuY4bPnw4Pj4+fPXVV2Wqrw7F1U9sUgbP/vgPC7YdAyDY14N3bu5E7+bBDm6ZiIhUF7WmQ/HGjRtZuXIlffr0KbFOVlYWycnJdi+pXsICvPjkti68c3MnGtTxIiE1i1s/W82Tc7aQkZ3n6OaJiEgNUyPDTUREBB4eHnTt2pX77ruP22+/vcS6r776KgEBAfmvhg0bVmFLpawsFgvXdGrAj+N70zEiAICvVx+k/fN/8Py8f9ThWEREyqxGhpsVK1awbt06PvroIyZPnszMmTNLrPvEE0+QlJSU/zp0SMsAVGfBvh78cG9v7ri0CT7uLuTaDKau3M/wD1ayM06zG4uIyLnV+D43L730El999RU7d+4sU331uak5MnPyWLj9GK/+uoMjiRn4erjy72FtGdapgSb+ExGpZWpNnxsAwzDIyspydDOkEni6uXB1h3Dm3NuLDhEBpGbl8uA3mxj0zgoWbT9GNcnlIiJSzTg03KSmphIdHU10dDQAMTExREdHc/DgQcB8pDRq1Kj8+u+//z4//fQTu3fvZvfu3UyZMoX//ve/jBw50hHNlyoS4u/J9Nu7c3efZri5WNgRl8L/fbmOSbM3K+CIiEgRro788HXr1tG3b9/89w899BAAo0ePZurUqcTGxuYHHQCbzcYTTzxBTEwMrq6uNGvWjNdee4277rqrytsuVcvf043HB0Uxpldj3py/k+83HOb7DYeZ/08c13eNYFzvJjQM8nZ0M0VEpBqoNn1uqor63DiHb9cd4vl5/5B+eqi4h6uVR6+KYnTPRri61PinrSIicpby/P5WuJEaKzMnj+W7jvP+0r1sOpQIQJswf968sSOtw/RnKyLiTGpVh2KpvTzdXLiybSjT/68bt3SPBGBbbDLDP1jJq79uJyFVHc1FRGoj3bkRp7E/IY0J30Tn38UJ9nXnzRs70adlPcc2TERELpgeS5VC4ca52WwGi3fE88YfO9l5zJz07+LGgYzt3YTB7cMc3DoRETlfCjelULipHTJz8nj5l+18tepAflmXRoFc3yWCm7o2xGrVJIAiIjWJwk0pFG5ql/UHTjFj9QF+2HAkv2xEt0ieGtIaXw+HzoQgIiLloHBTCoWb2mnF7uPc9vma/Pdebi5c3yWC8f2aU9/f04EtExGRslC4KYXCTe2VlZvHfTM28vfeBNJOz4/j7+nKnZc15eoO4TQO9nFwC0VEpCQKN6VQuJGcPBtP/LCF79Yftivv07IeL/yrrUKOiEg1pHBTCoUbOSMtK5eZaw7y/YYjbI9NBsDVamFUz8Y8OTgKA3DTbMciItWCwk0pFG6kONNXHeDLlfvZHZ+aXxbg5cY3d/UgKlT/nYiIOJrCTSkUbqQ0P0Yf4dkf/yEpIye/7I5LmzBpYCs8XF0c2DIRkdpNyy+InKdrOjXg1wmXMqhdaH7ZpytiGPTOCn7bEktcUiZ5tlr17wERkRpHd25ESnD4VDojPl3FoZMZRfbNubcXnSMDHdAqEZHaSY+lSqFwI+V1Mi2b/87fyderD9qVtw3356ORXWgY5O2glomI1B56LCVSgYJ83Hnl2vbs+PdV3NajUX75P0eTGfzOCn7efJSM0/PmiIiI4+nOjUg5xSdn8r/Fe+zWrbJaYHSvxjzQrwWBPu4ObJ2IiHPSY6lSKNxIRcnMyWPc1LWs3HvCrtzP05XrLorgkYGt8NH6VSIiFULhphQKN1KRbDaDk+nZzF53mK/XHLDrfOzl5sLDV7bktp6NNIxcROQCKdyUQuFGKsuptGxe/2MnM9ccxM/TlZTMXACaBPtwx6VN6dOqHvV8PXB3VVc3EZHyUrgphcKNVAXDMPj8zxg+Xr6P4ylZdvvuuqwpkwa20tIOIiLloHBTCoUbqUrJmTm8u3A3v22N40hiwSOrFiG+jOrZiL5RIUQEaii5iMi5KNyUQuFGHMFmM5ix+gBLdh4n+lAiJ9Oy8/dd2iKYZ65uQ5NgH93NEREpgcJNKRRuxNGS0nN4e+EufthwmOTT/XLOuK1HI0Z0i6RNuP7bFBEpTOGmFAo3Up38GH2ESbM3kZNX9H/DKWMupm9UiANaJSJS/SjclELhRqobwzD4Zu0hHv9hS5F9HSICaFbPlwf6t6BJsI8DWiciUj0o3JRC4Uaqs8ycPD5atpfJC3cX2XfzxQ2547KmNKvn64CWiYg4lsJNKRRupCbIybOxMy6FaX/v59t1h/PLLRYY1C6Ukd0b0SbcnzreWupBRGoHhZtSKNxITWMYBit2J/DVqgMs2HbMbt+IbpFc3yWCiEAv6vt7OqiFIiKVT+GmFAo3UpPtiEvmse+3sOlQol25u6uV4Z0bMOGKFni4uhCkxTtFxMko3JRC4UZquozsPH7adJTUrFxmrD7A3uNpReqM6dWYJwZHaU0rEXEaCjelULgRZ2IYBrFJmby/ZA8zVh+02xfg5Ya/lyuXNA/m2s4RXNw4EIvF4qCWiohcGIWbUijciLPaEZfMou3xWC0WPlq2l6SMnCJ1JvRvwe2XNsHP080BLRQROX8KN6VQuJHaIDkzh1V7T/DZnzGsiTlZZL+bi4V3bu7M4PZhDmidiEj5KdyUQuFGahvDMHh74W5mrztEenae3R0dNxcLFzcOYlTPRlzVTkFHRKovhZtSKNxIbXYiNYv/Ld7D1JX7i+zz83ClcbAPDw5oQbsGAYT4aWi5iFQfCjelULgRMSWkZhGbmMm0v/fz/YbD2Ar9TWCxwLBODXj4ypaE+HmSnJlDsK+H4xorIrWewk0pFG5EiopPzuSvvQms2JXA7//EkZ6dB4CHq5WsXBvuLlaeGBzFFa3r0zDI28GtFZHaSOGmFAo3Iue2ZEc87y3Zw/oDp+zKXa0WOkfW4fJWIdzQNUKPrkSkyijclELhRqRs8mwGC7cfY+7GI/y2Na7YOi3r+3Jbj0Zc3CSIqFD9/yQilUfhphQKNyLnJ89msGj7MVbtO8mGg6eIPmsJCIB/X9OWS1rUo3Fdb00YKCIVSuGmFAo3IhXjZFo27y7aXezIK4Bnrm5DmzB/Ggd7ExbgVbWNExGno3BTCoUbkYoVn5zJZ3/GEJOQVmTV8sIa1PHiqSGtNXGgiJwXhZtSKNyIVJ6kjBy+Xn2QWWsP4u3uyt7jqWTn2uzq/KtjOG3C/bm+S4SGl4tImSnclELhRqTqZOfauO/rDSXe0Wlaz4drOjZgQJv6tA7zUz8dESmRwk0pFG5EHCM3z8bUlfuZG32EHbEp5Nrs/+oJ9Hbj8lYhdGsSxKUtgokI1Hw6IlJA4aYUCjcijmezGRxNymDJjnjmbzvGqn0nyMmz/6uoZ9O6tGvgzy3dG9Ek2MdBLRWR6kLhphQKNyLVT0JqFluOJLFiVwLfrT9Ecmau3f66Pu4EeLtxcaMgOkfWYXCHMPw8XLEZ4GLVoyyR2kDhphQKNyLVm2EY/PFPHCv3nmDXsRRW7TtZYt2W9X357p5e+Hu6VWELRcQRFG5KoXAjUrNEH0pkb3wqh06l5w83P7P2FYC3uwsdIgJoHeZPmzB/+kWFUFejsEScjsJNKRRuRGq2nDwba2JOMuWv/SzcXnQUlpuLhW5NgujVLBhfD1e83V0Y2C5Ud3dEajiFm1Io3Ig4j4TULPbEp3L4VAbbjiazdv9JthxJKrH+6J6NuOfy5oQGaMFPkZpG4aYUCjcizm3v8VSmrdzPX3tP4Gq1cDItm/iULLs67i5WejSry9jejbm4cRA+7i6kZuXip7s7ItWWwk0pFG5EapfUrFwmL9jF1JX7qePtRkJqtt1+f09XPNxcSMnM4T/XdeBfHcMBNKGgSDWjcFMKhRuR2m3f8VRe+20H80tZB6tRXW/uvKwpnRrWYWdcCoPaheHl7lKFrRSRsynclELhRkQAkjNz8HC18mP0UbbHJnPgRDqr950grdBIrDMiAr0Y0iGMMb0aa4VzEQdRuCmFwo2IlCQlM4f1B07x994TTF91oNig4+XmQtfGgfh5unJJ83qM6NZQj7BEqoDCTSkUbkSkLNKyctl1LAU3FysfLdvL4h3xdvPrnBEV6oeHq5WB7UJpUteH0ABPGgZ5a8VzkQqmcFMKhRsROR+GYfDXnhMcPpVOUkYOq2NOsnhHfIn1uzUJolk9H5rV82Vkj0Z4uqnPjsiFULgphcKNiFSUrUeSWLbrOF+u3I/FAimZucXe3fF0s9KrWTCRQd5c3yWCdg0CHNBakZpN4aYUCjciUlly8mycTMtm3/E03luym82HkkjLzsV21t+y13eJICE1i5w8G+N6N6FvqxCsWgBUpFQKN6VQuBGRqpSSmcOGg4ks2n6MaX8fKLZOHW83gn096N4kiBHdIvFwtVLPz4MdcSl0axyk4COCwk2pFG5ExFFy82z85/cdfLf+MP2i6hPs687Xqw+SkpVb4jGuVgvj+zXnitb1aRvur5FZUmsp3JRC4UZEqpPkzBzm/3OME6lZfLPuEPuOp5VY19vdhR5N69IvKoTB7cMI8nGvwpaKOJbCTSkUbkSkOrPZDBZuP0Z4HS+mrzrAoVPpWLDw554Eu3puLhb6R9XHw83K7mOpdIgIoGezugBYLRaGnl5GQsRZKNyUQuFGRGqiU2nZrNp3go+X72P3sZRiJxgsrF0Dfwa3DyPU35NWoX60DdcILanZFG5KoXAjIs5g5Z4EvvhrPwu3m2tktQ7z59DJdFJL6L/j5+lKRKA3l7UIJirMDz8PcwX0DhEBhPh7Vlm7Rc6Xwk0pFG5ExFntT0jjm3WHuLR5MHuPp7J8dwJHEzPYFptMaX/T33t5M1qF+jGwbagmG5RqS+GmFAo3IlLbJKZnk5Cazcw1B/l+w2ES03OKrWe1QJtwfyLqeJOdZ6Nr40B8PVy5vGUIkXW9q7jVIvZqTLhZvnw5b7zxBuvXryc2NpY5c+YwbNiwEuv/8MMPfPjhh0RHR5OVlUXbtm15/vnnGThwYJk/U+FGRGq7PJvB4h3xHDyZzoJtcYT6ezJ/27FiZ1curE2YP92bBhHo7c61nRtgGHAqPZuODetUTcOlVivP72/XKmpTsdLS0ujYsSNjx47luuuuO2f95cuXM2DAAF555RXq1KnDlClTGDp0KKtXr6Zz585V0GIRkZrPxWphQJv6APzfJU0ASErPYe3+k2w6nMja/SfZdzyNXJvBybTs/OO2xSazLTYZgLcW7Mov93SzMr5vcxoGeXNx4yDC63hV4dWIFFVtHktZLJZz3rkpTtu2bbnpppt49tlny1Rfd25ERMrGMAyW7IzHxWrFZhgs3RHPn3sS2FvKXDwAkUHepGfnkZ6dy8C2obQK9aO+vwct6/vRqK4Pvh4O/Xe11FA15s7NhbLZbKSkpBAUFOTopoiIOB2LxUK/qPr57/u2CgHM0JOSlcvmQ0lsOpzIvOij7DmeSt7pRbQOnkzPP2bOxiNFzvtAv+YE+biTmJFDn5b1aN8ggNSsXOp4a1JCqRg1Oty8+eabpKWlceONN5ZYJysri6ysrPz3ycnJVdE0ERGnZbFY8Pd045IWwVzSIpj7+jYHICs3j93HUlm3/yQ2AxZuP4aL1UJ2ro3DpzI4kpgBwLuL9+Sfa/LC3fnbwb7uXNclgsHtwmge4svmw0lEBHrRMEidmaV8amy4mTlzJs8//zw//vgjISEhJdZ79dVXeeGFF6qwZSIitZOHqwvtGgTQroE5YeC40/15wLzbs+FgIrPXHeJYciYn03PYdCjR7viE1Gw+XraPj5ftsyvv1awuPZvWpUezulzcOIgDJ9J4Z9FuRvdsrM7MUqwa2efmm2++YezYscyePZshQ4aUWre4OzcNGzZUnxsREQczDIOdx1L4a88Jftl8lDwDsnLy2BGXUuIxLUJ82R2fmv9+aMdwejWrS67NICsnj66Ng+ikwOOUnLrPzcyZMxk3bhwzZ848Z7AB8PDwwMPDowpaJiIi5WGxWIgK9Scq1D9/1BbAvuOp/LDhCEeTMrgoMpCUzFzWHzjFwu3H7IINwE+bjvLTpqN2Zb4ernRrEkS7cH9C/D1xsVpoHuJL10aBnEjLxs/TFQ9XTVbozBwablJTU9mzp+DZa0xMDNHR0QQFBREZGckTTzzBkSNHmDZtGmAGm1GjRvHOO+/Qo0cP4uLiAPDy8iIgQOumiIg4g6b1fJk0sFWR8piENPbGp5KVa2PnsRTeXbTbbr+3uwvp2XmkZuWyeEc8i3fEF3t+f09XhnVuQOO6Pri6WPByc6FlfT894nIiDn0stXTpUvr27VukfPTo0UydOpUxY8awf/9+li5dCsDll1/OsmXLSqxfFhoKLiLiHI4kZlDP1wMDg6SMHOr5erBq30n++CcOV6uF46lZbDmSxL5zDF0/o1Fdby5vWY8GgV6kZOay+1gqt3SP5JLmwRw6lU5ogKfu+DhQjZmh2BEUbkREap/v1x9m8c54RvVoxKn0bH7fGseRxAyOJmYS6OPG9tiU/KHspbnrsqb0aFqXrUeS6NYkiDbh/thskJiRTaO6PlVwJbWXwk0pFG5ERORse+JTuHPaevYlmHd5gnzc7WZnPheLBV4b3p6tR5LJtRlMurIlrlYrvp6uuFgtldXsWkXhphQKNyIiUpJdx1JoUMcLHw9XjiRmcONHf5ORk8fEK1owY9VBcm024lOySMnMLdP56ni7MahdKHW83dkbn8qhUxnc3acpXRoFsutYChdFBmrywjJSuCmFwo2IiJRVbp6NXJuBp1tBX5vMnDySM3JIzMghz2YwN/oIS3ccZ+exkoewn4ufpyutw/y5u09T+kXVJ89mkGuzqY9PIQo3pVC4ERGRyhCfkkmwjwcWC3yz9hDrD5zCzdXK9thkMnNs7IxLpgzdeogM8iY+JZPMHBs3do0g0Med+GSzc/S/OoZzf7/mHE/JYvb6w9x0cUOCfWvHdCcKN6VQuBEREUfJyM7j4Ml0XKwW6vl68NTcLfy8OZZODesQ7OvOwu3FD18viYvVQrsGAdT386C+vycZOXnc0j2SiyIDAcjJs+HmYq2MS6lyCjelULgREZHqKjYpg8OnMtgem8xvW8wRXXFJmQT5uBOXnFmmc1gt0K5BAO4uVjYcPEWPpnWJCvXH3dVK6zA/hnYIZ+3+k8QlZ9ImzJ8W9f0q+aoqhsJNKRRuRESkpvp581E2HUqkU8NAvD1cOJCQxsm0bOKSM8nKtfHHP3Fk5tjKdc7IIG86NqxDhwYBDGwbitUKIX6eZGTnsflIIiF+nrQI8cVmGLg68C6Qwk0pFG5ERMSZ7YlPYeuRZFKycqnn68GM1QfYciSJDhF12HDgFKlZZRvpVZir1UKuzaBdA38Cvd359zXtaFTXm7TsPBLTs7HZwNvDpVL7/yjclELhRkREahvDMLBYLMSnZDJ34xHqeLtjAdYfOMWP0UfJyMmrkM8Z3rkBV3cMo3WYP6H+nlgsFTfHj8JNKRRuREREisrMySMnz8a6A6dYtvM4Ler7sjbmJPtPpLM3PpWUctzx8XC18s8LAyv0MZZTrwouIiIiFc/TzQVPNxf6tgqhb6sQAG7t3siuzs64FCwWMAxIzcohKSOHIB8PthxOZPPhJJbvPo6LxUL9AE+H9s9RuBEREZEyaRVa/MiqTmetqG4ry4Q+lcg5Br+LiIhItWF18HpaCjciIiLiVBRuRERExKko3IiIiIhTUbgRERERp6JwIyIiIk5F4UZEREScisKNiIiIOBWFGxEREXEqCjciIiLiVBRuRERExKko3IiIiIhTUbgRERERp6JwIyIiIk7F1dENqGqGYS7Dnpyc7OCWiIiISFmd+b195vd4aWpduElJSQGgYcOGDm6JiIiIlFdKSgoBAQGl1rEYZYlATsRms3H06FH8/PywWCwVeu7k5GQaNmzIoUOH8Pf3r9BzVwfOfn3g/Nfo7NcHzn+Nzn594PzXqOs7P4ZhkJKSQnh4OFZr6b1qat2dG6vVSkRERKV+hr+/v1P+B3uGs18fOP81Ovv1gfNfo7NfHzj/Ner6yu9cd2zOUIdiERERcSoKNyIiIuJUFG4qkIeHB8899xweHh6ObkqlcPbrA+e/Rme/PnD+a3T26wPnv0ZdX+WrdR2KRURExLnpzo2IiIg4FYUbERERcSoKNyIiIuJUFG5ERETEqSjcVJAPPviAJk2a4OnpSZcuXVixYoWjm1Rmy5cvZ+jQoYSHh2OxWJg7d67dfsMweP755wkPD8fLy4vLL7+cf/75x65OVlYW999/P8HBwfj4+PCvf/2Lw4cPV+FVlOzVV1/l4osvxs/Pj5CQEIYNG8bOnTvt6tTka/zwww/p0KFD/oRZPXv25LfffsvfX5OvrTivvvoqFouFiRMn5pfV9Gt8/vnnsVgsdq/Q0ND8/TX9+gCOHDnCyJEjqVu3Lt7e3nTq1In169fn76/p19i4ceMif4YWi4X77rsPqPnXl5uby9NPP02TJk3w8vKiadOmvPjii9hstvw61eoaDblgs2bNMtzc3IxPP/3U2LZtmzFhwgTDx8fHOHDggKObVia//vqr8dRTTxnff/+9ARhz5syx2//aa68Zfn5+xvfff29s2bLFuOmmm4ywsDAjOTk5v87dd99tNGjQwFiwYIGxYcMGo2/fvkbHjh2N3NzcKr6aogYOHGhMmTLF2Lp1qxEdHW0MGTLEiIyMNFJTU/Pr1ORrnDdvnvHLL78YO3fuNHbu3Gk8+eSThpubm7F161bDMGr2tZ1tzZo1RuPGjY0OHToYEyZMyC+v6df43HPPGW3btjViY2PzX/Hx8fn7a/r1nTx50mjUqJExZswYY/Xq1UZMTIyxcOFCY8+ePfl1avo1xsfH2/35LViwwACMJUuWGIZR86/vpZdeMurWrWv8/PPPRkxMjDF79mzD19fXmDx5cn6d6nSNCjcVoFu3bsbdd99tVxYVFWU8/vjjDmrR+Ts73NhsNiM0NNR47bXX8ssyMzONgIAA46OPPjIMwzASExMNNzc3Y9asWfl1jhw5YlitVuP333+vsraXVXx8vAEYy5YtMwzDOa8xMDDQ+Oyzz5zq2lJSUowWLVoYCxYsMPr06ZMfbpzhGp977jmjY8eOxe5zhut77LHHjEsuuaTE/c5wjWebMGGC0axZM8NmsznF9Q0ZMsQYN26cXdnw4cONkSNHGoZR/f4M9VjqAmVnZ7N+/XquvPJKu/Irr7ySlStXOqhVFScmJoa4uDi76/Pw8KBPnz7517d+/XpycnLs6oSHh9OuXbtq+R0kJSUBEBQUBDjXNebl5TFr1izS0tLo2bOnU13bfffdx5AhQ7jiiivsyp3lGnfv3k14eDhNmjTh5ptvZt++fYBzXN+8efPo2rUrN9xwAyEhIXTu3JlPP/00f78zXGNh2dnZTJ8+nXHjxmGxWJzi+i655BIWLVrErl27ANi0aRN//vkngwcPBqrfn2GtWzizoiUkJJCXl0f9+vXtyuvXr09cXJyDWlVxzlxDcdd34MCB/Dru7u4EBgYWqVPdvgPDMHjooYe45JJLaNeuHeAc17hlyxZ69uxJZmYmvr6+zJkzhzZt2uT/hVGTrw1g1qxZbNiwgbVr1xbZ5wx/ft27d2fatGm0bNmSY8eO8dJLL9GrVy/++ecfp7i+ffv28eGHH/LQQw/x5JNPsmbNGh544AE8PDwYNWqUU1xjYXPnziUxMZExY8YAzvHf6GOPPUZSUhJRUVG4uLiQl5fHyy+/zIgRI4Dqd40KNxXEYrHYvTcMo0hZTXY+11cdv4Px48ezefNm/vzzzyL7avI1tmrViujoaBITE/n+++8ZPXo0y5Yty99fk6/t0KFDTJgwgfnz5+Pp6VlivZp8jYMGDcrfbt++PT179qRZs2Z8+eWX9OjRA6jZ12ez2ejatSuvvPIKAJ07d+aff/7hww8/ZNSoUfn1avI1Fvb5558zaNAgwsPD7cpr8vV98803TJ8+na+//pq2bdsSHR3NxIkTCQ8PZ/To0fn1qss16rHUBQoODsbFxaVI6oyPjy+SYGuiMyM2Sru+0NBQsrOzOXXqVIl1qoP777+fefPmsWTJEiIiIvLLneEa3d3dad68OV27duXVV1+lY8eOvPPOO05xbevXryc+Pp4uXbrg6uqKq6sry5Yt491338XV1TW/jTX5Gs/m4+ND+/bt2b17t1P8GYaFhdGmTRu7statW3Pw4EHAOf4fPOPAgQMsXLiQ22+/Pb/MGa7vkUce4fHHH+fmm2+mffv23HbbbTz44IO8+uqrQPW7RoWbC+Tu7k6XLl1YsGCBXfmCBQvo1auXg1pVcZo0aUJoaKjd9WVnZ7Ns2bL86+vSpQtubm52dWJjY9m6dWu1+A4Mw2D8+PH88MMPLF68mCZNmtjtd4ZrPJthGGRlZTnFtfXv358tW7YQHR2d/+ratSu33nor0dHRNG3atMZf49mysrLYvn07YWFhTvFn2Lt37yLTL+zatYtGjRoBzvX/4JQpUwgJCWHIkCH5Zc5wfenp6Vit9pHBxcUlfyh4tbvGCu2eXEudGQr++eefG9u2bTMmTpxo+Pj4GPv373d008okJSXF2Lhxo7Fx40YDMN566y1j48aN+UPZX3vtNSMgIMD44YcfjC1bthgjRowodnhfRESEsXDhQmPDhg1Gv379qs0QxnvuuccICAgwli5dajdUMz09Pb9OTb7GJ554wli+fLkRExNjbN682XjyyScNq9VqzJ8/3zCMmn1tJSk8Wsowav41Pvzww8bSpUuNffv2GatWrTKuvvpqw8/PL//vkJp+fWvWrDFcXV2Nl19+2di9e7cxY8YMw9vb25g+fXp+nZp+jYZhGHl5eUZkZKTx2GOPFdlX069v9OjRRoMGDfKHgv/www9GcHCw8eijj+bXqU7XqHBTQd5//32jUaNGhru7u3HRRRflDzOuCZYsWWIARV6jR482DMMc4vfcc88ZoaGhhoeHh3HZZZcZW7ZssTtHRkaGMX78eCMoKMjw8vIyrr76auPgwYMOuJqiirs2wJgyZUp+nZp8jePGjcv/b69evXpG//7984ONYdTsayvJ2eGmpl/jmflA3NzcjPDwcGP48OHGP//8k7+/pl+fYRjGTz/9ZLRr187w8PAwoqKijE8++cRuvzNc4x9//GEAxs6dO4vsq+nXl5ycbEyYMMGIjIw0PD09jaZNmxpPPfWUkZWVlV+nOl2jxTAMo2LvBYmIiIg4jvrciIiIiFNRuBERERGnonAjIiIiTkXhRkRERJyKwo2IiIg4FYUbERERcSoKNyIiIuJUFG5ERDAX/Js7d66jmyEiFUDhRkQcbsyYMVgsliKvq666ytFNE5EayNXRDRARAbjqqquYMmWKXZmHh4eDWiMiNZnu3IhIteDh4UFoaKjdKzAwEDAfGX344YcMGjQILy8vmjRpwuzZs+2O37JlC/369cPLy4u6dety5513kpqaalfniy++oG3btnh4eBAWFsb48ePt9ickJHDttdfi7e1NixYtmDdvXuVetIhUCoUbEakRnnnmGa677jo2bdrEyJEjGTFiBNu3bwcgPT2dq666isDAQNauXcvs2bNZuHChXXj58MMPue+++7jzzjvZsmUL8+bNo3nz5naf8cILL3DjjTeyefNmBg8ezK233srJkyer9DpFpAJU+FKcIiLlNHr0aMPFxcXw8fGxe7344ouGYZgru9999912x3Tv3t245557DMMwjE8++cQIDAw0UlNT8/f/8ssvhtVqNeLi4gzDMIzw8HDjqaeeKrENgPH000/nv09NTTUsFovx22+/Vdh1ikjVUJ8bEakW+vbty4cffmhXFhQUlL/ds2dPu309e/YkOjoagO3bt9OxY0d8fHzy9/fu3RubzcbOnTuxWCwcPXqU/v37l9qGDh065G/7+Pjg5+dHfHz8+V6SiDiIwo2IVAs+Pj5FHhOdi8ViAcAwjPzt4up4eXmV6Xxubm5FjrXZbOVqk4g4nvrciEiNsGrVqiLvo6KiAGjTpg3R0dGkpaXl7//rr7+wWq20bNkSPz8/GjduzKJFi6q0zSLiGLpzIyLVQlZWFnFxcXZlrq6uBAcHAzB79my6du3KJZdcwowZM1izZg2ff/45ALfeeivPPfcco0eP5vnnn+f48ePcf//93HbbbdSvXx+A559/nrvvvpuQkBAGDRpESkoKf/31F/fff3/VXqiIVDqFGxGpFn7//XfCwsLsylq1asWOHTsAcyTTrFmzuPfeewkNDWXGjBm0adMGAG9vb/744w8mTJjAxRdfjLe3N9dddx1vvfVW/rlGjx5NZmYmb7/9NpMmTSI4OJjrr7++6i5QRKqMxTAMw9GNEBEpjcViYc6cOQwbNszRTRGRGkB9bkRERMSpKNyIiIiIU1GfGxGp9vT0XETKQ3duRERExKko3IiIiIhTUbgRERERp6JwIyIiIk5F4UZEREScisKNiIiIOBWFGxEREXEqCjciIiLiVBRuRERExKn8P9EERxES7tzFAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_acc_loss(training_history) # Observamos su exactitud y pérdida a lo largo de las epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Análisis del modelo: Red Neuronal Original \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Análisis del modelo: Red Neuronal Original \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Mejorar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbS9u6qRpXNd"
      },
      "source": [
        "## 5. Realizar predicciones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TdEpXa1trHJ"
      },
      "source": [
        "## 6. Reflexión\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLlLSsR4twKa"
      },
      "outputs": [],
      "source": [
        "# Empezando con el dataset. Estuve buscando diversas bases de datos que pudieran servirme para realizar este modelo en específico\n",
        "# me tope con la base de datos utilizada, que contiene las ventas en millones según los millones que se inverten en el tipo de marketing.\n",
        "# Decidi comenzar mi programa por importar librerías, consecuentemente me propuse a definir las funciones que serían necesarias para\n",
        "# desarrollar mis modelos de ML (Regresión Lineal Simple). Entre estas funciones se encuentra la atualización de los parametroa w y b, hasta el entrenamiento\n",
        "# y predicción dados ciertos parámetros. Después de definir mis funciones, separe la base de datos entre los features que ocuparían mis modelos\n",
        "# para funcionar: TV, Redes Sociales Y Radio. Teniendo esto, se completo el entrenamiento, visualización y predicción con cada modelo.\n",
        "#\n",
        "#Cabe aclarar que el tipo de modelo no fue el óptimo para todas las variables. Por ejemplo, para la variable de Millones invertidos en TV, se puede confiar en\n",
        "# el modelo pues su error es relativamente bajo y al graficar los datos junto con la predicción podemos observar un comportamiento similar y lineal. Por otro\n",
        "# lado, con las variables de Radio y Redes Socials, el modelo no alcanzó minimzar el error como se esperaba. Es por esto, que a pesar de tener las predicciones\n",
        "# para estas variables, no sonconfiables los resultados.\n",
        "#\n",
        "# Me gustaría en futuras entregas añadir un dataset para la variable de Influencer que también se encuentra en la base de datos original, por cuestiones\n",
        "# de tiempo, no agregué un modelo para dicha variable pero me parece interesante trabajar con ella puesto que es categórica entonces tendría que hacer algún\n",
        "# tipo de transformación a dummy, o parecido, para poder trabajar con ella.\n",
        "#\n",
        "# En conclusión, aprendí más sobre cómo trabaja la regresión lineal simple y cómo se puede optimizar su entrenamiento. A su vez, el manejo de datos aprendido\n",
        "# durante las sesiones tomo mucho valor en este proyecto ya que fue una parte principal para el funcionamiento correcto del modelo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
